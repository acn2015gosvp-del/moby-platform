"""
LLM ê¸°ë°˜ ë³´ê³ ì„œ ìƒì„± ì„œë¹„ìŠ¤ ëª¨ë“ˆ

Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ê°„/ì¼ì¼ ë³´ê³ ì„œë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤.
"""

import logging
import json
import os
import time
import re
from datetime import datetime, date
from typing import Dict, List, Any, Optional
from sqlalchemy.orm import Session

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    genai = None

from backend.api.services.schemas.models.core.config import settings

logger = logging.getLogger(__name__)


class MOBYReportGenerator:
    """MOBY ì£¼ê°„ ë³´ê³ ì„œ ìë™ ìƒì„±ê¸° (Gemini 2.5 Flash)"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        Args:
            api_key: Gemini API í‚¤ (ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ GEMINI_API_KEY ì‚¬ìš©)
        """
        if not GEMINI_AVAILABLE:
            raise ImportError(
                "google-generativeai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                "pip install google-generativeaië¥¼ ì‹¤í–‰í•˜ì„¸ìš”."
            )
        
        api_key = api_key or os.getenv('GEMINI_API_KEY') or getattr(settings, 'GEMINI_API_KEY', None)
        if not api_key:
            raise ValueError(
                "GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                ".env íŒŒì¼ì— GEMINI_API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜ í™˜ê²½ ë³€ìˆ˜ë¡œ ì œê³µí•´ì£¼ì„¸ìš”."
            )
        
        genai.configure(api_key=api_key)
        
        # ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ APIì—ì„œ ê°€ì ¸ì˜¤ê¸°
        self.model = None
        self.model_name = None
        
        # ë¨¼ì € ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜¤ê¸° ì‹œë„
        available_model_names = []
        try:
            models = genai.list_models()
            available_model_names = [
                m.name for m in models 
                if 'generateContent' in m.supported_generation_methods
                and 'gemini' in m.name.lower()
            ]
            logger.info(f"APIì—ì„œ {len(available_model_names)}ê°œì˜ ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸ ë°œê²¬")
        except Exception as e:
            logger.warning(f"ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨, ê¸°ë³¸ ëª©ë¡ ì‚¬ìš©: {e}")
        
        # ì§ì ‘ ëª¨ë¸ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„ (ì›ë³¸ ë…¸íŠ¸ë¶ê³¼ ë™ì¼í•œ ìš°ì„ ìˆœìœ„)
        # ì›ë³¸ ë…¸íŠ¸ë¶ì—ì„œ ì‚¬ìš©í•œ 'gemini-2.5-flash'ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ì‹œë„
        model_candidates = [
            'gemini-2.5-flash',              # ì›ë³¸ ë…¸íŠ¸ë¶ì—ì„œ ì‚¬ìš©í•œ ëª¨ë¸ (ìµœìš°ì„ )
            'models/gemini-2.5-flash',      # ê¸´ ì´ë¦„ ë²„ì „
            'models/gemini-flash-latest',    # ìµœì‹  Flash ëª¨ë¸
            'gemini-flash-latest',           # ì§§ì€ ì´ë¦„
            'models/gemini-2.5-pro',         # ìµœì‹  2.5 Pro ëª¨ë¸
            'gemini-2.5-pro',                # ì§§ì€ ì´ë¦„
            'models/gemini-pro-latest',      # ìµœì‹  Pro ëª¨ë¸
            'models/gemini-2.0-flash',       # 2.0 Flash ëª¨ë¸
            'models/gemini-1.5-flash',       # ì•ˆì •ì ì¸ Flash ëª¨ë¸
            'gemini-1.5-flash',              # ì§§ì€ ì´ë¦„
            'models/gemini-1.5-pro',         # ì•ˆì •ì ì¸ Pro ëª¨ë¸
            'gemini-1.5-pro',                # ì§§ì€ ì´ë¦„
        ]
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ìˆìœ¼ë©´ ìš°ì„ ìˆœìœ„ ì¡°ì •
        if available_model_names:
            # ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì¤‘ì—ì„œ ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ê²ƒë¶€í„° ì°¾ê¸°
            prioritized_available = []
            for candidate in model_candidates:
                # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ëª¨ë¸ ì°¾ê¸°
                for available in available_model_names:
                    if candidate == available or available.endswith('/' + candidate) or candidate == available.split('/')[-1]:
                        if available not in prioritized_available:
                            prioritized_available.append(available)
                            break
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì„ ì•ì— ë°°ì¹˜
            if prioritized_available:
                model_candidates = prioritized_available + [m for m in model_candidates if m not in prioritized_available]
                logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ìš°ì„ ìˆœìœ„ ì¡°ì •: {prioritized_available[:3]}")
        
        self.model = None
        self.model_name = None
        errors = []
        
        logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸ ì°¾ê¸° ì‹œì‘ (ì´ {len(model_candidates)}ê°œ ëª¨ë¸ ì‹œë„)")
        
        for idx, model_name in enumerate(model_candidates, 1):
            try:
                logger.info(f"[{idx}/{len(model_candidates)}] ëª¨ë¸ '{model_name}' ì‹œë„ ì¤‘...")
                
                # ëª¨ë¸ ì´ˆê¸°í™”
                test_model = genai.GenerativeModel(
                    model_name=model_name,
                    generation_config={
                        'temperature': 0.18,
                        'top_p': 0.8,
                        'top_k': 40,
                        'max_output_tokens': 8192,  # í† í° í•œë„ ì¦ê°€
                    }
                )
                
                # ëª¨ë¸ì´ ì‹¤ì œë¡œ ì‘ë™í•˜ëŠ”ì§€ ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ìš”ì²­
                test_response = test_model.generate_content("test")
                
                # ì•ˆì „í•˜ê²Œ í…ŒìŠ¤íŠ¸ ì‘ë‹µ í™•ì¸
                test_text = None
                try:
                    if hasattr(test_response, 'text') and test_response.text:
                        test_text = test_response.text
                    elif hasattr(test_response, 'candidates') and test_response.candidates:
                        candidate = test_response.candidates[0]
                        if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                            parts = candidate.content.parts
                            if parts and hasattr(parts[0], 'text'):
                                test_text = parts[0].text
                
                except AttributeError:
                    # response.text ì ‘ê·¼ ì‹¤íŒ¨ ì‹œ candidatesì—ì„œ ì¶”ì¶œ ì‹œë„
                    if hasattr(test_response, 'candidates') and test_response.candidates:
                        candidate = test_response.candidates[0]
                        if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                            parts = candidate.content.parts
                            if parts and hasattr(parts[0], 'text'):
                                test_text = parts[0].text
                
                if test_text:
                    # ëª¨ë¸ì´ ì •ìƒ ì‘ë™í•¨
                    self.model = test_model
                    self.model_name = model_name
                    logger.info(f"âœ… ëª¨ë¸ '{model_name}' ì´ˆê¸°í™” ë° í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
                    break
                else:
                    raise ValueError(f"ëª¨ë¸ '{model_name}'ê°€ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                error_msg = str(e)
                errors.append(f"{model_name}: {error_msg}")
                logger.warning(f"âŒ ëª¨ë¸ '{model_name}' ì‹¤íŒ¨: {error_msg}")
                
                # API í‚¤ ì •ì§€ ìƒíƒœ ê°ì§€
                if "CONSUMER_SUSPENDED" in error_msg or "has been suspended" in error_msg.lower():
                    # ì²« ë²ˆì§¸ ì •ì§€ ì˜¤ë¥˜ ë°œê²¬ ì‹œ ì¦‰ì‹œ ì¤‘ë‹¨í•˜ê³  ëª…í™•í•œ ë©”ì‹œì§€ ë°˜í™˜
                    api_key_masked = api_key[:10] + "..." if api_key and len(api_key) > 10 else "***"
                    raise ValueError(
                        f"ğŸš« Gemini API í‚¤ê°€ ì •ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n"
                        f"**ë¬¸ì œ**: API í‚¤ê°€ Googleì— ì˜í•´ ì •ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
                        f"**ì›ì¸**: í• ë‹¹ëŸ‰ ì´ˆê³¼, ì •ì±… ìœ„ë°˜, ë˜ëŠ” ë³´ì•ˆ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n"
                        f"**í•´ê²° ë°©ë²•**:\n"
                        f"1. Google AI Studio (https://makersuite.google.com/app/apikey)ì— ì ‘ì†\n"
                        f"2. ìƒˆë¡œìš´ API í‚¤ ìƒì„± ë˜ëŠ” ê¸°ì¡´ í‚¤ ìƒíƒœ í™•ì¸\n"
                        f"3. .env íŒŒì¼ì˜ GEMINI_API_KEY ê°’ì„ ìƒˆ API í‚¤ë¡œ ì—…ë°ì´íŠ¸\n"
                        f"4. ë°±ì—”ë“œ ì„œë²„ ì¬ì‹œì‘\n\n"
                        f"**ì°¸ê³ **: í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ API í‚¤: {api_key_masked}\n"
                        f"ìƒì„¸ ì˜¤ë¥˜: {error_msg[:200]}"
                    )
                
                # 429 í• ë‹¹ëŸ‰ ì´ˆê³¼ ì˜¤ë¥˜ëŠ” ëª¨ë¸ ì´ˆê¸°í™” ë‹¨ê³„ì—ì„œëŠ” ì¬ì‹œë„í•˜ì§€ ì•Šê³  ë‹¤ìŒ ëª¨ë¸ë¡œ ë„˜ì–´ê°
                # (í• ë‹¹ëŸ‰ì´ ì´ˆê³¼ëœ ê²½ìš° ë‹¤ë¥¸ ëª¨ë¸ë„ ë™ì¼í•œ í• ë‹¹ëŸ‰ì„ ê³µìœ í•˜ë¯€ë¡œ)
                if "429" in error_msg or "quota" in error_msg.lower() or "exceeded" in error_msg.lower():
                    logger.warning(f"âš ï¸ ëª¨ë¸ '{model_name}' í• ë‹¹ëŸ‰ ì´ˆê³¼. ë‹¤ìŒ ëª¨ë¸ ì‹œë„...")
                
                continue
        
        if self.model is None:
            # API í‚¤ ì •ì§€ ìƒíƒœê°€ ì´ë¯¸ ê°ì§€ë˜ì—ˆëŠ”ì§€ í™•ì¸
            has_suspended_error = any("CONSUMER_SUSPENDED" in err or "has been suspended" in err.lower() for err in errors)
            
            if has_suspended_error:
                # ì •ì§€ ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ ì´ë¯¸ ìœ„ì—ì„œ ì²˜ë¦¬ë˜ì—ˆì„ ê²ƒì´ì§€ë§Œ, ì•ˆì „ì¥ì¹˜
                api_key_masked = api_key[:10] + "..." if api_key and len(api_key) > 10 else "***"
                raise ValueError(
                    f"ğŸš« Gemini API í‚¤ê°€ ì •ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n"
                    f"**í•´ê²° ë°©ë²•**:\n"
                    f"1. Google AI Studio (https://makersuite.google.com/app/apikey)ì—ì„œ ìƒˆ API í‚¤ ìƒì„±\n"
                    f"2. .env íŒŒì¼ì˜ GEMINI_API_KEY ì—…ë°ì´íŠ¸\n"
                    f"3. ë°±ì—”ë“œ ì„œë²„ ì¬ì‹œì‘\n\n"
                    f"**í˜„ì¬ API í‚¤**: {api_key_masked}"
                )
            
            error_summary = "\n".join([f"  - {err}" for err in errors])
            raise ValueError(
                f"ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
                f"ì‹œë„í•œ ëª¨ë¸ë“¤:\n{error_summary}\n\n"
                f"API í‚¤ì™€ í• ë‹¹ëŸ‰ì„ í™•ì¸í•˜ì„¸ìš”. "
                f"Google AI Studio (https://makersuite.google.com/app/apikey)ì—ì„œ API í‚¤ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”."
            )
        
        logger.info(f"âœ… MOBYReportGenerator ì´ˆê¸°í™” ì™„ë£Œ! ì‚¬ìš© ëª¨ë¸: {self.model_name}")
    
    def _summarize_data_for_prompt(self, data: Dict[str, Any]) -> str:
        """í”„ë¡¬í”„íŠ¸ í¬ê¸°ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ë°ì´í„°ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤."""
        try:
            # ì„¼ì„œ í†µê³„ ìš”ì•½ (í•µì‹¬ í•„ë“œë§Œ)
            sensor_stats_summary = {}
            for key, value in data.get("sensor_stats", {}).items():
                if isinstance(value, dict):
                    # í•µì‹¬ í•„ë“œë§Œ ì¶”ì¶œ
                    summary = {}
                    
                    # ì²« ë²ˆì§¸ ê°’ì´ dictì¸ì§€ í™•ì¸ (ì¤‘ì²© êµ¬ì¡° ê°ì§€)
                    first_value = next(iter(value.values()), None) if value else None
                    if isinstance(first_value, dict):
                        # ì¤‘ì²©ëœ êµ¬ì¡° (ì§„ë™, ê°€ì†ë„, ìì´ë¡œ: x, y, z ì¶•)
                        for axis_key, axis_value in value.items():
                            if isinstance(axis_value, dict):
                                axis_summary = {}
                                for k in ["mean", "max", "min", "peak", "rms", "std", "p95"]:
                                    if k in axis_value:
                                        axis_summary[k] = axis_value[k]
                                if axis_summary:
                                    summary[axis_key] = axis_summary
                    else:
                        # ë‹¨ìˆœ êµ¬ì¡° (ì˜¨ë„, ìŠµë„, ìŒì••, ê¸°ì••)
                        for k in ["mean", "max", "min", "threshold_violations", "std", "p95"]:
                            if k in value:
                                summary[k] = value[k]
                    
                    if summary:
                        sensor_stats_summary[key] = summary
                else:
                    sensor_stats_summary[key] = value
            
            # ìš”ì•½ëœ ë°ì´í„° êµ¬ì„±
            summarized = {
                "metadata": data.get("metadata", {}),
                "sensor_stats": sensor_stats_summary,
                "alarms_count": len(data.get("alarms", [])),
                "alarms_sample": data.get("alarms", [])[:10],  # ìµœëŒ€ 10ê°œë§Œ
                "mlp_anomalies_count": len(data.get("mlp_anomalies", [])),
                "mlp_anomalies_sample": data.get("mlp_anomalies", [])[:5],  # ìµœëŒ€ 5ê°œë§Œ
                "if_anomalies_count": len(data.get("if_anomalies", [])),
                "if_anomalies_sample": data.get("if_anomalies", [])[:5],  # ìµœëŒ€ 5ê°œë§Œ
                "correlations": data.get("correlations", {})
            }
            
            return json.dumps(summarized, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.warning(f"ë°ì´í„° ìš”ì•½ ì‹¤íŒ¨, ì „ì²´ ë°ì´í„° ì‚¬ìš©: {e}")
            # ìš”ì•½ ì‹¤íŒ¨ ì‹œ ì „ì²´ ë°ì´í„° ì‚¬ìš© (ì•ˆì „ì¥ì¹˜)
            return json.dumps(data, indent=2, ensure_ascii=False)
    
    def generate_report(self, report_data: Dict[str, Any]) -> str:
        """
        ë³´ê³ ì„œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì£¼ê°„ ë³´ê³ ì„œ ìƒì„±
        
        Args:
            report_data: ë³´ê³ ì„œ ìƒì„±ì— í•„ìš”í•œ ëª¨ë“  ë°ì´í„°
                - metadata: ë³´ê³  ê¸°ê°„, ì„¤ë¹„ëª…, ìƒì„± ì‹œê°
                - sensor_stats: ì„¼ì„œë³„ í†µê³„
                - alarms: ì•ŒëŒ ëª©ë¡
                - mlp_anomalies: MLP íƒì§€ ê²°ê³¼
                - if_anomalies: Isolation Forest íƒì§€ ê²°ê³¼
                - correlations: ì„¼ì„œ ê°„ ìƒê´€ê³„ìˆ˜
                
        Returns:
            ìƒì„±ëœ ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ë¬¸ìì—´
        """
        try:
            # ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ í™•ì¸ (ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ì‹œë„)
            current_model = 'unknown'
            if self.model_name:
                current_model = self.model_name
            elif self.model:
                # GenerativeModel ê°ì²´ì—ì„œ ëª¨ë¸ ì´ë¦„ ì¶”ì¶œ ì‹œë„
                try:
                    if hasattr(self.model, '_model_name'):
                        current_model = self.model._model_name
                    elif hasattr(self.model, 'model_name'):
                        current_model = self.model.model_name
                except:
                    pass
            
            logger.info(f"ë³´ê³ ì„œ ìƒì„± ì‹œì‘... (ì €ì¥ëœ ëª¨ë¸ëª…: {self.model_name}, ì‹¤ì œ ì‚¬ìš© ëª¨ë¸: {current_model})")
            
            # ëª¨ë¸ì´ ì œëŒ€ë¡œ ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if self.model is None or self.model_name is None:
                logger.warning("ë³´ê³ ì„œ ìƒì„±ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¬ì´ˆê¸°í™” ì‹œë„...")
                # ì¬ì´ˆê¸°í™” ì‹œë„ (API í‚¤ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´)
                try:
                    import os
                    from backend.api.services.schemas.models.core.config import settings
                    api_key = os.getenv('GEMINI_API_KEY') or getattr(settings, 'GEMINI_API_KEY', None)
                    self.__init__(api_key=api_key)
                    if self.model is None or self.model_name is None:
                        raise ValueError("ë³´ê³ ì„œ ìƒì„±ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëª¨ë¸ì„ ë‹¤ì‹œ ì„ íƒí•´ì£¼ì„¸ìš”.")
                    logger.info(f"âœ… ì¬ì´ˆê¸°í™” ì™„ë£Œ! ìƒˆ ëª¨ë¸: {self.model_name}")
                except Exception as init_error:
                    logger.error(f"ì¬ì´ˆê¸°í™” ì‹¤íŒ¨: {init_error}")
                    raise ValueError(f"ë³´ê³ ì„œ ìƒì„±ê¸° ì¬ì´ˆê¸°í™” ì‹¤íŒ¨: {init_error}")
            
            prompt = self._build_prompt(report_data)
            
            start_time = time.time()
            logger.info(f"Gemini API í˜¸ì¶œ ì¤‘... (ëª¨ë¸: {self.model_name}, ìµœì í™”ëœ ì„¤ì •: max_tokens=8192)")
            
            # 429 ì˜¤ë¥˜ ì¬ì‹œë„ ë¡œì§
            max_retries = 3
            retry_count = 0
            response = None
            last_error = None
            
            while retry_count < max_retries:
                try:
                    response = self.model.generate_content(
                        prompt,
                        generation_config={
                            "max_output_tokens": 8192,
                            "temperature": 0.7,
                        }
                    )
                    # ì„±ê³µ ì‹œ ë£¨í”„ ì¢…ë£Œ
                    break
                    
                except Exception as e:
                    error_msg = str(e)
                    last_error = e
                    
                    # 429 í• ë‹¹ëŸ‰ ì´ˆê³¼ ì˜¤ë¥˜ ê°ì§€
                    is_quota_error = (
                        "429" in error_msg or 
                        "quota" in error_msg.lower() or 
                        "rate limit" in error_msg.lower() or 
                        "exceeded" in error_msg.lower()
                    )
                    
                    if is_quota_error and retry_count < max_retries - 1:
                        # retry_delay íŒŒì‹±
                        retry_seconds = None
                        retry_match = re.search(r'retry in ([\d.]+)s', error_msg, re.IGNORECASE)
                        if retry_match:
                            retry_seconds = float(retry_match.group(1))
                        else:
                            # ê¸°ë³¸ ëŒ€ê¸° ì‹œê°„ (20ì´ˆ)
                            retry_seconds = 20.0
                        
                        retry_count += 1
                        wait_time = min(retry_seconds + 2, 60)  # ìµœëŒ€ 60ì´ˆê¹Œì§€ ëŒ€ê¸°
                        logger.warning(
                            f"âš ï¸ Gemini API í• ë‹¹ëŸ‰ ì´ˆê³¼ (ì‹œë„ {retry_count}/{max_retries}). "
                            f"{wait_time:.1f}ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤..."
                        )
                        time.sleep(wait_time)
                        continue
                    else:
                        # 429ê°€ ì•„ë‹ˆê±°ë‚˜ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼
                        if "timeout" in error_msg.lower() or "timed out" in error_msg.lower():
                            raise ValueError(f"Gemini API í˜¸ì¶œ ì‹œê°„ ì´ˆê³¼ (60ì´ˆ): {error_msg}")
                        raise
            
            elapsed_time = time.time() - start_time
            
            # ì•ˆì „í•˜ê²Œ ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            response_text = None
            try:
                # ë¨¼ì € response.textë¥¼ ì‹œë„ (ì¼ë°˜ì ì¸ ê²½ìš°)
                if hasattr(response, 'text') and response.text:
                    response_text = response.text
                elif hasattr(response, 'candidates') and response.candidates:
                    # candidatesì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    for candidate in response.candidates:
                        if hasattr(candidate, 'content') and candidate.content:
                            if hasattr(candidate.content, 'parts'):
                                parts_text = []
                                for part in candidate.content.parts:
                                    if hasattr(part, 'text') and part.text:
                                        parts_text.append(part.text)
                                if parts_text:
                                    response_text = ''.join(parts_text)
                                    break
                        elif hasattr(candidate, 'parts'):
                            # ì§ì ‘ partsê°€ ìˆëŠ” ê²½ìš°
                            parts_text = []
                            for part in candidate.parts:
                                if hasattr(part, 'text') and part.text:
                                    parts_text.append(part.text)
                            if parts_text:
                                response_text = ''.join(parts_text)
                                break
                
                if not response_text:
                    # finish_reason í™•ì¸
                    finish_reason = None
                    if hasattr(response, 'candidates') and response.candidates:
                        finish_reason = getattr(response.candidates[0], 'finish_reason', None)
                    
                    error_detail = f"ì‘ë‹µì— ìœ íš¨í•œ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."
                    if finish_reason:
                        error_detail += f" finish_reason: {finish_reason}"
                    
                    logger.error(f"Gemini API ì‘ë‹µ ì²˜ë¦¬ ì‹¤íŒ¨: {error_detail}")
                    logger.error(f"ì‘ë‹µ êµ¬ì¡°: candidates={hasattr(response, 'candidates')}, text={hasattr(response, 'text')}")
                    
                    raise ValueError(f"Gemini APIê°€ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤. {error_detail}")
                
            except AttributeError as ae:
                # response.text ì ‘ê·¼ ì‹œ ë°œìƒí•˜ëŠ” AttributeError ì²˜ë¦¬
                logger.error(f"Gemini API ì‘ë‹µ êµ¬ì¡° ì˜¤ë¥˜: {ae}")
                logger.error(f"ì‘ë‹µ íƒ€ì…: {type(response)}, ì†ì„±: {dir(response)}")
                
                # ëŒ€ì²´ ë°©ë²•ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
                if hasattr(response, 'candidates') and response.candidates:
                    try:
                        candidate = response.candidates[0]
                        if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                            parts = candidate.content.parts
                            if parts and hasattr(parts[0], 'text'):
                                response_text = parts[0].text
                            else:
                                raise ValueError(f"ì‘ë‹µì— ìœ íš¨í•œ Partê°€ ì—†ìŠµë‹ˆë‹¤. finish_reason: {getattr(candidate, 'finish_reason', 'unknown')}")
                        else:
                            raise ValueError(f"ì‘ë‹µ êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤: {type(candidate)}")
                    except Exception as e:
                        raise ValueError(f"Gemini API ì‘ë‹µ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                else:
                    raise ValueError(f"Gemini API ì‘ë‹µì— candidatesê°€ ì—†ìŠµë‹ˆë‹¤. ì‘ë‹µ íƒ€ì…: {type(response)}")
            
            # ì¬ì‹œë„ê°€ ìˆì—ˆëŠ”ì§€ ë¡œê¹…
            if retry_count > 0:
                logger.info(f"âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ (ì¬ì‹œë„ {retry_count}íšŒ í›„ ì„±ê³µ, ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ, ê¸¸ì´: {len(response_text)} ë¬¸ì, ëª¨ë¸: {self.model_name})")
            else:
                logger.info(f"âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ (ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ, ê¸¸ì´: {len(response_text)} ë¬¸ì, ëª¨ë¸: {self.model_name})")
            return response_text
            
        except Exception as e:
            error_msg = str(e)
            current_model = getattr(self.model, '_model_name', None) or self.model_name or 'unknown'
            logger.exception(f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ëª¨ë¸: {current_model}): {e}")
            
            # 404 ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ ì˜¤ë¥˜ ì²˜ë¦¬
            if "404" in error_msg and "not found" in error_msg.lower():
                # ëª¨ë¸ì´ ì—†ìœ¼ë©´ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë¦¬ì…‹í•˜ê³  ì¬ì‹œë„
                logger.warning(f"ëª¨ë¸ '{current_model}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë³´ê³ ì„œ ìƒì„±ê¸° ë¦¬ì…‹ í›„ ì¬ì´ˆê¸°í™” ì‹œë„...")
                self.model = None
                self.model_name = None
                
                # ìƒˆë¡œìš´ ëª¨ë¸ë¡œ ì¬ì´ˆê¸°í™” ì‹œë„
                try:
                    import os
                    from backend.api.services.schemas.models.core.config import settings
                    from backend.api.services.report_generator import reset_report_generator
                    
                    api_key = os.getenv('GEMINI_API_KEY') or getattr(settings, 'GEMINI_API_KEY', None)
                    
                    # ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë¦¬ì…‹
                    reset_report_generator()
                    
                    # ìƒˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
                    new_generator = MOBYReportGenerator(api_key=api_key)
                    self.model = new_generator.model
                    self.model_name = new_generator.model_name
                    logger.info(f"âœ… ìƒˆë¡œìš´ ëª¨ë¸ë¡œ ì¬ì´ˆê¸°í™” ì™„ë£Œ: {self.model_name}")
                    
                    # ì¬ì‹œë„
                    logger.info(f"ì¬ì‹œë„ ì¤‘... (ìƒˆ ëª¨ë¸: {self.model_name})")
                    response = self.model.generate_content(prompt)
                    
                    # ì•ˆì „í•˜ê²Œ ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ìœ„ì™€ ë™ì¼í•œ ë¡œì§)
                    response_text = None
                    try:
                        if hasattr(response, 'text') and response.text:
                            response_text = response.text
                        elif hasattr(response, 'candidates') and response.candidates:
                            for candidate in response.candidates:
                                if hasattr(candidate, 'content') and candidate.content:
                                    if hasattr(candidate.content, 'parts'):
                                        parts_text = []
                                        for part in candidate.content.parts:
                                            if hasattr(part, 'text') and part.text:
                                                parts_text.append(part.text)
                                        if parts_text:
                                            response_text = ''.join(parts_text)
                                            break
                    
                    except AttributeError as ae:
                        logger.error(f"ì¬ì‹œë„ ì¤‘ ì‘ë‹µ ì²˜ë¦¬ ì˜¤ë¥˜: {ae}")
                        if hasattr(response, 'candidates') and response.candidates:
                            candidate = response.candidates[0]
                            if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                                parts = candidate.content.parts
                                if parts and hasattr(parts[0], 'text'):
                                    response_text = parts[0].text
                    
                    if not response_text:
                        raise ValueError("Gemini APIê°€ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤ (ì¬ì‹œë„).")
                    
                    logger.info(f"ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ (ì¬ì‹œë„ ì„±ê³µ). ê¸¸ì´: {len(response_text)} ë¬¸ì")
                    return response_text
                except Exception as retry_error:
                    logger.error(f"ì¬ì‹œë„ ì‹¤íŒ¨: {retry_error}")
                    raise ValueError(
                        f"Gemini ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                        f"ì‚¬ìš© ì‹œë„ ëª¨ë¸: {current_model}. "
                        f"ì¬ì‹œë„ í›„ ì˜¤ë¥˜: {retry_error}. "
                        f"ì„œë²„ë¥¼ ì¬ì‹œì‘í•´ì£¼ì„¸ìš”."
                    )
            
            # 429 í• ë‹¹ëŸ‰ ì´ˆê³¼ ì˜¤ë¥˜ ì²˜ë¦¬
            if "429" in error_msg or "quota" in error_msg.lower() or "rate limit" in error_msg.lower() or "exceeded" in error_msg.lower():
                # í• ë‹¹ëŸ‰ ì´ˆê³¼ ìƒì„¸ ì •ë³´ ì¶”ì¶œ
                retry_seconds = None
                if "retry_delay" in error_msg or "retry in" in error_msg.lower():
                    import re
                    retry_match = re.search(r'retry in ([\d.]+)s', error_msg, re.IGNORECASE)
                    if retry_match:
                        retry_seconds = float(retry_match.group(1))
                
                quota_info = ""
                is_free_tier = False
                if "free_tier" in error_msg.lower() or "free tier" in error_msg.lower() or "limit: 20" in error_msg:
                    quota_info = " (ë¬´ë£Œ í‹°ì–´ ì¼ì¼ í•œë„: 20íšŒ)"
                    is_free_tier = True
                elif "limit: 0" in error_msg:
                    quota_info = " (Free tierì—ì„œ ì´ ëª¨ë¸ ì‚¬ìš© ë¶ˆê°€)"
                elif "limit:" in error_msg:
                    import re
                    limit_match = re.search(r'limit:\s*(\d+)', error_msg)
                    if limit_match:
                        limit = limit_match.group(1)
                        quota_info = f" (ì¼ì¼ í•œë„: {limit}íšŒ)"
                
                retry_info = ""
                if retry_seconds:
                    retry_minutes = int(retry_seconds // 60)
                    retry_secs = int(retry_seconds % 60)
                    if retry_minutes > 0:
                        retry_info = f"\nâ° ì¬ì‹œë„ ê°€ëŠ¥ ì‹œê°„: ì•½ {retry_minutes}ë¶„ {retry_secs}ì´ˆ í›„"
                    else:
                        retry_info = f"\nâ° ì¬ì‹œë„ ê°€ëŠ¥ ì‹œê°„: ì•½ {retry_secs}ì´ˆ í›„"
                
                # ì‚¬ìš©ì ì¹œí™”ì ì¸ ì—ëŸ¬ ë©”ì‹œì§€ ìƒì„±
                if is_free_tier:
                    error_detail = (
                        f"âš ï¸ Gemini API ë¬´ë£Œ í‹°ì–´ í• ë‹¹ëŸ‰ ì´ˆê³¼\n\n"
                        f"**í˜„ì¬ ìƒí™©**:\n"
                        f"- ë¬´ë£Œ í‹°ì–´ ì¼ì¼ ìš”ì²­ í•œë„(20íšŒ)ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.\n"
                        f"- ì˜¤ëŠ˜ ë” ì´ìƒ ë³´ê³ ì„œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.{retry_info}\n\n"
                        f"**í•´ê²° ë°©ë²•**:\n"
                        f"1. ë‚´ì¼ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš” (í• ë‹¹ëŸ‰ì´ ìë™ìœ¼ë¡œ ë¦¬ì…‹ë©ë‹ˆë‹¤).\n"
                        f"2. Google AI Studioì—ì„œ ìœ ë£Œ í”Œëœìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œí•˜ì„¸ìš”.\n"
                        f"3. í• ë‹¹ëŸ‰ ì‚¬ìš©ëŸ‰ í™•ì¸: https://ai.dev/usage?tab=rate-limit\n\n"
                        f"**ì°¸ê³ **:\n"
                        f"- í• ë‹¹ëŸ‰ ì •ì±…: https://ai.google.dev/gemini-api/docs/rate-limits"
                    )
                else:
                    error_detail = (
                        f"âš ï¸ Gemini API í• ë‹¹ëŸ‰ ì´ˆê³¼\n\n"
                        f"**í˜„ì¬ ìƒí™©**:\n"
                        f"- API ìš”ì²­ í• ë‹¹ëŸ‰ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.{quota_info}{retry_info}\n\n"
                        f"**í•´ê²° ë°©ë²•**:\n"
                        f"1. í• ë‹¹ëŸ‰ì´ ë¦¬ì…‹ë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ì„¸ìš”.{retry_info}\n"
                        f"2. Google AI Studioì—ì„œ í• ë‹¹ëŸ‰ì„ í™•ì¸í•˜ì„¸ìš”.\n"
                        f"3. í• ë‹¹ëŸ‰ ì‚¬ìš©ëŸ‰ í™•ì¸: https://ai.dev/usage?tab=rate-limit\n\n"
                        f"**ì°¸ê³ **:\n"
                        f"- í• ë‹¹ëŸ‰ ì •ì±…: https://ai.google.dev/gemini-api/docs/rate-limits"
                    )
                
                raise ValueError(error_detail)
            
            # ê¸°íƒ€ ì˜¤ë¥˜
            raise ValueError(f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤ (ëª¨ë¸: {current_model}): {error_msg}")
    
    def _build_prompt(self, data: Dict[str, Any]) -> str:
        """ë³´ê³ ì„œ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        
        prompt = f"""ë‹¹ì‹ ì€ ì‚°ì—… ì„¤ë¹„ ëª¨ë‹ˆí„°ë§ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì„¼ì„œ ë°ì´í„°ì™€ ì´ìƒ íƒì§€ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, 
ì—”ì§€ë‹ˆì–´ë§ íŒ€ì„ ìœ„í•œ ì£¼ê°„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

# ë³´ê³ ì„œ ì‘ì„± ì§€ì¹¨

## í˜•ì‹ ìš”êµ¬ì‚¬í•­
- ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±
- ì œê³µëœ í…œí”Œë¦¿ êµ¬ì¡°ë¥¼ ì •í™•íˆ ë”°ë¥¼ ê²ƒ
- í‘œëŠ” ì •ë ¬ëœ í˜•íƒœë¡œ ì‘ì„±

## ë‚´ìš© ìš”êµ¬ì‚¬í•­
**ì¤‘ìš”: ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ ë‚´ìš©ë§Œ ì‘ì„±í•˜ì„¸ìš”. ë¶ˆí•„ìš”í•œ ë°˜ë³µì´ë‚˜ ì¥í™©í•œ ì„¤ëª…ì„ í”¼í•˜ì„¸ìš”.**

1. **Executive Summary**: 2-3ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ ë°œê²¬ì‚¬í•­ ìš”ì•½
   - ì£¼ìš” ì„¼ì„œ ìƒê´€ê´€ê³„
   - ì´ìƒ íƒì§€ ê±´ìˆ˜ ë° ì‹¬ê°ë„
   - ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš” ì—¬ë¶€
   
2. **ì„¼ì„œë³„ í†µê³„**: ì œê³µëœ ìˆ˜ì¹˜ë¥¼ í‘œë¡œ ì •ë¦¬ (ê°„ê²°í•˜ê²Œ)
   - **í•„ìˆ˜**: ì£¼ì–´ì§„ sensor_statsì˜ ìˆ˜ì¹˜ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì—¬ ë§ˆí¬ë‹¤ìš´ í‘œë¥¼ ì‘ì„±í•˜ë¼.
   - **ì˜¨ë„/ìŠµë„/ìŒì••**: mean, min, max, std, p95 ê°’ì„ ëª¨ë‘ í‘œì— í¬í•¨í•˜ë¼.
   - **ì§„ë™ ë°ì´í„°**: X, Y, Zì¶•ì˜ mean, peak(ì ˆëŒ“ê°’ ìµœëŒ€), rms(Root Mean Square)ë¥¼ ë°˜ë“œì‹œ êµ¬ë¶„í•˜ì—¬ í‘œê¸°í•˜ë¼.
   - **ë°ì´í„°ê°€ 0ì´ê±°ë‚˜ ë¯¸ë¯¸í•˜ë”ë¼ë„**: 'ì •ìƒ ë²”ìœ„ ë‚´ ì‘ë™'ìœ¼ë¡œ í•´ì„í•˜ì—¬ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ê³ , ë¹ˆ í‘œë¥¼ ë§Œë“¤ì§€ ë§ˆë¼.
   - **"ë°ì´í„° ì—†ìŒ" ë˜ëŠ” "í†µê³„ ë°ì´í„° ì—†ìŒ"ì´ë¼ê³  í‘œì‹œí•˜ì§€ ë§ˆë¼.** ëª¨ë“  ì„¼ì„œì— ëŒ€í•´ í‘œë¥¼ ì‘ì„±í•˜ë¼.
   - ì„ê³„ê°’ ì´ˆê³¼ ì‹œ **êµµì€ ê¸€ì”¨**ë¡œ ê°•ì¡°
   
3. **ì´ìƒ íƒì§€ ìƒì„¸**: ê° ì´ìƒì— ëŒ€í•´ (í•µì‹¬ë§Œ)
   - ë°œìƒ ì‹œê° ë° ìœ í˜•
   - **ë¬¼ë¦¬ì  í•´ì„**: ì™œ ì´ íŒ¨í„´ì´ ë°œìƒí–ˆëŠ”ì§€, ì„¤ë¹„ ê´€ì ì—ì„œ ê°„ë‹¨íˆ ì„¤ëª…
   - êµ¬ì²´ì  ê¶Œì¥ ì¡°ì¹˜ (1-2ì¤„)
   - ì›ì‹œ ë°ì´í„° JSONì€ ì¤‘ìš”í•œ ê²½ìš°ë§Œ í¬í•¨
   
4. **ìƒê´€ ë¶„ì„ ì¸ì‚¬ì´íŠ¸**: 
   - ì„¼ì„œ ê°„ ê´€ê³„ì˜ **ê³µí•™ì  ì˜ë¯¸** í•´ì„ (ê°„ê²°í•˜ê²Œ)
   - ì‹œê°„ì  íŒ¨í„´ ë¶„ì„ (í•µì‹¬ë§Œ)
   - ê·¼ë³¸ ì›ì¸ ì¶”ë¡  (ê°„ë‹¨íˆ)
   
5. **ê¶Œì¥ ì‚¬í•­**: ìš°ì„ ìˆœìœ„ë³„ ë¶„ë¥˜ (High/Medium/Ongoing) - ê° í•­ëª© 1-2ì¤„

## í†¤ ë° ìŠ¤íƒ€ì¼
- ì „ë¬¸ì ì´ê³  ëª…í™•í•œ ê¸°ìˆ  ë¬¸ì„œ ìŠ¤íƒ€ì¼
- ë¶ˆí™•ì‹¤í•œ ì¶”ì¸¡ë³´ë‹¤ëŠ” ë°ì´í„° ê¸°ë°˜ ë¶„ì„
- ê³¼ì¥í•˜ì§€ ì•Šë˜, ìœ„í—˜ ì‹ í˜¸ëŠ” ëª…í™•íˆ ì§€ì 

---

# ì…ë ¥ ë°ì´í„° êµ¬ì¡°
ì•„ë˜ JSONì€ ë‹¤ìŒ í‚¤ë¥¼ í¬í•¨í•©ë‹ˆë‹¤:
- `metadata`: ë³´ê³  ê¸°ê°„, ì„¤ë¹„ëª…, ìƒì„± ì‹œê°
- `sensor_stats`: ì„¼ì„œë³„ í†µê³„ (ì˜¨ë„, ìŠµë„, ì§„ë™, ê°€ì†ë„, ìì´ë¡œ, ìŒì••, ê¸°ì••)
- `alarms`: ê·œì¹™ ê¸°ë°˜ ì„ê³„ê°’ ì´ˆê³¼ ì•ŒëŒ ëª©ë¡
- `mlp_anomalies`: MLP ëª¨ë¸ì´ íƒì§€í•œ ì•Œë ¤ì§„ ì´ìƒ íŒ¨í„´
- `if_anomalies`: Isolation Forestê°€ íƒì§€í•œ ë¯¸ì§€ì˜ ì´ìƒ (Novelty)
- `correlations`: ì„¼ì„œ ê°„ ìƒê´€ê³„ìˆ˜ ë° í•´ì„

# ì…ë ¥ ë°ì´í„° (ìš”ì•½ ë²„ì „ - í•µì‹¬ ì •ë³´ë§Œ í¬í•¨í•˜ì—¬ í”„ë¡¬í”„íŠ¸ í¬ê¸° ìµœì†Œí™”)
```json
{self._summarize_data_for_prompt(data)}
```

---

# ë³´ê³ ì„œ í…œí”Œë¦¿

ì•„ë˜ êµ¬ì¡°ë¥¼ ë”°ë¼ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”:
```markdown
# ğŸ“˜ MOBY ì„¤ë¹„ ëª¨ë‹ˆí„°ë§ Â· ì´ìƒ íƒì§€ ì£¼ê°„ ë³´ê³ ì„œ

| í•­ëª© | ë‚´ìš© |
| :--- | :--- |
| **ë³´ê³  ê¸°ê°„** | [ìë™ ì…ë ¥] |
| **ì„¤ë¹„** | [ìë™ ì…ë ¥] |
| **ìƒì„± ì¼ì‹œ** | [ìë™ ì…ë ¥] |

---

## 1. ğŸ“Š Executive Summary

[í•µì‹¬ ë°œê²¬ì‚¬í•­ì„ 3-4ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½]

---

## 2. ğŸ“ˆ ì„¼ì„œë³„ í†µê³„ ìš”ì•½

### 2.1 ì˜¨ë„/ìŠµë„ (DHT11)

| ì„¼ì„œ | Mean | Min | Max | Std | P95 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| ì˜¨ë„ | [sensor_stats.temperature.mean ê°’ ì‚¬ìš©] | [sensor_stats.temperature.min ê°’ ì‚¬ìš©] | [sensor_stats.temperature.max ê°’ ì‚¬ìš©] | [sensor_stats.temperature.std ê°’ ì‚¬ìš©] | [sensor_stats.temperature.p95 ê°’ ì‚¬ìš©] |
| ìŠµë„ | [sensor_stats.humidity.mean ê°’ ì‚¬ìš©] | [sensor_stats.humidity.min ê°’ ì‚¬ìš©] | [sensor_stats.humidity.max ê°’ ì‚¬ìš©] | [sensor_stats.humidity.std ê°’ ì‚¬ìš©] | [sensor_stats.humidity.p95 ê°’ ì‚¬ìš©] |

### 2.2 ì§„ë™ (Vibration - MPU6050)

| ì¶• | Mean | Peak (ì ˆëŒ“ê°’ ìµœëŒ€) | RMS (Root Mean Square) |
| :--- | :--- | :--- | :--- |
| X | [sensor_stats.vibration.x.mean ê°’ ì‚¬ìš©] | [sensor_stats.vibration.x.peak ê°’ ì‚¬ìš©] | [sensor_stats.vibration.x.rms ê°’ ì‚¬ìš©] |
| Y | [sensor_stats.vibration.y.mean ê°’ ì‚¬ìš©] | [sensor_stats.vibration.y.peak ê°’ ì‚¬ìš©] | [sensor_stats.vibration.y.rms ê°’ ì‚¬ìš©] |
| Z | [sensor_stats.vibration.z.mean ê°’ ì‚¬ìš©] | [sensor_stats.vibration.z.peak ê°’ ì‚¬ìš©] | [sensor_stats.vibration.z.rms ê°’ ì‚¬ìš©] |

### 2.3 ê°€ì†ë„ (Acceleration - MPU-6050)

| ì¶• | Mean | Min | Max | Std | P95 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| X | [sensor_stats.acceleration.x.mean ê°’ ì‚¬ìš©] | [sensor_stats.acceleration.x.min ê°’ ì‚¬ìš©] | [sensor_stats.acceleration.x.max ê°’ ì‚¬ìš©] | [sensor_stats.acceleration.x.std ê°’ ì‚¬ìš©] | [sensor_stats.acceleration.x.p95 ê°’ ì‚¬ìš©] |
| Y | [sensor_stats.acceleration.y.mean ê°’ ì‚¬ìš©] | [sensor_stats.acceleration.y.min ê°’ ì‚¬ìš©] | [sensor_stats.acceleration.y.max ê°’ ì‚¬ìš©] | [sensor_stats.acceleration.y.std ê°’ ì‚¬ìš©] | [sensor_stats.acceleration.y.p95 ê°’ ì‚¬ìš©] |
| Z | [sensor_stats.acceleration.z.mean ê°’ ì‚¬ìš©] | [sensor_stats.acceleration.z.min ê°’ ì‚¬ìš©] | [sensor_stats.acceleration.z.max ê°’ ì‚¬ìš©] | [sensor_stats.acceleration.z.std ê°’ ì‚¬ìš©] | [sensor_stats.acceleration.z.p95 ê°’ ì‚¬ìš©] |

### 2.4 ìì´ë¡œ (Gyro - MPU-6050)

| ì¶• | Mean | Min | Max | Std | P95 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| X | [sensor_stats.gyro.x.mean ê°’ ì‚¬ìš©] | [sensor_stats.gyro.x.min ê°’ ì‚¬ìš©] | [sensor_stats.gyro.x.max ê°’ ì‚¬ìš©] | [sensor_stats.gyro.x.std ê°’ ì‚¬ìš©] | [sensor_stats.gyro.x.p95 ê°’ ì‚¬ìš©] |
| Y | [sensor_stats.gyro.y.mean ê°’ ì‚¬ìš©] | [sensor_stats.gyro.y.min ê°’ ì‚¬ìš©] | [sensor_stats.gyro.y.max ê°’ ì‚¬ìš©] | [sensor_stats.gyro.y.std ê°’ ì‚¬ìš©] | [sensor_stats.gyro.y.p95 ê°’ ì‚¬ìš©] |
| Z | [sensor_stats.gyro.z.mean ê°’ ì‚¬ìš©] | [sensor_stats.gyro.z.min ê°’ ì‚¬ìš©] | [sensor_stats.gyro.z.max ê°’ ì‚¬ìš©] | [sensor_stats.gyro.z.std ê°’ ì‚¬ìš©] | [sensor_stats.gyro.z.p95 ê°’ ì‚¬ìš©] |

**ì¤‘ìš”**: ê°€ì†ë„ì™€ ìì´ë¡œ í…Œì´ë¸”ì€ ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. HTML íƒœê·¸ë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ë§ˆí¬ë‹¤ìš´ í‘œê°€ ìë™ìœ¼ë¡œ HTML `<table>` íƒœê·¸ë¡œ ë³€í™˜ë©ë‹ˆë‹¤.

### 2.5 ìŒì•• (Sound)

| ì„¼ì„œ | Mean | Min | Max | Std | P95 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| ìŒì•• | [sensor_stats.sound.mean ê°’ ì‚¬ìš©] | [sensor_stats.sound.min ê°’ ì‚¬ìš©] | [sensor_stats.sound.max ê°’ ì‚¬ìš©] | [sensor_stats.sound.std ê°’ ì‚¬ìš©] | [sensor_stats.sound.p95 ê°’ ì‚¬ìš©] |

### 2.6 ê¸°ì•• (Pressure)

| ì„¼ì„œ | Mean | Min | Max | Std | P95 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| ê¸°ì•• | [sensor_stats.pressure.mean ê°’ ì‚¬ìš©] | [sensor_stats.pressure.min ê°’ ì‚¬ìš©] | [sensor_stats.pressure.max ê°’ ì‚¬ìš©] | [sensor_stats.pressure.std ê°’ ì‚¬ìš©] | [sensor_stats.pressure.p95 ê°’ ì‚¬ìš©] |

---

## 3. âš ï¸ ì•ŒëŒ ë° ì´ìƒ íƒì§€ ìƒì„¸

### 3.1 ê·œì¹™ ê¸°ë°˜ ì„¼ì„œ ì•ŒëŒ
[í‘œ ì‘ì„±]

### 3.2 MLP ê¸°ë°˜ ì´ìƒ íƒì§€ (ì•Œë ¤ì§„ ì´ìƒ)
[ê° ì´ìƒë³„ ìƒì„¸ ë¶„ì„]

### 3.3 Isolation Forest ê¸°ë°˜ ë¯¸ì§€ì˜ ì´ìƒ (Novelty)
[Novelty íŒ¨í„´ ë¶„ì„]

---

## 4. ğŸ”— ìƒê´€ ë¶„ì„ ë° ì£¼ê°„ ì¸ì‚¬ì´íŠ¸

### 4.1 ì„¼ì„œ ê°„ ìƒê´€ê³„ìˆ˜
[í‘œ ì‘ì„±]

### 4.2 ì£¼ìš” ì¸ì‚¬ì´íŠ¸
[ë²ˆí˜¸ ëª©ë¡ìœ¼ë¡œ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì •ë¦¬]

---

## 5. ğŸ› ï¸ ê¶Œì¥ ì‚¬í•­

### ì¦‰ì‹œ ì¡°ì¹˜ (High Priority)
[ì²´í¬ë°•ìŠ¤ í•­ëª©]

### ì¤‘ê¸° ì¡°ì¹˜ (Medium Priority)
[ì²´í¬ë°•ìŠ¤ í•­ëª©]

### ëª¨ë‹ˆí„°ë§ ì§€ì† (Ongoing)
[ì²´í¬ë°•ìŠ¤ í•­ëª©]
```

ì´ì œ ìœ„ í…œí”Œë¦¿ì— ë§ì¶° ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
        return prompt


def generate_daily_alert_report_text(db: Session, target_date: Optional[date] = None) -> str:
    """
    ê¸ˆì¼ ë°œìƒí•œ ì•Œë¦¼ì„ ì¡°íšŒí•˜ì—¬ ë³´ê³ ì„œ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        target_date: ì¡°íšŒí•  ë‚ ì§œ (ì—†ìœ¼ë©´ ì˜¤ëŠ˜)
        
    Returns:
        ìƒì„±ëœ ë³´ê³ ì„œ í…ìŠ¤íŠ¸ (ë§ˆí¬ë‹¤ìš´ í˜•ì‹)
    """
    from backend.api.services.alert_history_service import get_today_alerts
    
    try:
        if target_date is None:
            target_date = date.today()
        
        # ê¸ˆì¼ ì•Œë¦¼ ì¡°íšŒ
        alerts = get_today_alerts(db, target_date)
        
        if not alerts:
            return f"# ğŸ“Š MOBY ì¼ì¼ ì´ìƒì§•í›„ ë³´ê³ ì„œ\n\n**ë³´ê³  ë‚ ì§œ:** {target_date}\n\n**ë°œìƒí•œ ì´ìƒì§•í›„ê°€ ì—†ìŠµë‹ˆë‹¤.** âœ…\n"
        
        # ë³´ê³ ì„œ í…ìŠ¤íŠ¸ ìƒì„±
        report_lines = [
            f"# ğŸ“Š MOBY ì¼ì¼ ì´ìƒì§•í›„ ë³´ê³ ì„œ",
            f"",
            f"**ë³´ê³  ë‚ ì§œ:** {target_date}",
            f"**ì´ ë°œìƒ ê±´ìˆ˜:** {len(alerts)}ê±´",
            f"",
            f"---",
            f"",
            f"## ë°œìƒí•œ ì´ìƒì§•í›„ ëª©ë¡",
            f"",
        ]
        
        # ë¯¸í™•ì¸ ì•Œë¦¼ ìˆ˜ ê³„ì‚°
        unchecked_count = sum(1 for alert in alerts if alert.check_status.value == "UNCHECKED")
        if unchecked_count > 0:
            report_lines.append(f"âš ï¸ **ë¯¸í™•ì¸ ì•Œë¦¼:** {unchecked_count}ê±´")
            report_lines.append(f"")
        
        # ì•Œë¦¼ë³„ ìƒì„¸ ì •ë³´
        for idx, alert in enumerate(alerts, 1):
            status_icon = "âŒ" if alert.check_status.value == "UNCHECKED" else "âœ…"
            report_lines.extend([
                f"### {idx}. {status_icon} {alert.message}",
                f"",
                f"- **ë””ë°”ì´ìŠ¤ ID:** {alert.device_id}",
                f"- **ë°œìƒ ì‹œê°:** {alert.occurred_at.strftime('%Y-%m-%d %H:%M:%S')}",
            ])
            
            if alert.error_code:
                report_lines.append(f"- **ì—ëŸ¬ ì½”ë“œ:** {alert.error_code}")
            
            if alert.raw_value:
                try:
                    raw_data = json.loads(alert.raw_value)
                    report_lines.append(f"- **ì›ì‹œ ë°ì´í„°:** `{json.dumps(raw_data, ensure_ascii=False)[:100]}...`")
                except:
                    report_lines.append(f"- **ì›ì‹œ ë°ì´í„°:** `{alert.raw_value[:100]}...`")
            
            if alert.check_status.value == "CHECKED" and alert.checked_by:
                report_lines.append(f"- **í™•ì¸ì:** {alert.checked_by}")
            
            report_lines.append(f"")
        
        # ìš”ì•½
        report_lines.extend([
            f"---",
            f"",
            f"## ìš”ì•½",
            f"",
            f"- ì´ ë°œìƒ ê±´ìˆ˜: **{len(alerts)}ê±´**",
            f"- ë¯¸í™•ì¸ ê±´ìˆ˜: **{unchecked_count}ê±´**",
            f"- í™•ì¸ ì™„ë£Œ ê±´ìˆ˜: **{len(alerts) - unchecked_count}ê±´**",
        ])
        
        report_text = "\n".join(report_lines)
        
        logger.info(f"âœ… ì¼ì¼ ì•Œë¦¼ ë³´ê³ ì„œ í…ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ. ë‚ ì§œ: {target_date}, ê±´ìˆ˜: {len(alerts)}")
        
        return report_text
        
    except Exception as e:
        logger.error(
            f"âŒ ì¼ì¼ ì•Œë¦¼ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨. ë‚ ì§œ: {target_date}, ì˜¤ë¥˜: {e}",
            exc_info=True
        )
        return f"# âŒ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨\n\në‚ ì§œ: {target_date}\nì˜¤ë¥˜: {str(e)}"


def generate_daily_alert_report_html(db: Session, target_date: Optional[date] = None) -> str:
    """
    ê¸ˆì¼ ë°œìƒí•œ ì•Œë¦¼ì„ ì¡°íšŒí•˜ì—¬ HTML í˜•ì‹ì˜ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        target_date: ì¡°íšŒí•  ë‚ ì§œ (ì—†ìœ¼ë©´ ì˜¤ëŠ˜)
        
    Returns:
        ìƒì„±ëœ HTML ë³´ê³ ì„œ
    """
    try:
        import markdown
    except ImportError:
        logger.warning("markdown ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.")
        # markdownì´ ì—†ìœ¼ë©´ ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜
        markdown_text = generate_daily_alert_report_text(db, target_date)
        # ê°„ë‹¨í•œ HTML ë³€í™˜
        html = markdown_text.replace('\n', '<br>').replace('**', '<strong>').replace('**', '</strong>')
        return f'<div style="font-family: sans-serif; padding: 20px;">{html}</div>'
    
    # ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ ìƒì„±
    markdown_text = generate_daily_alert_report_text(db, target_date)
    
    # HTMLë¡œ ë³€í™˜
    html = markdown.markdown(markdown_text, extensions=['extra', 'codehilite'])
    
    return html


# ì „ì—­ ë³´ê³ ì„œ ìƒì„±ê¸° ì¸ìŠ¤í„´ìŠ¤
_report_generator: Optional[MOBYReportGenerator] = None


def get_report_generator() -> MOBYReportGenerator:
    """
    ë³´ê³ ì„œ ìƒì„±ê¸° ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Returns:
        MOBYReportGenerator: ë³´ê³ ì„œ ìƒì„±ê¸° ì¸ìŠ¤í„´ìŠ¤
        
    Raises:
        ImportError: google-generativeai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš°
        ValueError: GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš°
    """
    global _report_generator
    if _report_generator is None:
        _report_generator = MOBYReportGenerator()
    return _report_generator


def reset_report_generator():
    """ë³´ê³ ì„œ ìƒì„±ê¸° ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë¦¬ì…‹í•©ë‹ˆë‹¤. (ëª¨ë¸ ë³€ê²½ ì‹œ í•„ìš”)"""
    global _report_generator
    if _report_generator is not None:
        logger.info("ğŸ”„ ë³´ê³ ì„œ ìƒì„±ê¸° ì¸ìŠ¤í„´ìŠ¤ ë¦¬ì…‹ ì¤‘... (ì´ì „ ëª¨ë¸: {})".format(
            getattr(_report_generator, 'model_name', 'unknown')
        ))
    _report_generator = None
    logger.info("âœ… ë³´ê³ ì„œ ìƒì„±ê¸°ê°€ ë¦¬ì…‹ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ í˜¸ì¶œ ì‹œ ìƒˆ ëª¨ë¸ë¡œ ì´ˆê¸°í™”ë©ë‹ˆë‹¤.")

