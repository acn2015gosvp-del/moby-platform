"""
ë³´ê³ ì„œ ìƒì„± ë°ì´í„° ìˆ˜ì§‘ ì„œë¹„ìŠ¤ ëª¨ë“ˆ

ì‹¤ì œ InfluxDB ë° ì‹œìŠ¤í…œ ë¡œê·¸ì—ì„œ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ì—¬ ë³´ê³ ì„œ ìƒì„±ì— í•„ìš”í•œ ë°ì´í„°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

InfluxDB ì„¼ì„œ ë°ì´í„° ìŠ¤í‚¤ë§ˆ:
- Bucket: sensor_data_v2
- Measurement: moby_sensors
- Tag: device_id (ì˜ˆ: test-sensor-001)

í•„ë“œ ë§¤í•‘:
1. ì˜¨ë„/ìŠµë„ (DHT11):
   - ì˜¨ë„: fields.temperature_c
   - ìŠµë„: fields.humidity_percent

2. ì§„ë™ (Vibration):
   - Mean/Peak/RMS ê³„ì‚°ìš©: fields_vibration_raw

3. ê°€ì†ë„/ìì´ë¡œ (MPU-6050):
   - ê°€ì†ë„ Xì¶•: accel_x
   - ê°€ì†ë„ Yì¶•: accel_y
   - ê°€ì†ë„ Zì¶•: accel_z
   - ìì´ë¡œ Xì¶•: gyro_x
   - ìì´ë¡œ Yì¶•: gyro_y
   - ìì´ë¡œ Zì¶•: gyro_z

4. ìŒì•• (Sound):
   - ìŒì•• ì„¼ì„œê°’: fields.sound_raw ë˜ëŠ” fields.sound_voltage

5. ê¸°ì•• (Pressure):
   - ê¸°ì••: pressure_hpa

ì£¼ì˜ì‚¬í•­:
- í•„ë“œëª…ì— 'fields_' ì ‘ë‘ì‚¬ê°€ ë¶™ì–´ìˆì„ ìˆ˜ ìˆìŒ (fields_temperature_c ë“±)
- pandasì™€ numpyê°€ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ ë°ì´í„° ì²˜ë¦¬ ê°€ëŠ¥
"""

import logging
import random
import math
from datetime import datetime, timezone, timedelta
from typing import Dict, Any, List, Optional, TYPE_CHECKING
from concurrent.futures import ThreadPoolExecutor, as_completed

if TYPE_CHECKING:
    import pandas as pd
from sqlalchemy.orm import Session

try:
    import pandas as pd
    import numpy as np
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False
    pd = None  # pdê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ì„ ë•Œë¥¼ ëŒ€ë¹„
    np = None
    logging.warning("pandasê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install pandas numpy")

from backend.api.services.influx_client import influx_manager
from backend.api.services.schemas.models.core.config import settings
from backend.api.services.alert_storage import get_latest_alerts
from backend.api.services.schemas.models.core.logger import get_logger

logger = get_logger(__name__)


class ReportDataService:
    """ë³´ê³ ì„œ ìƒì„± ë°ì´í„° ìˆ˜ì§‘ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        """InfluxDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        self.influx_client = influx_manager
        # InfluxDB ìŠ¤í‚¤ë§ˆ: Bucket = sensor_data_v2, Measurement = moby_sensors
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ bucketì„ ê°€ì ¸ì˜¤ë˜, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        self.bucket = getattr(settings, 'INFLUX_BUCKET', 'sensor_data_v2')
        # ëª…ì‹œì ìœ¼ë¡œ sensor_data_v2 ì‚¬ìš© (ìŠ¤í‚¤ë§ˆ ëª…ì‹œ)
        if self.bucket != 'sensor_data_v2':
            logger.warning(
                f"âš ï¸ Bucketì´ 'sensor_data_v2'ê°€ ì•„ë‹™ë‹ˆë‹¤: {self.bucket}. "
                f"ìŠ¤í‚¤ë§ˆì— ë”°ë¥´ë©´ 'sensor_data_v2'ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤."
            )
        self.org = settings.INFLUX_ORG
        
        logger.info(
            f"ReportDataService ì´ˆê¸°í™” ì™„ë£Œ. "
            f"Bucket: {self.bucket}, Org: {self.org}, Measurement: moby_sensors"
        )
    
    def fetch_report_data(
        self,
        start_time: datetime,
        end_time: datetime,
        equipment_id: str,
        db: Session,
        sensor_ids: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        ë³´ê³ ì„œ ìƒì„±ì— í•„ìš”í•œ ë°ì´í„°ë¥¼ ì‹¤ì œ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ì¡°íšŒí•©ë‹ˆë‹¤.
        
        Args:
            start_time: ë³´ê³  ê¸°ê°„ ì‹œì‘ ì‹œê°„
            end_time: ë³´ê³  ê¸°ê°„ ì¢…ë£Œ ì‹œê°„
            equipment_id: ì„¤ë¹„ ID
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            sensor_ids: íŠ¹ì • ì„¼ì„œ ID ëª©ë¡ (ì„ íƒ)
            
        Returns:
            ë³´ê³ ì„œ ìƒì„±ì— í•„ìš”í•œ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ì•ŒëŒ ë°ì´í„° ì¡°íšŒ (ë¨¼ì € ì¡°íšŒí•˜ì—¬ fallback ë¡œì§ì— ì‚¬ìš©)
            alarms = self._fetch_alarms(
                db=db,
                start_time=start_time,
                end_time=end_time,
                equipment_id=equipment_id
            )
            
            # ì„¼ì„œ í†µê³„ ë°ì´í„° ì¡°íšŒ (ì•ŒëŒ ë°ì´í„°ë¥¼ fallbackìœ¼ë¡œ ì „ë‹¬)
            sensor_stats = self._fetch_sensor_stats(
                start_time=start_time,
                end_time=end_time,
                equipment_id=equipment_id,
                sensor_ids=sensor_ids,
                alarms=alarms  # fallback ë¡œì§ì— ì‚¬ìš©
            )
            
            # MLP ì´ìƒ íƒì§€ ë°ì´í„° ì¡°íšŒ
            mlp_anomalies = self._fetch_mlp_anomalies(
                db=db,
                start_time=start_time,
                end_time=end_time,
                equipment_id=equipment_id
            )
            
            # IF ì´ìƒ íƒì§€ ë°ì´í„° ì¡°íšŒ
            if_anomalies = self._fetch_if_anomalies(
                db=db,
                start_time=start_time,
                end_time=end_time,
                equipment_id=equipment_id
            )
            
            # ìƒê´€ê³„ìˆ˜ ê³„ì‚°
            correlations = self._calculate_correlations(
                start_time=start_time,
                end_time=end_time,
                equipment_id=equipment_id
            )
            
            # ë©”íƒ€ë°ì´í„°
            metadata = {
                "period_start": start_time.isoformat(),
                "period_end": end_time.isoformat(),
                "equipment": equipment_id,
                "generated_at": datetime.now(timezone.utc).isoformat()
            }
            
            return {
                "metadata": metadata,
                "sensor_stats": sensor_stats,
                "alarms": alarms,
                "mlp_anomalies": mlp_anomalies,
                "if_anomalies": if_anomalies,
                "correlations": correlations
            }
            
        except Exception as e:
            logger.exception(f"ë³´ê³ ì„œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ êµ¬ì¡° ë°˜í™˜
            return {
                "metadata": {
                    "period_start": start_time.isoformat(),
                    "period_end": end_time.isoformat(),
                    "equipment": equipment_id,
                    "generated_at": datetime.now(timezone.utc).isoformat()
                },
                "sensor_stats": self._get_default_sensor_stats(),
                "alarms": [],
                "mlp_anomalies": [],
                "if_anomalies": [],
                "correlations": {}
            }
    
    def _fetch_sensor_stats(
        self,
        start_time: datetime,
        end_time: datetime,
        equipment_id: str,
        sensor_ids: Optional[List[str]] = None,
        alarms: Optional[List[Dict[str, Any]]] = None
    ) -> Dict[str, Any]:
        """
        InfluxDBì—ì„œ Raw ì„¼ì„œ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ì—¬ pandasë¡œ ì •ë°€ í†µê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Raw ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ mean, min, max, std, p95, rms ë“±ì„ ì •í™•í•˜ê²Œ ê³„ì‚°í•©ë‹ˆë‹¤.
        """
        if not PANDAS_AVAILABLE:
            logger.error("pandasê°€ í•„ìš”í•©ë‹ˆë‹¤. pip install pandas numpy")
            return self._get_default_sensor_stats()
        
        try:
            # ì‹œê°„ ë²”ìœ„ë¥¼ RFC3339 í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (íƒ€ì„ì¡´ ëª…ì‹œì ìœ¼ë¡œ UTCë¡œ ë³€í™˜)
            # timezone-awareë¡œ ë³€í™˜ (ì—†ìœ¼ë©´ UTCë¡œ ì„¤ì •)
            if start_time.tzinfo is None:
                start_time = start_time.replace(tzinfo=timezone.utc)
            if end_time.tzinfo is None:
                end_time = end_time.replace(tzinfo=timezone.utc)
            
            # UTCë¡œ ë³€í™˜ (ë‹¤ë¥¸ íƒ€ì„ì¡´ì´ë©´)
            start_time_utc = start_time.astimezone(timezone.utc)
            end_time_utc = end_time.astimezone(timezone.utc)
            
            # RFC3339 í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (Z suffix ì‚¬ìš©)
            start_rfc3339 = start_time_utc.strftime("%Y-%m-%dT%H:%M:%SZ")
            end_rfc3339 = end_time_utc.strftime("%Y-%m-%dT%H:%M:%SZ")
            
            logger.info(f"ğŸ“… ì„¼ì„œ í†µê³„ ì¡°íšŒ ì‹œê°„ ë²”ìœ„ (UTC): {start_rfc3339} ~ {end_rfc3339}")
            logger.info(f"   ì›ë³¸ ì‹œê°„: {start_time} ~ {end_time}")
            logger.info(f"   ì‹œê°„ ë²”ìœ„ ê¸¸ì´: {(end_time_utc - start_time_utc).total_seconds() / 3600:.2f}ì‹œê°„")
            
            # ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ” ì‹œê°„ ë²”ìœ„ì™€ ë¹„êµ
            if alarms:
                alarm_times = []
                for alarm in alarms:
                    alarm_time_str = alarm.get('timestamp') or alarm.get('ts') or alarm.get('time')
                    if alarm_time_str:
                        try:
                            if isinstance(alarm_time_str, str):
                                if 'Z' in alarm_time_str:
                                    alarm_time_str = alarm_time_str.replace('Z', '+00:00')
                                alarm_dt = datetime.fromisoformat(alarm_time_str)
                            else:
                                alarm_dt = alarm_time_str
                            
                            if alarm_dt.tzinfo is None:
                                alarm_dt = alarm_dt.replace(tzinfo=timezone.utc)
                            else:
                                alarm_dt = alarm_dt.astimezone(timezone.utc)
                            
                            alarm_times.append(alarm_dt)
                        except Exception:
                            continue
                
                if alarm_times:
                    actual_data_start = min(alarm_times)
                    actual_data_end = max(alarm_times)
                    logger.info(
                        f"   ì•ŒëŒ ë°ì´í„° ì‹œê°„ ë²”ìœ„: {actual_data_start.isoformat()} ~ {actual_data_end.isoformat()}"
                    )
                    
                    # ì‹œê°„ ë²”ìœ„ ê²¹ì¹¨ í™•ì¸
                    if actual_data_start > end_time_utc or actual_data_end < start_time_utc:
                        logger.warning(
                            f"   âš ï¸ ì‹œê°„ ë²”ìœ„ ë¶ˆì¼ì¹˜! ìš”ì²­ ë²”ìœ„ì™€ ì•ŒëŒ ë°ì´í„° ë²”ìœ„ê°€ ê²¹ì¹˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
                            f"      ìš”ì²­ ë²”ìœ„: {start_rfc3339} ~ {end_rfc3339}\n"
                            f"      ì•ŒëŒ ë²”ìœ„: {actual_data_start.isoformat()} ~ {actual_data_end.isoformat()}"
                        )
                    else:
                        logger.info(f"   âœ… ì‹œê°„ ë²”ìœ„ ì¼ì¹˜ í™•ì¸ë¨")
            
            # ì•ŒëŒ ë°ì´í„°ì—ì„œ ì‹¤ì œ ë°ì´í„° ì¡´ì¬ ì‹œê°„ ë²”ìœ„ í™•ì¸
            actual_data_start = None
            actual_data_end = None
            if alarms:
                alarm_times = []
                for alarm in alarms:
                    alarm_time_str = alarm.get('timestamp') or alarm.get('ts') or alarm.get('time')
                    if alarm_time_str:
                        try:
                            if isinstance(alarm_time_str, str):
                                # ISO í˜•ì‹ íŒŒì‹±
                                if 'Z' in alarm_time_str:
                                    alarm_time_str = alarm_time_str.replace('Z', '+00:00')
                                alarm_dt = datetime.fromisoformat(alarm_time_str)
                            else:
                                alarm_dt = alarm_time_str
                            
                            if alarm_dt.tzinfo is None:
                                alarm_dt = alarm_dt.replace(tzinfo=timezone.utc)
                            else:
                                alarm_dt = alarm_dt.astimezone(timezone.utc)
                            
                            alarm_times.append(alarm_dt)
                        except Exception as e:
                            logger.debug(f"ì•ŒëŒ ì‹œê°„ íŒŒì‹± ì‹¤íŒ¨: {alarm_time_str}, ì˜¤ë¥˜: {e}")
                
                if alarm_times:
                    actual_data_start = min(alarm_times)
                    actual_data_end = max(alarm_times)
                    logger.info(
                        f"ğŸ“Š ì•ŒëŒ ë°ì´í„° ê¸°ë°˜ ì‹¤ì œ ë°ì´í„° ì‹œê°„ ë²”ìœ„: "
                        f"{actual_data_start.isoformat()} ~ {actual_data_end.isoformat()}"
                    )
                    
                    # ìš”ì²­ ì‹œê°„ ë²”ìœ„ì™€ ì•ŒëŒ ì‹œê°„ ë²”ìœ„ ë¹„êµ
                    if actual_data_start < start_time_utc or actual_data_end > end_time_utc:
                        logger.warning(
                            f"âš ï¸ ì•ŒëŒ ì‹œê°„ ë²”ìœ„ê°€ ìš”ì²­ ì‹œê°„ ë²”ìœ„ì™€ ë‹¤ë¦…ë‹ˆë‹¤!\n"
                            f"   ìš”ì²­ ë²”ìœ„: {start_rfc3339} ~ {end_rfc3339}\n"
                            f"   ì•ŒëŒ ë²”ìœ„: {actual_data_start.isoformat()} ~ {actual_data_end.isoformat()}\n"
                            f"   â†’ ì‹œê°„ ë²”ìœ„ë¥¼ ì•ŒëŒ ë°ì´í„°ì— ë§ì¶° í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                        )
            
            # ì„¼ì„œ í•„í„° êµ¬ì„±
            # InfluxDB ìŠ¤í‚¤ë§ˆ: Tag = device_id (ì˜ˆ: test-sensor-001)
            # ì£¼ì˜: equipment_idëŠ” ì„¤ë¹„ëª…("Conveyor A-01")ì¼ ìˆ˜ ìˆê³ , device_idëŠ” ì‹¤ì œ ë””ë°”ì´ìŠ¤ IDì…ë‹ˆë‹¤.
            # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë³´ë‚´ëŠ” equipment_idì™€ ì‹¤ì œ InfluxDBì˜ device_id íƒœê·¸ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ,
            # ì¼ë‹¨ í•„í„° ì—†ì´ ëª¨ë“  ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
            # ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œëŠ” equipment_id -> device_id ë§¤í•‘ í…Œì´ë¸”ì´ í•„ìš”í•©ë‹ˆë‹¤.
            device_filter = None
            
            # TODO: equipment_id -> device_id ë§¤í•‘ ë¡œì§ ì¶”ê°€ í•„ìš”
            # í˜„ì¬ëŠ” í•„í„° ì—†ì´ ëª¨ë“  ë°ì´í„° ì¡°íšŒí•˜ì—¬ í†µê³„ ê³„ì‚°
            # equipment_idëŠ” ì„¤ë¹„ëª…ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ device_id í•„í„°ë¥¼ ì ìš©í•˜ì§€ ì•ŠìŒ
            logger.info(f"equipment_id '{equipment_id}' - í•„í„° ì—†ì´ ëª¨ë“  ë°ì´í„° ì¡°íšŒ (ì„¤ë¹„ëª…ì¼ ìˆ˜ ìˆìŒ)")
            
            # sensor_idsëŠ” ì‹¤ì œ device_idì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ í•„í„° ì ìš©
            # InfluxDB ìŠ¤í‚¤ë§ˆì— ë”°ë¥´ë©´ device_id íƒœê·¸ë¥¼ ì‚¬ìš©í•´ì•¼ í•¨
            if sensor_ids:
                # sensor_idsê°€ ì‹¤ì œ device_id í˜•ì‹ì¸ì§€ í™•ì¸
                valid_sensor_ids = [sid for sid in sensor_ids if len(sid) >= 10]
                if valid_sensor_ids:
                    # device_id íƒœê·¸ í•„í„° ì‚¬ìš© (ìŠ¤í‚¤ë§ˆ ëª…ì‹œ)
                    sensor_filter = ' or '.join([f'r["device_id"] == "{sid}"' for sid in valid_sensor_ids])
                    device_filter = f'({sensor_filter})'
                    logger.info(f"device_id í•„í„° ì ìš©: {valid_sensor_ids}")
            
            sensor_stats = {}
            
            # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì„¼ì„œ í†µê³„ ê³„ì‚° ì†ë„ í–¥ìƒ
            logger.info(f"ì„¼ì„œ í†µê³„ ë³‘ë ¬ ê³„ì‚° ì‹œì‘ (ê¸°ê°„: {start_rfc3339} ~ {end_rfc3339})")
            
            def calc_temperature():
                try:
                    # InfluxDB ìŠ¤í‚¤ë§ˆ: fields.temperature_c (DHT11)
                    return ("temperature", self._calculate_sensor_stats_from_raw(
                        start_rfc3339, end_rfc3339, "fields_temperature_c", device_filter, "moby_sensors"
                    ))
                except Exception as e:
                    logger.error(f"âŒ ì˜¨ë„ í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {e}")
                    return ("temperature", {"mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0})
            
            def calc_humidity():
                try:
                    # InfluxDB ìŠ¤í‚¤ë§ˆ: fields.humidity_percent (DHT11)
                    return ("humidity", self._calculate_sensor_stats_from_raw(
                        start_rfc3339, end_rfc3339, "fields_humidity_percent", device_filter, "moby_sensors"
                    ))
                except Exception as e:
                    logger.error(f"âŒ ìŠµë„ í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {e}")
                    return ("humidity", {"mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0})
            
            def calc_vibration():
                try:
                    # InfluxDB í•„ë“œëª…: fields_vibration_raw
                    return ("vibration", self._calculate_vibration_stats_from_raw(
                        start_rfc3339, end_rfc3339, device_filter, "moby_sensors"
                    ))
                except Exception as e:
                    logger.error(f"âŒ ì§„ë™ í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {e}")
                    return ("vibration", {
                        "x": {"mean": 0.0, "peak": 0.0, "rms": 0.0},
                        "y": {"mean": 0.0, "peak": 0.0, "rms": 0.0},
                        "z": {"mean": 0.0, "peak": 0.0, "rms": 0.0}
                    })
            
            def calc_sound():
                try:
                    # InfluxDB ìŠ¤í‚¤ë§ˆ: fields.sound_raw ë˜ëŠ” fields.sound_voltage
                    return ("sound", self._calculate_sensor_stats_from_raw(
                        start_rfc3339, end_rfc3339, "fields_sound_raw", device_filter, "moby_sensors"
                    ))
                except Exception as e:
                    logger.error(f"âŒ ìŒì•• í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {e}")
                    return ("sound", {"mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0})
            
            def calc_acceleration():
                try:
                    # InfluxDB í•„ë“œëª…: accel_x, accel_y, accel_z (fields_ ì ‘ë‘ì‚¬ ì—†ìŒ)
                    return ("acceleration", self._calculate_axis_stats_from_raw(
                        start_rfc3339, end_rfc3339, 
                        ["accel_x", "accel_y", "accel_z"],
                        device_filter, "moby_sensors"
                    ))
                except Exception as e:
                    logger.error(f"âŒ ê°€ì†ë„ í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {e}")
                    return ("acceleration", {
                        "x": {"mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0},
                        "y": {"mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0},
                        "z": {"mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0}
                    })
            
            def calc_gyro():
                try:
                    # InfluxDB í•„ë“œëª…: gyro_x, gyro_y, gyro_z (fields_ ì ‘ë‘ì‚¬ ì—†ìŒ)
                    return ("gyro", self._calculate_axis_stats_from_raw(
                        start_rfc3339, end_rfc3339,
                        ["gyro_x", "gyro_y", "gyro_z"],
                        device_filter, "moby_sensors"
                    ))
                except Exception as e:
                    logger.error(f"âŒ ìì´ë¡œ í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {e}")
                    return ("gyro", {
                        "x": {"mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0},
                        "y": {"mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0},
                        "z": {"mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0}
                    })
            
            def calc_pressure():
                try:
                    # InfluxDB í•„ë“œëª…: pressure_hpa (fields_ ì ‘ë‘ì‚¬ ì—†ìŒ)
                    return ("pressure", self._calculate_sensor_stats_from_raw(
                        start_rfc3339, end_rfc3339, "pressure_hpa", device_filter, "moby_sensors"
                    ))
                except Exception as e:
                    logger.error(f"âŒ ê¸°ì•• í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {e}")
                    return ("pressure", {"mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0})
            
            # ë³‘ë ¬ ì‹¤í–‰ (ìµœëŒ€ 7ê°œ ìŠ¤ë ˆë“œ: ì˜¨ë„, ìŠµë„, ì§„ë™, ìŒì••, ê°€ì†ë„, ìì´ë¡œ, ê¸°ì••)
            with ThreadPoolExecutor(max_workers=7) as executor:
                futures = {
                    executor.submit(calc_temperature): "temperature",
                    executor.submit(calc_humidity): "humidity",
                    executor.submit(calc_vibration): "vibration",
                    executor.submit(calc_sound): "sound",
                    executor.submit(calc_acceleration): "acceleration",
                    executor.submit(calc_gyro): "gyro",
                    executor.submit(calc_pressure): "pressure"
                }
                
                for future in as_completed(futures):
                    sensor_name = None
                    try:
                        # íƒ€ì„ì•„ì›ƒì„ 10ì´ˆë¡œ ë‹¨ì¶• (ë” ë¹ ë¥¸ ì‹¤íŒ¨ ì²˜ë¦¬)
                        sensor_name, stats = future.result(timeout=10)
                        sensor_stats[sensor_name] = stats
                        logger.info(f"âœ… {sensor_name} í†µê³„ ê³„ì‚° ì™„ë£Œ")
                    except TimeoutError:
                        sensor_name = futures.get(future, "unknown")
                        logger.warning(f"â±ï¸ {sensor_name} í†µê³„ ê³„ì‚° íƒ€ì„ì•„ì›ƒ (10ì´ˆ ì´ˆê³¼), ê¸°ë³¸ê°’ ì‚¬ìš©")
                        if sensor_name in ["vibration", "acceleration", "gyro"]:
                            if sensor_name == "vibration":
                                sensor_stats[sensor_name] = {
                                    "x": {"mean": 0.0, "peak": 0.0, "rms": 0.0},
                                    "y": {"mean": 0.0, "peak": 0.0, "rms": 0.0},
                                    "z": {"mean": 0.0, "peak": 0.0, "rms": 0.0}
                                }
                            else:
                                sensor_stats[sensor_name] = {
                                    "x": {"mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0},
                                    "y": {"mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0},
                                    "z": {"mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0}
                                }
                        else:
                            sensor_stats[sensor_name] = {
                                "mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0
                            }
                    except Exception as e:
                        sensor_name = futures.get(future, "unknown")
                        logger.error(f"âŒ {sensor_name} í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {e}", exc_info=True)
                        # ê¸°ë³¸ê°’ ì„¤ì •
                        if sensor_name in ["vibration", "acceleration", "gyro"]:
                            if sensor_name == "vibration":
                                sensor_stats[sensor_name] = {
                                    "x": {"mean": 0.0, "peak": 0.0, "rms": 0.0},
                                    "y": {"mean": 0.0, "peak": 0.0, "rms": 0.0},
                                    "z": {"mean": 0.0, "peak": 0.0, "rms": 0.0}
                                }
                            else:
                                sensor_stats[sensor_name] = {
                                    "x": {"mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0},
                                    "y": {"mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0},
                                    "z": {"mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0}
                                }
                        else:
                            sensor_stats[sensor_name] = {
                                "mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0
                            }
            
            logger.info(f"ì„¼ì„œ í†µê³„ ê³„ì‚° ì™„ë£Œ: {len(sensor_stats)}ê°œ ì„¼ì„œ")
            logger.info(f"ì„¼ì„œ í†µê³„ ìƒì„¸: {sensor_stats}")
            
            # í†µê³„ ê°’ì´ ëª¨ë‘ 0.0ì¸ì§€ í™•ì¸
            all_zero = True
            for sensor_name, stats in sensor_stats.items():
                if sensor_name == "vibration":
                    for axis in ["x", "y", "z"]:
                        axis_stats = stats.get(axis, {})
                        if any(v != 0.0 for v in axis_stats.values()):
                            all_zero = False
                            break
                else:
                    if any(v != 0.0 for v in stats.values()):
                        all_zero = False
                        break
                if not all_zero:
                    break
            
            # Fallback: InfluxDB ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì•ŒëŒ ë°ì´í„°ì—ì„œ í†µê³„ ê³„ì‚°
            if all_zero:
                logger.warning("âš ï¸ ëª¨ë“  ì„¼ì„œ í†µê³„ê°€ 0.0ì…ë‹ˆë‹¤. ë°ì´í„° ì¡°íšŒì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                logger.warning(f"   ê¸°ê°„: {start_time} ~ {end_time}")
                logger.warning(f"   equipment_id: {equipment_id}")
                logger.warning(f"   device_filter: {device_filter}")
                
                # ì•ŒëŒ ë°ì´í„°ì—ì„œ í†µê³„ ê³„ì‚° ì‹œë„
                if alarms and len(alarms) > 0:
                    logger.info(f"ğŸ“Š ì•ŒëŒ ë°ì´í„°ì—ì„œ í†µê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤ (Fallback). ì•ŒëŒ ê°œìˆ˜: {len(alarms)}ê°œ")
                    try:
                        sensor_stats = self._calculate_stats_from_alarms(alarms)
                        # Fallbackìœ¼ë¡œ ê³„ì‚°í•œ í†µê³„ê°€ ì—¬ì „íˆ 0.0ì¸ì§€ í™•ì¸
                        fallback_all_zero = True
                        for sensor_name, stats in sensor_stats.items():
                            if sensor_name == "vibration":
                                for axis in ["x", "y", "z"]:
                                    axis_stats = stats.get(axis, {})
                                    if any(v != 0.0 for v in axis_stats.values()):
                                        fallback_all_zero = False
                                        break
                            else:
                                if any(v != 0.0 for v in stats.values()):
                                    fallback_all_zero = False
                                    break
                            if not fallback_all_zero:
                                break
                        
                        if not fallback_all_zero:
                            logger.info("âœ… ì•ŒëŒ ë°ì´í„°ì—ì„œ í†µê³„ ê³„ì‚° ì„±ê³µ (0ì´ ì•„ë‹Œ ê°’ ì¡´ì¬)")
                        else:
                            logger.warning("âš ï¸ ì•ŒëŒ ë°ì´í„°ì—ì„œë„ í†µê³„ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’(0.0)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    except Exception as fallback_error:
                        logger.error(f"âŒ ì•ŒëŒ ë°ì´í„°ì—ì„œ í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {fallback_error}", exc_info=True)
                        logger.warning("âš ï¸ ê¸°ë³¸ê°’(0.0)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                else:
                    logger.warning("âš ï¸ ì•ŒëŒ ë°ì´í„°ë„ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’(0.0)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            
            return sensor_stats
            
        except Exception as e:
            logger.exception(f"ì„¼ì„œ í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            logger.error(f"   ê¸°ê°„: {start_time} ~ {end_time}")
            logger.error(f"   equipment_id: {equipment_id}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜ (0.0ìœ¼ë¡œ ì±„ì›Œì§„ êµ¬ì¡°)
            return self._get_default_sensor_stats()
    
    def _fetch_raw_data_as_dataframe(
        self,
        start_rfc3339: str,
        end_rfc3339: str,
        field_name: str,
        device_filter: Optional[str] = None,
        measurement: str = "moby_sensors"
    ) -> Optional[Any]:
        """
        InfluxDBì—ì„œ Raw ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ì—¬ pandas DataFrameìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Returns:
            DataFrame with columns: ['_time', '_value'] or None if no data
            Returns None if pandas is not available
        """
        try:
            # Raw ë°ì´í„° ì¡°íšŒ ì¿¼ë¦¬
            base_filter = f'|> filter(fn: (r) => r["_measurement"] == "{measurement}")\n  |> filter(fn: (r) => r["_field"] == "{field_name}")'
            if device_filter:
                base_filter += f'\n  |> filter(fn: (r) => {device_filter})'
            
            # ì¿¼ë¦¬ ìµœì í™”: aggregateWindowë¥¼ ì‚¬ìš©í•˜ì—¬ 10ë¶„ ë‹¨ìœ„ë¡œ ì§‘ê³„ (ë” ë¹ ë¥¸ ì²˜ë¦¬)
            # Raw ë°ì´í„°ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ íƒ€ì„ì•„ì›ƒ ë°œìƒí•˜ë¯€ë¡œ ì§‘ê³„ ì‚¬ìš©
            # í†µê³„ ê³„ì‚°ì—ëŠ” ì§‘ê³„ëœ ë°ì´í„°ë¡œë„ ì¶©ë¶„í•¨
            # ì¤‘ìš”: float()ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°’ì´ ë¬¸ìì—´ì´ì–´ë„ ìˆ«ìë¡œ ë³€í™˜
            # InfluxDBì˜ float() í•¨ìˆ˜ëŠ” ë¬¸ìì—´ì„ ìˆ«ìë¡œ ë³€í™˜
            query = f'''
            from(bucket: "{self.bucket}")
              |> range(start: {start_rfc3339}, stop: {end_rfc3339})
              {base_filter}
              |> group()
              |> aggregateWindow(every: 30m, fn: mean, createEmpty: false)
              |> map(fn: (r) => ({{
                _time: r._time,
                _value: if exists r._value then float(v: r._value) else 0.0,
                _measurement: r._measurement,
                _field: r._field
              }}))
              |> sort(columns: ["_time"])
              |> limit(n: 5000)
            '''
            
            logger.info(f"ğŸ“Š Raw ë°ì´í„° ì¡°íšŒ ì¿¼ë¦¬ ì‹¤í–‰ (30ë¶„ ì§‘ê³„): {field_name}")
            logger.info(f"   ì¡°íšŒ ê¸°ê°„: {start_rfc3339} ~ {end_rfc3339}")
            logger.info(f"   í•„í„°: {device_filter if device_filter else 'ì—†ìŒ (ëª¨ë“  ë°ì´í„°)'}")
            logger.info(f"   measurement: {measurement}, field: {field_name}")
            logger.info(f"   ì‹¤í–‰ ì¿¼ë¦¬:")
            logger.info(f"   {query}")
            try:
                # ì¿¼ë¦¬ ì‹¤í–‰ ì „ ë¡œê¹…
                logger.info(f"   ğŸ”„ InfluxDB ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘...")
                query_start_time = datetime.now(timezone.utc)
                
                # ì¿¼ë¦¬ íƒ€ì„ì•„ì›ƒ ì„¤ì • (15ì´ˆ)
                result = self.influx_client.query_api.query(
                    query=query, 
                    org=self.org
                )
                
                query_end_time = datetime.now(timezone.utc)
                query_duration = (query_end_time - query_start_time).total_seconds()
                logger.info(f"   âœ… ì¿¼ë¦¬ ì‹¤í–‰ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {query_duration:.2f}ì´ˆ)")
                if query_duration > 5.0:
                    logger.warning(f"   âš ï¸ ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„ì´ ê¹ë‹ˆë‹¤: {query_duration:.2f}ì´ˆ ({field_name})")
            except Exception as e:
                error_msg = str(e)
                logger.warning(f"ì§‘ê³„ ì¿¼ë¦¬ ì‹¤íŒ¨ ({field_name}): {error_msg}")
                
                # "Too Many Requests" ì˜¤ë¥˜ì¸ ê²½ìš° ìƒ˜í”Œë§ ì‚¬ìš©
                if "too many requests" in error_msg.lower() or "429" in error_msg:
                    logger.info(f"{field_name}: Too Many Requests, ìƒ˜í”Œë§ìœ¼ë¡œ ì¬ì‹œë„...")
                    query_sample = f'''
                    from(bucket: "{self.bucket}")
                      |> range(start: {start_rfc3339}, stop: {end_rfc3339})
                      {base_filter}
                      |> group()
                      |> sample(n: 5000)
                      |> sort(columns: ["_time"])
                    '''
                    result = self.influx_client.query_api.query(query=query_sample, org=self.org)
                else:
                    # ë‹¤ë¥¸ ì˜¤ë¥˜ëŠ” ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ
                    raise
            
            # DataFrameìœ¼ë¡œ ë³€í™˜ (ìµœëŒ€ 10000ê°œë¡œ ì œí•œí•˜ì—¬ ë©”ëª¨ë¦¬ ë° ì†ë„ ìµœì í™”)
            data = []
            table_count = 0
            record_count = 0
            valid_value_count = 0
            invalid_value_count = 0
            max_records = 10000  # ìµœëŒ€ ë ˆì½”ë“œ ìˆ˜ ì œí•œ
            
            for table in result:
                table_count += 1
                for record in table.records:
                    if len(data) >= max_records:
                        logger.warning(f"{field_name}: ìµœëŒ€ ë ˆì½”ë“œ ìˆ˜({max_records}) ë„ë‹¬, ì¡°ê¸° ì¢…ë£Œ")
                        break
                    record_count += 1
                    value = record.get_value()
                    
                    # ê°’ì´ Noneì´ ì•„ë‹Œì§€ í™•ì¸
                    if value is not None:
                        try:
                            # ìˆ«ìë¡œ ë³€í™˜ ì‹œë„
                            float_value = float(value)
                            # NaNì´ë‚˜ Infinityê°€ ì•„ë‹Œì§€ í™•ì¸
                            if not (float('nan') == float_value or float('inf') == abs(float_value)):
                                data.append({
                                    '_time': record.get_time(),
                                    '_value': float_value
                                })
                                valid_value_count += 1
                            else:
                                invalid_value_count += 1
                                logger.debug(f"{field_name}: NaN/Infinity ê°’ ë¬´ì‹œ: {value}")
                        except (ValueError, TypeError) as ve:
                            invalid_value_count += 1
                            logger.warning(f"{field_name}: ê°’ ë³€í™˜ ì‹¤íŒ¨ (ë¬´ì‹œ): {value} (íƒ€ì…: {type(value)}), ì˜¤ë¥˜: {ve}")
                            continue
                    else:
                        invalid_value_count += 1
                if len(data) >= max_records:
                    break
            
            # ì¿¼ë¦¬ ê²°ê³¼ ìƒì„¸ ë¡œê¹…
            logger.info(f"   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
            logger.info(f"   âœ… {field_name}: ì¿¼ë¦¬ ì‹¤í–‰ ì™„ë£Œ")
            logger.info(f"   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
            logger.info(f"   í…Œì´ë¸” ê°œìˆ˜: {table_count}ê°œ")
            logger.info(f"   ì „ì²´ ë ˆì½”ë“œ: {record_count}ê°œ")
            logger.info(f"   ìœ íš¨ ê°’: {valid_value_count}ê°œ")
            logger.info(f"   ë¬´íš¨ ê°’: {invalid_value_count}ê°œ")
            logger.info(f"   ìµœì¢… ë°ì´í„° í¬ì¸íŠ¸: {len(data)}ê°œ")
            if valid_value_count == 0:
                logger.warning(f"   âš ï¸ {field_name}: ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
            
            # ë°ì´í„°ê°€ ìˆì„ ë•Œ ìƒ˜í”Œ ê°’ ì¶œë ¥
            if len(data) > 0:
                logger.debug(f"   ğŸ“Š ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):")
                for i, item in enumerate(data[:3], 1):
                    logger.debug(f"      {i}. ì‹œê°„: {item['_time']}, ê°’: {item['_value']} (íƒ€ì…: {type(item['_value']).__name__})")
            else:
                logger.warning(f"   âš ï¸ ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
            
            # ë¹ˆ ë°°ì—´ê³¼ 0 ê°’ êµ¬ë¶„
            if not data:
                logger.warning(
                    f"âš ï¸ {field_name}: ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ (ë¹ˆ ë°°ì—´).\n"
                    f"   ê¸°ê°„: {start_rfc3339} ~ {end_rfc3339}\n"
                    f"   í•„í„°: {device_filter if device_filter else 'ì—†ìŒ (ëª¨ë“  ë°ì´í„°)'}\n"
                    f"   measurement: {measurement}\n"
                    f"   field: {field_name}\n"
                    f"   í…Œì´ë¸”: {table_count}ê°œ, ë ˆì½”ë“œ: {record_count}ê°œ\n"
                    f"   ìœ íš¨ ê°’: {valid_value_count}ê°œ, ë¬´íš¨ ê°’: {invalid_value_count}ê°œ"
                )
                
                # ë°ì´í„°ê°€ ì—†ì„ ë•Œ ê°€ëŠ¥í•œ ì›ì¸ ì§„ë‹¨
                if record_count > 0 and valid_value_count == 0:
                    logger.warning(
                        f"   ğŸ’¡ ì§„ë‹¨: ë ˆì½”ë“œëŠ” ìˆì§€ë§Œ ìœ íš¨ ê°’ì´ ì—†ìŠµë‹ˆë‹¤.\n"
                        f"      â†’ ë°ì´í„° íƒ€ì… ë³€í™˜ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
                        f"      â†’ InfluxDBì—ì„œ ê°’ì´ ë¬¸ìì—´ë¡œ ì €ì¥ë˜ì—ˆì„ ê°€ëŠ¥ì„±."
                    )
                elif record_count == 0:
                    logger.warning(
                        f"   ğŸ’¡ ì§„ë‹¨: ë ˆì½”ë“œ ìì²´ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
                        f"      â†’ í•´ë‹¹ ê¸°ê°„ì— ë°ì´í„°ê°€ ì—†ê±°ë‚˜\n"
                        f"      â†’ measurement/field ì´ë¦„ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
                        f"      â†’ ì‹œê°„ ë²”ìœ„ë¥¼ í™•ì¸í•˜ì„¸ìš”."
                    )
                # í•„í„° ì—†ì´ ì¬ì‹œë„í•˜ì—¬ ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                if device_filter:
                    logger.info(f"{field_name}: í•„í„° ì—†ì´ ì¬ì‹œë„í•˜ì—¬ ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸...")
                    try:
                        query_no_filter = f'''
                        from(bucket: "{self.bucket}")
                          |> range(start: {start_rfc3339}, stop: {end_rfc3339})
                          |> filter(fn: (r) => r["_measurement"] == "{measurement}")
                          |> filter(fn: (r) => r["_field"] == "{field_name}")
                          |> group()
                          |> aggregateWindow(every: 30m, fn: mean, createEmpty: false)
                          |> limit(n: 1)
                        '''
                        test_result = self.influx_client.query_api.query(query=query_no_filter, org=self.org)
                        test_count = sum(1 for table in test_result for _ in table.records)
                        if test_count > 0:
                            logger.warning(f"{field_name}: âš ï¸ í•„í„° ì—†ì´ëŠ” ë°ì´í„°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤! device_filterê°€ ì˜ëª»ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                        else:
                            logger.warning(f"{field_name}: í•„í„° ì—†ì´ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í•´ë‹¹ ê¸°ê°„ì— ë°ì´í„°ê°€ ì—†ê±°ë‚˜ í•„ë“œëª…ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    except Exception as test_e:
                        logger.debug(f"{field_name}: í•„í„° ì—†ì´ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {test_e}")
                return None
            
            if not PANDAS_AVAILABLE or pd is None:
                logger.error("pandasê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
                return None
            
            try:
                df = pd.DataFrame(data)
                df['_time'] = pd.to_datetime(df['_time'])
                df = df.sort_values('_time')
                logger.debug(f"{field_name}: DataFrame ìƒì„± ì™„ë£Œ ({len(df)}í–‰)")
                return df
            except Exception as df_error:
                logger.error(f"{field_name}: DataFrame ìƒì„± ì‹¤íŒ¨: {df_error}")
                return None
            
        except Exception as e:
            logger.warning(f"Raw ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨ ({field_name}): {e}", exc_info=True)
            return None
    
    def _calculate_sensor_stats_from_raw(
        self,
        start_rfc3339: str,
        end_rfc3339: str,
        field_name: str,
        device_filter: Optional[str] = None,
        measurement: str = "moby_sensors"
    ) -> Dict[str, float]:
        """
        Raw ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ pandasë¡œ ì •ë°€ í†µê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Returns:
            {"mean": float, "min": float, "max": float, "std": float, "p95": float}
            ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ëª¨ë‘ 0.0
        """
        df = self._fetch_raw_data_as_dataframe(
            start_rfc3339=start_rfc3339,
            end_rfc3339=end_rfc3339,
            field_name=field_name,
            device_filter=device_filter,
            measurement=measurement
        )
        
        if df is None or len(df) == 0:
            logger.warning(
                f"{field_name}: âš ï¸ ë°ì´í„° ì—†ìŒ - ê¸°ë³¸ê°’ ë°˜í™˜\n"
                f"   ê¸°ê°„: {start_rfc3339} ~ {end_rfc3339}\n"
                f"   í•„í„°: {device_filter if device_filter else 'ì—†ìŒ'}\n"
                f"   measurement: {measurement}\n"
                f"   field: {field_name}"
            )
            
            # í•„í„° ì—†ì´ ì¬ì‹œë„
            if device_filter:
                logger.info(f"{field_name}: í•„í„° ì—†ì´ ì¬ì‹œë„...")
                try:
                    df_retry = self._fetch_raw_data_as_dataframe(
                        start_rfc3339=start_rfc3339,
                        end_rfc3339=end_rfc3339,
                        field_name=field_name,
                        device_filter=None,
                        measurement=measurement
                    )
                    if df_retry is not None and len(df_retry) > 0:
                        logger.info(f"{field_name}: âœ… í•„í„° ì—†ì´ ì¬ì‹œë„ ì„±ê³µ! ({len(df_retry)}ê°œ ë°ì´í„°)")
                        df = df_retry
                    else:
                        logger.warning(f"{field_name}: í•„í„° ì—†ì´ë„ ë°ì´í„° ì—†ìŒ")
                except Exception as retry_e:
                    logger.warning(f"{field_name}: í•„í„° ì—†ì´ ì¬ì‹œë„ ì‹¤íŒ¨: {retry_e}")
            
            # ì—¬ì „íˆ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ê³¼ 0 ê°’ êµ¬ë¶„ì„ ëª…í™•íˆ
            if df is None or len(df) == 0:
                logger.error(
                    f"{field_name}: âŒ ìµœì¢…ì ìœ¼ë¡œ ë°ì´í„° ì—†ìŒ - ë¹ˆ ë°°ì—´ ë°˜í™˜ (0.0 ê¸°ë³¸ê°’ ì‚¬ìš©)\n"
                    f"   âš ï¸ ì£¼ì˜: ì´ëŠ” 'ë°ì´í„°ê°€ ì—†ìŒ'ì„ ì˜ë¯¸í•˜ë©°, ì‹¤ì œ ì„¼ì„œ ê°’ì´ 0ì¸ ê²ƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤.\n"
                    f"   ğŸ’¡ í•´ê²° ë°©ë²•:\n"
                    f"      1. InfluxDBì— í•´ë‹¹ ê¸°ê°„ì˜ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸\n"
                    f"      2. measurement ì´ë¦„ í™•ì¸: {measurement}\n"
                    f"      3. field ì´ë¦„ í™•ì¸: {field_name}\n"
                    f"      4. ì‹œê°„ ë²”ìœ„ í™•ì¸: {start_rfc3339} ~ {end_rfc3339}\n"
                    f"      5. ì•ŒëŒ ë°ì´í„°ì—ëŠ” ê°’ì´ ìˆë‹¤ë©´ ì‹œê°„ ë²”ìœ„ë‚˜ í•„í„° ë¬¸ì œì¼ ìˆ˜ ìˆìŒ"
                )
                return {
                    "mean": 0.0,
                    "min": 0.0,
                    "max": 0.0,
                    "std": 0.0,
                    "p95": 0.0
                }
        
        # ë°ì´í„° íƒ€ì… í™•ì¸ ë° ë³€í™˜
        if '_value' not in df.columns:
            logger.error(f"{field_name}: '_value' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ì»¬ëŸ¼: {df.columns.tolist()}")
            return {
                "mean": 0.0,
                "min": 0.0,
                "max": 0.0,
                "std": 0.0,
                "p95": 0.0
            }
        
        # ìˆ«ì íƒ€ì…ìœ¼ë¡œ ê°•ì œ ë³€í™˜ (ë°ì´í„° íƒ€ì… ë¬¸ì œ í•´ê²°)
        logger.info(f"   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        logger.debug(f"   ğŸ“Š {field_name}: í†µê³„ ê³„ì‚° ì‹œì‘")
        logger.debug(f"   DataFrame í¬ê¸°: {len(df)}í–‰ x {len(df.columns)}ì—´")
        logger.debug(f"   ì»¬ëŸ¼ ëª©ë¡: {df.columns.tolist()}")
        logger.debug(f"   '_value' ì»¬ëŸ¼ ë°ì´í„° íƒ€ì… (ë³€í™˜ ì „): {df['_value'].dtype}")
        logger.debug(f"   '_value' ì»¬ëŸ¼ ìƒ˜í”Œ (ë³€í™˜ ì „): {df['_value'].head(5).tolist()}")
        
        # ìˆ«ì íƒ€ì…ìœ¼ë¡œ ê°•ì œ ë³€í™˜ (ë¬¸ìì—´ì´ì–´ë„ ìˆ«ìë¡œ ë³€í™˜)
        try:
            # pd.to_numericì€ ë¬¸ìì—´ë„ ìˆ«ìë¡œ ë³€í™˜ ê°€ëŠ¥
            df['_value'] = pd.to_numeric(df['_value'], errors='coerce')
            logger.debug(f"   '_value' ì»¬ëŸ¼ ë°ì´í„° íƒ€ì… (ë³€í™˜ í›„): {df['_value'].dtype}")
            logger.debug(f"   '_value' ì»¬ëŸ¼ ìƒ˜í”Œ (ë³€í™˜ í›„): {df['_value'].head(5).tolist()}")
        except Exception as e:
            logger.error(f"{field_name}: ìˆ«ì ë³€í™˜ ì‹¤íŒ¨: {e}")
            logger.error(f"   ì›ë³¸ ë°ì´í„° íƒ€ì…: {df['_value'].dtype}")
            logger.error(f"   ì›ë³¸ ìƒ˜í”Œ: {df['_value'].head(5).tolist()}")
            return {
                "mean": 0.0,
                "min": 0.0,
                "max": 0.0,
                "std": 0.0,
                "p95": 0.0
            }
        
        # NaN ì œê±°
        values = df['_value'].dropna()
        
        logger.info(f"   NaN ì œê±° ì „: {len(df)}ê°œ, NaN ì œê±° í›„: {len(values)}ê°œ")
        
        # ë°ì´í„°ê°€ ì—†ì„ ë•Œì™€ 0 ê°’ êµ¬ë¶„
        if len(values) == 0:
            logger.error(f"   âŒ {field_name}: ìœ íš¨í•œ ë°ì´í„° í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤!")
            logger.error(f"   DataFrame ê¸¸ì´: {len(df)}")
            logger.error(f"   NaN ê°œìˆ˜: {df['_value'].isna().sum()}")
            if len(df) > 0:
                logger.error(f"   DataFrame ìƒ˜í”Œ (ì²˜ìŒ 5ê°œ):")
                for idx, row in df.head(5).iterrows():
                    logger.error(f"      ì¸ë±ìŠ¤ {idx}: _time={row['_time']}, _value={row['_value']} (íƒ€ì…: {type(row['_value']).__name__})")
            return {
                "mean": 0.0,
                "min": 0.0,
                "max": 0.0,
                "std": 0.0,
                "p95": 0.0
            }
        
        # í†µê³„ ê³„ì‚° (ì•ˆì „í•˜ê²Œ)
        try:
            logger.info(f"   ğŸ“Š {field_name}: í†µê³„ ê³„ì‚° ì‹œì‘ (ë°ì´í„° í¬ì¸íŠ¸: {len(values)}ê°œ)")
            
            # ê°’ì´ ëª¨ë‘ ìˆ«ìì¸ì§€ í™•ì¸
            if not values.dtype in ['float64', 'int64', 'float32', 'int32']:
                logger.warning(f"   âš ï¸ ë°ì´í„° íƒ€ì…ì´ ìˆ«ìê°€ ì•„ë‹™ë‹ˆë‹¤: {values.dtype}")
                logger.warning(f"   ìƒ˜í”Œ ê°’: {values.head(10).tolist()}")
            
            # ë°ì´í„° í¬ì¸íŠ¸ê°€ 1ê°œì¸ ê²½ìš° ê²½ê³  ë° ì²˜ë¦¬
            if len(values) == 1:
                logger.warning(f"   âš ï¸ {field_name}: ë°ì´í„° í¬ì¸íŠ¸ê°€ 1ê°œë¿ì…ë‹ˆë‹¤. Std/P95 ê³„ì‚° ë¶ˆê°€ (ì •ìƒ ë™ì‘).")
                single_value = float(values.iloc[0]) if hasattr(values, 'iloc') else float(values[0])
                stats = {
                    "mean": single_value,
                    "min": single_value,
                    "max": single_value,
                    "std": 0.0,  # ë°ì´í„° í¬ì¸íŠ¸ 1ê°œì´ë¯€ë¡œ í‘œì¤€í¸ì°¨ëŠ” 0
                    "p95": single_value  # ë°ì´í„° í¬ì¸íŠ¸ 1ê°œì´ë¯€ë¡œ P95ëŠ” ê·¸ ê°’ ìì²´
                }
                logger.info(f"   âœ… í†µê³„ (ë‹¨ì¼ ê°’): mean={stats['mean']:.4f}, min={stats['min']:.4f}, max={stats['max']:.4f}, std={stats['std']:.4f}, p95={stats['p95']:.4f}")
            else:
                # ì—¬ëŸ¬ ë°ì´í„° í¬ì¸íŠ¸ê°€ ìˆëŠ” ê²½ìš° ì •ìƒ ê³„ì‚°
                # í†µê³„ ê³„ì‚° (numpy ì‚¬ìš©)
                if PANDAS_AVAILABLE and np is not None:
                    # numpyë¥¼ ì‚¬ìš©í•œ ì •í™•í•œ í†µê³„ ê³„ì‚°
                    values_array = values.values if hasattr(values, 'values') else values.to_numpy()
                    stats = {
                        "mean": float(np.mean(values_array)) if len(values_array) > 0 else 0.0,
                        "min": float(np.min(values_array)) if len(values_array) > 0 else 0.0,
                        "max": float(np.max(values_array)) if len(values_array) > 0 else 0.0,
                        "std": float(np.std(values_array)) if len(values_array) > 1 else 0.0,
                        "p95": float(np.percentile(values_array, 95)) if len(values_array) > 0 else 0.0
                    }
                else:
                    # pandas fallback (numpyê°€ ì—†ëŠ” ê²½ìš°)
                    stats = {
                        "mean": float(values.mean()) if len(values) > 0 else 0.0,
                        "min": float(values.min()) if len(values) > 0 else 0.0,
                        "max": float(values.max()) if len(values) > 0 else 0.0,
                        "std": float(values.std()) if len(values) > 1 else 0.0,
                        "p95": float(values.quantile(0.95)) if len(values) > 0 else 0.0
                    }
                
                logger.info(f"   âœ… í†µê³„ ê³„ì‚° ì™„ë£Œ:")
                logger.info(f"      Mean: {stats['mean']:.4f}, Min: {stats['min']:.4f}, Max: {stats['max']:.4f}, Std: {stats['std']:.4f}, P95: {stats['p95']:.4f}")
                logger.info(f"      ë°ì´í„° í¬ì¸íŠ¸: {len(values)}ê°œ, ê°’ ë²”ìœ„: {float(values.min()):.4f} ~ {float(values.max()):.4f}")
            
            # ë¡œê·¸ëŠ” ìœ„ì—ì„œ ì´ë¯¸ ì¶œë ¥ë¨ (ë‹¨ì¼ ê°’ì¸ ê²½ìš°ì™€ ì—¬ëŸ¬ ê°’ì¸ ê²½ìš° ëª¨ë‘)
            
            # í†µê³„ ê°’ì´ ëª¨ë‘ 0ì¸ì§€ í™•ì¸
            if all(v == 0.0 for v in stats.values()):
                logger.warning(f"   âš ï¸ ëª¨ë“  í†µê³„ ê°’ì´ 0.0ì…ë‹ˆë‹¤!")
                logger.warning(f"   ê°’ ê°œìˆ˜: {len(values)}")
                logger.warning(f"   ìƒ˜í”Œ ê°’: {values.head(10).tolist()}")
                logger.warning(f"   ê°’ ë²”ìœ„: {values.min()} ~ {values.max()}")
                logger.warning(f"   â†’ ì‹¤ì œ ë°ì´í„° ê°’ì´ ëª¨ë‘ 0ì¸ì§€, ì•„ë‹ˆë©´ ì¡°íšŒ ë¬¸ì œì¸ì§€ í™•ì¸ í•„ìš”")
            else:
                logger.info(f"   âœ… í†µê³„ ê°’ì´ ì •ìƒì ìœ¼ë¡œ ê³„ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤")
            
            return stats
        except Exception as e:
            logger.error(f"{field_name} í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {
                "mean": 0.0,
                "min": 0.0,
                "max": 0.0,
                "std": 0.0,
                "p95": 0.0
            }
    
    def _calculate_vibration_stats_from_raw(
        self,
        start_rfc3339: str,
        end_rfc3339: str,
        device_filter: Optional[str] = None,
        measurement: str = "moby_sensors"
    ) -> Dict[str, Dict[str, float]]:
        """
        ì§„ë™ ì„¼ì„œì˜ Raw ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ì •ë°€ í†µê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        InfluxDB í•„ë“œëª…: fields_vibration_raw
        ë³´ê³ ì„œ í˜•ì‹ì— ë§ì¶° x, y, z ì¶• êµ¬ì¡°ë¡œ ë°˜í™˜í•˜ì§€ë§Œ, ì‹¤ì œë¡œëŠ” ë‹¨ì¼ ì§„ë™ ê°’ì…ë‹ˆë‹¤.
        
        Returns:
            {
                "x": {"mean": float, "peak": float, "rms": float},
                "y": {"mean": float, "peak": float, "rms": float},
                "z": {"mean": float, "peak": float, "rms": float}
            }
        """
        # InfluxDB í•„ë“œëª…: fields_vibration_raw (ë‹¨ì¼ í•„ë“œëª…ë§Œ ì‚¬ìš©)
        field_names = ["fields_vibration_raw"]
        df = None
        successful_field = None
        
        logger.info(f"ğŸ” ì§„ë™ ë°ì´í„° ì¡°íšŒ ì‹œì‘ (ì´ {len(field_names)}ê°œ í•„ë“œëª… ì‹œë„)")
        logger.info(f"   ì¡°íšŒ ê¸°ê°„: {start_rfc3339} ~ {end_rfc3339}")
        logger.info(f"   í•„í„°: {device_filter if device_filter else 'ì—†ìŒ (ëª¨ë“  ë°ì´í„°)'}")
        
        for idx, field_name in enumerate(field_names, 1):
            logger.info(f"   [{idx}/{len(field_names)}] ì§„ë™ í•„ë“œ ì‹œë„: {field_name}")
            try:
                # ì§„ë™ ë°ì´í„° ì¡°íšŒ
                df = self._fetch_raw_data_as_dataframe(
                    start_rfc3339=start_rfc3339,
                    end_rfc3339=end_rfc3339,
                    field_name=field_name,
                    device_filter=device_filter,
                    measurement=measurement
                )
                
                if df is not None and len(df) > 0:
                    successful_field = field_name
                    logger.info(f"   âœ… ì§„ë™ ë°ì´í„° ë°œê²¬: {field_name} ({len(df)}ê°œ ë°ì´í„° í¬ì¸íŠ¸)")
                    # ë°ì´í„° ìƒ˜í”Œ ë¡œê¹…
                    if len(df) > 0:
                        sample_values = df['_value'].head(5).tolist()
                        logger.info(f"   ğŸ“Š ë°ì´í„° ìƒ˜í”Œ: {sample_values}")
                    break
                else:
                    logger.warning(f"   âŒ {field_name}: ë°ì´í„° ì—†ìŒ (df={df is not None}, len={len(df) if df is not None else 0})")
            except Exception as e:
                logger.warning(f"   âš ï¸ {field_name} ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        # ëª¨ë“  í•„ë“œ ì‹œë„ í›„ì—ë„ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ í•„í„° ì—†ì´ ì¬ì‹œë„
        if df is None or len(df) == 0:
            logger.warning(f"   âš ï¸ ëª¨ë“  í•„ë“œëª… ì‹œë„ ì‹¤íŒ¨, í•„í„° ì—†ì´ ì¬ì‹œë„...")
            for idx, field_name in enumerate(field_names, 1):
                logger.info(f"   [{idx}/{len(field_names)}] í•„í„° ì—†ì´ ì¬ì‹œë„: {field_name}")
                try:
                    df = self._fetch_raw_data_as_dataframe(
                        start_rfc3339=start_rfc3339,
                        end_rfc3339=end_rfc3339,
                        field_name=field_name,
                        device_filter=None,
                        measurement=measurement
                    )
                    if df is not None and len(df) > 0:
                        successful_field = field_name
                        logger.info(f"   âœ… ì§„ë™: í•„í„° ì—†ì´ ì¡°íšŒ ì„±ê³µ ({field_name}, {len(df)}ê°œ ë°ì´í„°)")
                        # ë°ì´í„° ìƒ˜í”Œ ë¡œê¹…
                        if len(df) > 0:
                            sample_values = df['_value'].head(5).tolist()
                            logger.info(f"   ğŸ“Š ë°ì´í„° ìƒ˜í”Œ: {sample_values}")
                        break
                    else:
                        logger.warning(f"   âŒ í•„í„° ì—†ì´ë„ {field_name}: ë°ì´í„° ì—†ìŒ")
                except Exception as e:
                    logger.warning(f"   âš ï¸ í•„í„° ì—†ì´ ì¬ì‹œë„ ì‹¤íŒ¨ ({field_name}): {e}")
        
        if successful_field:
            logger.info(f"   âœ… ìµœì¢… ì‚¬ìš© í•„ë“œ: {successful_field}")
        else:
            logger.warning(f"   âŒ ëª¨ë“  ì§„ë™ í•„ë“œëª… ì‹œë„ ì‹¤íŒ¨. ì‚¬ìš© ê°€ëŠ¥í•œ í•„ë“œëª…ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ê¸°ë³¸ê°’ ì´ˆê¸°í™”
        default_stats = {
            "mean": 0.0,
            "peak": 0.0,
            "rms": 0.0
        }
        
        if df is None or len(df) == 0:
            logger.debug(f"ì§„ë™: ë°ì´í„° ì—†ìŒ, ê¸°ë³¸ê°’ ë°˜í™˜")
            return {
                "x": default_stats.copy(),
                "y": default_stats.copy(),
                "z": default_stats.copy()
            }
        
        values = df['_value'].dropna()
        
        if len(values) == 0:
            logger.warning(f"ì§„ë™: ìœ íš¨í•œ ë°ì´í„° í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {
                "x": default_stats.copy(),
                "y": default_stats.copy(),
                "z": default_stats.copy()
            }
        
        # í†µê³„ ê³„ì‚° (ë‹¨ì¼ ì§„ë™ ê°’ì— ëŒ€í•´)
        try:
            logger.info(f"   ğŸ“Š ì§„ë™ í†µê³„ ê³„ì‚° ì‹œì‘ (ë°ì´í„° í¬ì¸íŠ¸: {len(values)}ê°œ)")
            
            if len(values) == 0:
                logger.warning(f"   âš ï¸ ì§„ë™: ìœ íš¨í•œ ë°ì´í„° í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return {
                    "x": default_stats.copy(),
                    "y": default_stats.copy(),
                    "z": default_stats.copy()
                }
            
            # ë°ì´í„° í¬ì¸íŠ¸ê°€ 1ê°œì¸ ê²½ìš° ê²½ê³ 
            if len(values) == 1:
                logger.warning(f"   âš ï¸ ì§„ë™: ë°ì´í„° í¬ì¸íŠ¸ê°€ 1ê°œë¿ì…ë‹ˆë‹¤. í‘œì¤€í¸ì°¨ ê³„ì‚° ë¶ˆê°€.")
                single_value = float(values.iloc[0]) if hasattr(values, 'iloc') else float(values[0])
                stats = {
                    "mean": single_value,
                    "peak": abs(single_value),
                    "rms": abs(single_value)
                }
                logger.info(f"   âœ… ì§„ë™ í†µê³„ (ë‹¨ì¼ ê°’): mean={stats['mean']:.4f}, peak={stats['peak']:.4f}, rms={stats['rms']:.4f}")
            else:
                # ì—¬ëŸ¬ ë°ì´í„° í¬ì¸íŠ¸ê°€ ìˆëŠ” ê²½ìš° ì •ìƒ ê³„ì‚°
                mean_val = float(values.mean()) if len(values) > 0 else 0.0
                
                # peak ê³„ì‚° (ì ˆëŒ“ê°’ ìµœëŒ€)
                abs_values = values.abs()
                peak_val = float(abs_values.max()) if len(abs_values) > 0 else 0.0
                
                # RMS ê³„ì‚° (Root Mean Square)
                if not PANDAS_AVAILABLE or np is None:
                    rms_val = 0.0
                else:
                    if len(values) > 0:
                        rms_val = float(np.sqrt((values ** 2).mean()))
                    else:
                        rms_val = 0.0
                
                stats = {
                    "mean": mean_val,
                    "peak": peak_val,
                    "rms": rms_val
                }
                
                logger.info(f"   âœ… ì§„ë™ í†µê³„ ê³„ì‚° ì™„ë£Œ:")
                logger.info(f"      Mean: {mean_val:.4f}, Peak: {peak_val:.4f}, RMS: {rms_val:.4f}")
                logger.info(f"      ë°ì´í„° í¬ì¸íŠ¸: {len(values)}ê°œ, ê°’ ë²”ìœ„: {float(values.min()):.4f} ~ {float(values.max()):.4f}")
            
            # ë³´ê³ ì„œ í˜•ì‹ì— ë§ì¶° x, y, z ì¶• ëª¨ë‘ ë™ì¼í•œ ê°’ìœ¼ë¡œ ë°˜í™˜
            # (ì‹¤ì œë¡œëŠ” ë‹¨ì¼ ì§„ë™ ê°’ì´ì§€ë§Œ, ë³´ê³ ì„œ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´)
            return {
                "x": stats.copy(),
                "y": stats.copy(),
                "z": stats.copy()
            }
            
        except Exception as e:
            logger.error(f"ì§„ë™ í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {e}", exc_info=True)
            return {
                "x": default_stats.copy(),
                "y": default_stats.copy(),
                "z": default_stats.copy()
            }
    
    def _calculate_axis_stats_from_raw(
        self,
        start_rfc3339: str,
        end_rfc3339: str,
        field_names: List[str],  # ["accel_x", "accel_y", "accel_z"] ë˜ëŠ” ["gyro_x", "gyro_y", "gyro_z"]
        device_filter: Optional[str] = None,
        measurement: str = "moby_sensors"
    ) -> Dict[str, Dict[str, float]]:
        """
        ì¶•ë³„ ì„¼ì„œ ë°ì´í„°(ê°€ì†ë„, ìì´ë¡œ ë“±)ì˜ í†µê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Args:
            field_names: ì¶•ë³„ í•„ë“œëª… ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["accel_x", "accel_y", "accel_z"] ë˜ëŠ” ["gyro_x", "gyro_y", "gyro_z"])
        
        Returns:
            {
                "x": {"mean": float, "min": float, "max": float, "std": float, "p95": float},
                "y": {"mean": float, "min": float, "max": float, "std": float, "p95": float},
                "z": {"mean": float, "min": float, "max": float, "std": float, "p95": float}
            }
        """
        axis_map = {"x": 0, "y": 1, "z": 2}
        result = {}
        
        for axis, idx in axis_map.items():
            if idx >= len(field_names):
                logger.warning(f"ì¶• {axis}ì— ëŒ€í•œ í•„ë“œëª…ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ ì‚¬ìš©.")
                result[axis] = {"mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0}
                continue
            
            field_name = field_names[idx]
            try:
                stats = self._calculate_sensor_stats_from_raw(
                    start_rfc3339, end_rfc3339, field_name, device_filter, measurement
                )
                result[axis] = stats
            except Exception as e:
                logger.error(f"ì¶• {axis} ({field_name}) í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {e}")
                result[axis] = {"mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0}
        
        return result
    
    def _get_default_sensor_stats(self) -> Dict[str, Any]:
        """
        ë°ì´í„°ê°€ ì—†ì„ ë•Œ ê¸°ë³¸ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        ëª¨ë“  ê°’ì€ 0.0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ í…Œì´ë¸”ì´ ê¹¨ì§€ì§€ ì•Šê²Œ í•©ë‹ˆë‹¤.
        """
        return {
            "temperature": {
                "mean": 0.0,
                "min": 0.0,
                "max": 0.0,
                "std": 0.0,
                "p95": 0.0
            },
            "humidity": {
                "mean": 0.0,
                "min": 0.0,
                "max": 0.0,
                "std": 0.0,
                "p95": 0.0
            },
            "vibration": {
                "x": {"mean": 0.0, "peak": 0.0, "rms": 0.0},
                "y": {"mean": 0.0, "peak": 0.0, "rms": 0.0},
                "z": {"mean": 0.0, "peak": 0.0, "rms": 0.0}
            },
            "sound": {
                "mean": 0.0,
                "min": 0.0,
                "max": 0.0,
                "std": 0.0,
                "p95": 0.0
            },
            "acceleration": {
                "x": {"mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0},
                "y": {"mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0},
                "z": {"mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0}
            },
            "gyro": {
                "x": {"mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0},
                "y": {"mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0},
                "z": {"mean": 0.0, "min": 0.0, "max": 0.0, "std": 0.0, "p95": 0.0}
            },
            "pressure": {
                "mean": 0.0,
                "min": 0.0,
                "max": 0.0,
                "std": 0.0,
                "p95": 0.0
            }
        }
    
    def _fetch_alarms(
        self,
        db: Session,
        start_time: datetime,
        end_time: datetime,
        equipment_id: str
    ) -> List[Dict[str, Any]]:
        """ì•ŒëŒ ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
        try:
            # DBì—ì„œ ì•ŒëŒ ì¡°íšŒ
            all_alerts = get_latest_alerts(
                db=db,
                limit=1000,
                sensor_id=None,
                level=None
            )
            
            # ê¸°ê°„ ë° ì„¤ë¹„ í•„í„°ë§
            filtered_alarms = []
            for alert in all_alerts:
                # AlertëŠ” SQLAlchemy ëª¨ë¸ ê°ì²´ì´ë¯€ë¡œ ì†ì„±ìœ¼ë¡œ ì ‘ê·¼
                alert_time = getattr(alert, 'ts', None) or getattr(alert, 'timestamp', None)
                if alert_time:
                    try:
                        if isinstance(alert_time, str):
                            alert_dt = datetime.fromisoformat(alert_time.replace("Z", "+00:00"))
                        else:
                            alert_dt = alert_time
                            # timezone-awareë¡œ ë³€í™˜
                            if alert_dt.tzinfo is None:
                                alert_dt = alert_dt.replace(tzinfo=timezone.utc)
                        
                        if start_time <= alert_dt <= end_time:
                            device = getattr(alert, 'sensor_id', None) or getattr(alert, 'device_id', "") or ""
                            if equipment_id.lower() in device.lower() or device.lower() in equipment_id.lower() or not device:
                                # detailsì—ì„œ valueì™€ threshold ì¶”ì¶œ ì‹œë„
                                details = getattr(alert, 'details', None)
                                if isinstance(details, dict):
                                    value = details.get('value', 0.0)
                                    threshold = details.get('threshold', 0.0)
                                else:
                                    value = 0.0
                                    threshold = 0.0
                                
                                filtered_alarms.append({
                                    "timestamp": alert_dt.isoformat() if hasattr(alert_dt, 'isoformat') else str(alert_dt),
                                    "sensor": device or equipment_id,
                                    "severity": getattr(alert, 'level', 'unknown'),
                                    "value": value,
                                    "threshold": threshold,
                                    "message": getattr(alert, 'message', 'ì•ŒëŒ ë°œìƒ')
                                })
                    except Exception as e:
                        logger.debug(f"ì•ŒëŒ ì‹œê°„ íŒŒì‹± ì‹¤íŒ¨: {e}")
                        continue
            
            if not filtered_alarms:
                # ë”ë¯¸ ë°ì´í„° ìƒì„± (ê¸°ê°„ì— ë”°ë¼ ê°€ë³€)
                filtered_alarms = self._generate_dummy_alarms(start_time, end_time, equipment_id)
            
            return filtered_alarms
            
        except Exception as e:
            logger.exception(f"ì•ŒëŒ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return self._generate_dummy_alarms(start_time, end_time, equipment_id)
    
    def _fetch_mlp_anomalies(
        self,
        db: Session,
        start_time: datetime,
        end_time: datetime,
        equipment_id: str
    ) -> List[Dict[str, Any]]:
        """MLP ì´ìƒ íƒì§€ ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
        try:
            # ì‹¤ì œ DB ì¡°íšŒ ë¡œì§ (í˜„ì¬ëŠ” ë”ë¯¸ ë°ì´í„°)
            return self._generate_dummy_mlp_anomalies(start_time, end_time, equipment_id)
        except Exception as e:
            logger.exception(f"MLP ì´ìƒ íƒì§€ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def _fetch_if_anomalies(
        self,
        db: Session,
        start_time: datetime,
        end_time: datetime,
        equipment_id: str
    ) -> List[Dict[str, Any]]:
        """Isolation Forest ì´ìƒ íƒì§€ ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
        try:
            # ì‹¤ì œ DB ì¡°íšŒ ë¡œì§ (í˜„ì¬ëŠ” ë”ë¯¸ ë°ì´í„°)
            return self._generate_dummy_if_anomalies(start_time, end_time, equipment_id)
        except Exception as e:
            logger.exception(f"IF ì´ìƒ íƒì§€ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def _calculate_correlations(
        self,
        start_time: datetime,
        end_time: datetime,
        equipment_id: str
    ) -> Dict[str, float]:
        """ì„¼ì„œ ê°„ ìƒê´€ê³„ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        try:
            if not PANDAS_AVAILABLE:
                logger.warning("pandasê°€ ì—†ì–´ì„œ ìƒê´€ê³„ìˆ˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return {"temperature_vibration": 0.0, "vibration_sound": 0.0, "temperature_humidity": 0.0}
            
            # ì‹œê°„ ë²”ìœ„ ë³€í™˜
            if start_time.tzinfo is None:
                start_time = start_time.replace(tzinfo=timezone.utc)
            if end_time.tzinfo is None:
                end_time = end_time.replace(tzinfo=timezone.utc)
            
            start_rfc3339 = start_time.astimezone(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")
            end_rfc3339 = end_time.astimezone(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")
            
            # device_filter ì„¤ì •
            # ì£¼ì˜: equipment_idëŠ” ì„¤ë¹„ëª…("ì»¨ë² ì´ì–´ ë²¨íŠ¸ #1")ì¼ ìˆ˜ ìˆê³ , device_idëŠ” ì‹¤ì œ ë””ë°”ì´ìŠ¤ IDì…ë‹ˆë‹¤.
            # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë³´ë‚´ëŠ” equipment_idì™€ ì‹¤ì œ InfluxDBì˜ device_id íƒœê·¸ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ,
            # ì„¼ì„œ í†µê³„ ê³„ì‚°ê³¼ ë™ì¼í•˜ê²Œ í•„í„° ì—†ì´ ëª¨ë“  ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
            # ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œëŠ” equipment_id -> device_id ë§¤í•‘ í…Œì´ë¸”ì´ í•„ìš”í•©ë‹ˆë‹¤.
            device_filter = None
            
            # TODO: equipment_id -> device_id ë§¤í•‘ ë¡œì§ ì¶”ê°€ í•„ìš”
            # í˜„ì¬ëŠ” í•„í„° ì—†ì´ ëª¨ë“  ë°ì´í„° ì¡°íšŒí•˜ì—¬ ìƒê´€ê³„ìˆ˜ ê³„ì‚°
            # equipment_idëŠ” ì„¤ë¹„ëª…ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ device_id í•„í„°ë¥¼ ì ìš©í•˜ì§€ ì•ŠìŒ
            logger.info(f"ğŸ“Š ìƒê´€ê³„ìˆ˜ ê³„ì‚° ì‹œì‘: {start_rfc3339} ~ {end_rfc3339}")
            logger.info(f"   equipment_id '{equipment_id}' - í•„í„° ì—†ì´ ëª¨ë“  ë°ì´í„° ì¡°íšŒ (ì„¤ë¹„ëª…ì¼ ìˆ˜ ìˆìŒ)")
            
            # ê° ì„¼ì„œ ë°ì´í„° ì¡°íšŒ (í•„í„° ì—†ì´ ì „ì²´ ë°ì´í„° ì¡°íšŒ)
            temp_df = self._fetch_raw_data_as_dataframe(
                start_rfc3339, 
                end_rfc3339, 
                "fields_temperature_c",
                device_filter=None  # í•„í„° ì—†ì´ ì „ì²´ ë°ì´í„° ì¡°íšŒ
            )
            humidity_df = self._fetch_raw_data_as_dataframe(
                start_rfc3339, 
                end_rfc3339, 
                "fields_humidity_percent",
                device_filter=None  # í•„í„° ì—†ì´ ì „ì²´ ë°ì´í„° ì¡°íšŒ
            )
            vibration_df = self._fetch_raw_data_as_dataframe(
                start_rfc3339, 
                end_rfc3339, 
                "fields_vibration_raw",
                device_filter=None  # í•„í„° ì—†ì´ ì „ì²´ ë°ì´í„° ì¡°íšŒ
            )
            sound_df = self._fetch_raw_data_as_dataframe(
                start_rfc3339, 
                end_rfc3339, 
                "fields_sound_raw",
                device_filter=None  # í•„í„° ì—†ì´ ì „ì²´ ë°ì´í„° ì¡°íšŒ
            )
            
            # ë°ì´í„°í”„ë ˆì„ ë³‘í•©ì„ ìœ„í•œ ì¤€ë¹„
            dfs = {}
            if temp_df is not None and len(temp_df) > 0:
                temp_df = temp_df.rename(columns={'_value': 'temperature'})
                dfs['temperature'] = temp_df[['_time', 'temperature']]
                logger.info(f"   âœ… ì˜¨ë„ ë°ì´í„°: {len(temp_df)}ê°œ í¬ì¸íŠ¸")
            
            if humidity_df is not None and len(humidity_df) > 0:
                humidity_df = humidity_df.rename(columns={'_value': 'humidity'})
                dfs['humidity'] = humidity_df[['_time', 'humidity']]
                logger.info(f"   âœ… ìŠµë„ ë°ì´í„°: {len(humidity_df)}ê°œ í¬ì¸íŠ¸")
            
            if vibration_df is not None and len(vibration_df) > 0:
                vibration_df = vibration_df.rename(columns={'_value': 'vibration'})
                dfs['vibration'] = vibration_df[['_time', 'vibration']]
                logger.info(f"   âœ… ì§„ë™ ë°ì´í„°: {len(vibration_df)}ê°œ í¬ì¸íŠ¸")
            
            if sound_df is not None and len(sound_df) > 0:
                sound_df = sound_df.rename(columns={'_value': 'sound'})
                dfs['sound'] = sound_df[['_time', 'sound']]
                logger.info(f"   âœ… ìŒì•• ë°ì´í„°: {len(sound_df)}ê°œ í¬ì¸íŠ¸")
            
            if len(dfs) < 2:
                logger.warning("ìƒê´€ê³„ìˆ˜ ê³„ì‚°ì„ ìœ„í•œ ì¶©ë¶„í•œ ì„¼ì„œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return {"temperature_vibration": 0.0, "vibration_sound": 0.0, "temperature_humidity": 0.0}
            
            # ì‹œê°„ ê¸°ì¤€ ë³‘í•©
            merged_df = None
            for name, df in dfs.items():
                if merged_df is None:
                    merged_df = df
                else:
                    merged_df = pd.merge(merged_df, df, on='_time', how='outer')
            
            if merged_df is None or len(merged_df) < 2:
                logger.warning("ë³‘í•©ëœ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return {"temperature_vibration": 0.0, "vibration_sound": 0.0, "temperature_humidity": 0.0}
            
            logger.info(f"   âœ… ë³‘í•©ëœ ë°ì´í„°: {len(merged_df)}ê°œ í¬ì¸íŠ¸, ì»¬ëŸ¼: {list(merged_df.columns)}")
            
            # ìˆ«ìí˜• ì»¬ëŸ¼ë§Œ ì„ íƒ (ìƒê´€ê³„ìˆ˜ ê³„ì‚°ìš©)
            numeric_cols = merged_df.select_dtypes(include=['float64', 'int64', 'float32', 'int32']).columns.tolist()
            # _time ì œì™¸
            numeric_cols = [col for col in numeric_cols if col != '_time']
            
            if len(numeric_cols) < 2:
                logger.warning("ìƒê´€ê³„ìˆ˜ ê³„ì‚°ì„ ìœ„í•œ ì¶©ë¶„í•œ ìˆ«ìí˜• ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return {"temperature_vibration": 0.0, "vibration_sound": 0.0, "temperature_humidity": 0.0}
            
            # ìƒê´€ê³„ìˆ˜ ê³„ì‚°
            corr_matrix = merged_df[numeric_cols].corr()
            
            result = {
                "temperature_vibration": 0.0,
                "vibration_sound": 0.0,
                "temperature_humidity": 0.0
            }
            
            # ìƒê´€ê³„ìˆ˜ ì¶”ì¶œ (NaNì´ë©´ 0.0)
            if 'temperature' in corr_matrix.columns and 'vibration' in corr_matrix.columns:
                val = corr_matrix.loc['temperature', 'vibration']
                result["temperature_vibration"] = round(float(val), 3) if not pd.isna(val) else 0.0
                logger.info(f"   ğŸ“ˆ ì˜¨ë„-ì§„ë™ ìƒê´€ê³„ìˆ˜: {result['temperature_vibration']}")
            
            if 'vibration' in corr_matrix.columns and 'sound' in corr_matrix.columns:
                val = corr_matrix.loc['vibration', 'sound']
                result["vibration_sound"] = round(float(val), 3) if not pd.isna(val) else 0.0
                logger.info(f"   ğŸ“ˆ ì§„ë™-ìŒì•• ìƒê´€ê³„ìˆ˜: {result['vibration_sound']}")
            
            if 'temperature' in corr_matrix.columns and 'humidity' in corr_matrix.columns:
                val = corr_matrix.loc['temperature', 'humidity']
                result["temperature_humidity"] = round(float(val), 3) if not pd.isna(val) else 0.0
                logger.info(f"   ğŸ“ˆ ì˜¨ë„-ìŠµë„ ìƒê´€ê³„ìˆ˜: {result['temperature_humidity']}")
            
            logger.info(f"âœ… ìƒê´€ê³„ìˆ˜ ê³„ì‚° ì™„ë£Œ: {result}")
            return result
            
        except Exception as e:
            logger.error(f"ìƒê´€ê³„ìˆ˜ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            return {"temperature_vibration": 0.0, "vibration_sound": 0.0, "temperature_humidity": 0.0}
    
    def _generate_dummy_alarms(
        self,
        start_time: datetime,
        end_time: datetime,
        equipment_id: str
    ) -> List[Dict[str, Any]]:
        """ë”ë¯¸ ì•ŒëŒ ë°ì´í„° ìƒì„±"""
        duration_hours = (end_time - start_time).total_seconds() / 3600
        num_alarms = max(1, int(duration_hours / 24))  # í•˜ë£¨ì— 1ê°œ ì •ë„
        
        alarms = []
        for i in range(num_alarms):
            alarm_time = start_time + timedelta(hours=i * (duration_hours / max(1, num_alarms)))
            alarms.append({
                "timestamp": alarm_time.isoformat(),
                "sensor": equipment_id,
                "severity": random.choice(["CRITICAL", "WARNING", "INFO"]),
                "value": round(random.uniform(45.0, 60.0), 2),
                "threshold": 50.0,
                "message": f"ì„ê³„ê°’ ì´ˆê³¼ ì•ŒëŒ {i+1}"
            })
        
        return alarms
    
    def _generate_dummy_mlp_anomalies(
        self,
        start_time: datetime,
        end_time: datetime,
        equipment_id: str
    ) -> List[Dict[str, Any]]:
        """ë”ë¯¸ MLP ì´ìƒ íƒì§€ ë°ì´í„° ìƒì„±"""
        return [
            {
                "timestamp": (start_time + timedelta(hours=12)).isoformat(),
                "type": "MLP_composite",
                "score": 0.75,
                "description": "í•™ìŠµëœ ì´ìƒ íŒ¨í„´ ê°ì§€"
            }
        ]
    
    def _generate_dummy_if_anomalies(
        self,
        start_time: datetime,
        end_time: datetime,
        equipment_id: str
    ) -> List[Dict[str, Any]]:
        """ë”ë¯¸ IF ì´ìƒ íƒì§€ ë°ì´í„° ìƒì„±"""
        return [
            {
                "timestamp": (start_time + timedelta(hours=24)).isoformat(),
                "type": "IF_outlier",
                "score": 0.82,
                "description": "ë¯¸ì§€ì˜ ì´ìƒ íŒ¨í„´ ê°ì§€"
            }
        ]
    
    def _calculate_stats_from_alarms(self, alarms: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        ì•ŒëŒ ë°ì´í„°ì—ì„œ ì„¼ì„œ í†µê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤ (Fallback ë¡œì§).
        
        ì•ŒëŒì˜ 'value' í•„ë“œë‚˜ 'details.meta.value' í•„ë“œì—ì„œ ê°’ì„ ì¶”ì¶œí•˜ì—¬
        Mean, Min, Maxë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Args:
            alarms: ì•ŒëŒ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì„¼ì„œ í†µê³„ ë”•ì…”ë„ˆë¦¬
        """
        import re
        
        logger.info(f"ğŸ“Š ì•ŒëŒ ë°ì´í„°ì—ì„œ í†µê³„ ê³„ì‚° ì‹œì‘ (ì•ŒëŒ ê°œìˆ˜: {len(alarms)}ê°œ)")
        
        # ì•ŒëŒì—ì„œ ê°’ ì¶”ì¶œ
        values = []
        for alarm in alarms:
            # ì•ŒëŒ ë©”ì‹œì§€ì—ì„œ ê°’ ì¶”ì¶œ ì‹œë„ (ì˜ˆ: "ì„ê³„ê°’ ì´ˆê³¼ ì•ŒëŒ 1" -> 53.66)
            # ë˜ëŠ” details.meta.value í•„ë“œ í™•ì¸
            value = None
            
            # ë°©ë²• 1: ì•ŒëŒ ë°ì´í„°ì— ì§ì ‘ value í•„ë“œê°€ ìˆëŠ”ì§€ í™•ì¸ (ê°€ì¥ ìš°ì„ )
            value = alarm.get('value')
            
            # ë°©ë²• 2: details.meta.value í™•ì¸
            if (value is None or value == 0.0) and isinstance(alarm.get('details'), dict):
                details = alarm.get('details', {})
                if isinstance(details.get('meta'), dict):
                    meta = details.get('meta', {})
                    value = meta.get('value')
                # detailsì— ì§ì ‘ valueê°€ ìˆëŠ”ì§€ í™•ì¸
                elif 'value' in details:
                    value = details.get('value')
            
            # ë°©ë²• 3: ì•ŒëŒ ë©”ì‹œì§€ì—ì„œ ìˆ«ì ì¶”ì¶œ (ì˜ˆ: "**53.66**" ë˜ëŠ” "53.66")
            if (value is None or value == 0.0):
                message = alarm.get('message', '')
                # ë©”ì‹œì§€ì—ì„œ ìˆ«ì ì¶”ì¶œ ì‹œë„ (ì†Œìˆ˜ì  í¬í•¨)
                numbers = re.findall(r'\d+\.\d+', message)  # ì†Œìˆ˜ì ì´ ìˆëŠ” ìˆ«ìë§Œ
                if not numbers:
                    numbers = re.findall(r'\d+', message)  # ì •ìˆ˜ë„ ì‹œë„
                if numbers:
                    try:
                        # ê°€ì¥ í° ìˆ«ìë¥¼ ê°’ìœ¼ë¡œ ì‚¬ìš© (ì„ê³„ê°’ë³´ë‹¤ í° ê°’ì¼ ê°€ëŠ¥ì„±)
                        candidate_values = [float(n) for n in numbers if float(n) > 0]
                        if candidate_values:
                            value = max(candidate_values)  # ê°€ì¥ í° ê°’ ì‚¬ìš©
                    except (ValueError, IndexError):
                        pass
            
            if value is not None:
                try:
                    float_value = float(value)
                    # 0.0ì´ ì•„ë‹Œ ìœ íš¨í•œ ê°’ë§Œ ì¶”ê°€
                    if not (math.isnan(float_value) or math.isinf(float_value)) and float_value != 0.0:
                        values.append(float_value)
                        logger.debug(f"   ê°’ ì¶”ì¶œ ì„±ê³µ: {float_value} (ì•ŒëŒ ë©”ì‹œì§€: {alarm.get('message', '')[:50]})")
                except (ValueError, TypeError) as e:
                    logger.debug(f"   ê°’ ë³€í™˜ ì‹¤íŒ¨: {value} (íƒ€ì…: {type(value)}, ì˜¤ë¥˜: {e})")
                    pass
        
        logger.info(f"   ì¶”ì¶œëœ ê°’ ê°œìˆ˜: {len(values)}ê°œ")
        if values:
            logger.info(f"   ê°’ ìƒ˜í”Œ: {values[:5]}")
        
        # í†µê³„ ê³„ì‚°
        if len(values) > 0:
            if PANDAS_AVAILABLE:
                values_series = pd.Series(values)
                mean_val = float(values_series.mean())
                min_val = float(values_series.min())
                max_val = float(values_series.max())
                std_val = float(values_series.std()) if len(values) > 1 else 0.0
                p95_val = float(values_series.quantile(0.95)) if len(values) > 0 else 0.0
            else:
                # pandasê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ê³„ì‚°
                mean_val = sum(values) / len(values)
                min_val = min(values)
                max_val = max(values)
                # í‘œì¤€í¸ì°¨ ê³„ì‚°
                variance = sum((x - mean_val) ** 2 for x in values) / len(values)
                std_val = math.sqrt(variance) if len(values) > 1 else 0.0
                # P95 ê³„ì‚°
                sorted_values = sorted(values)
                p95_idx = int(len(sorted_values) * 0.95)
                p95_val = sorted_values[min(p95_idx, len(sorted_values) - 1)]
            
            logger.info(f"   âœ… ì•ŒëŒ ê¸°ë°˜ í†µê³„ ê³„ì‚° ì™„ë£Œ:")
            logger.info(f"      Mean: {mean_val:.4f}, Min: {min_val:.4f}, Max: {max_val:.4f}, Std: {std_val:.4f}, P95: {p95_val:.4f}")
            
            # ì˜¨ë„/ìŠµë„ëŠ” ë™ì¼í•œ í†µê³„ ì‚¬ìš© (ì•ŒëŒì—ì„œ êµ¬ë¶„ ë¶ˆê°€)
            return {
                "temperature": {
                    "mean": mean_val,
                    "min": min_val,
                    "max": max_val,
                    "std": std_val,
                    "p95": p95_val
                },
                "humidity": {
                    "mean": mean_val,
                    "min": min_val,
                    "max": max_val,
                    "std": std_val,
                    "p95": p95_val
                },
                "vibration": {
                    "x": {"mean": mean_val, "peak": max_val, "rms": std_val},
                    "y": {"mean": mean_val, "peak": max_val, "rms": std_val},
                    "z": {"mean": mean_val, "peak": max_val, "rms": std_val}
                },
                "sound": {
                    "mean": mean_val,
                    "min": min_val,
                    "max": max_val,
                    "std": std_val,
                    "p95": p95_val
                }
            }
        else:
            logger.warning("   âš ï¸ ì•ŒëŒ ë°ì´í„°ì—ì„œ ê°’ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’(0.0)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return self._get_default_sensor_stats()


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_report_service: Optional[ReportDataService] = None


def get_report_service() -> ReportDataService:
    """ReportDataService ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _report_service
    if _report_service is None:
        _report_service = ReportDataService()
    return _report_service
