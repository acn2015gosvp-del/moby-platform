"""
InfluxDB í´ë¼ì´ì–¸íŠ¸ ì„œë¹„ìŠ¤ ëª¨ë“ˆ

ì£¼ìš” ê¸°ëŠ¥:
- ë°°ì¹˜ ì“°ê¸°ë¡œ ì„±ëŠ¥ ìµœì í™”
- ìë™ í”ŒëŸ¬ì‹œ (ì‹œê°„ ê¸°ë°˜ ë˜ëŠ” í¬ê¸° ê¸°ë°˜)
- ì“°ê¸° ì‹¤íŒ¨ ì‹œ ìë™ ì¬ì‹œë„
- ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡œê¹…
"""

import logging
import threading
import time
from collections import deque
from dataclasses import dataclass
from datetime import datetime
from typing import Dict, Any, Optional, List

from influxdb_client import InfluxDBClient, Point, WriteApi, WriteOptions
from influxdb_client.client.exceptions import InfluxDBError
from influxdb_client.client.query_api import QueryApi

from .schemas.models.core.config import settings

logger = logging.getLogger(__name__)

# -------------------------------------------------------------------
# ë°°ì¹˜ ì“°ê¸° ë²„í¼ í•­ëª©
# -------------------------------------------------------------------

@dataclass
class BufferedPoint:
    """ë²„í¼ì— ì €ì¥ëœ í¬ì¸íŠ¸ ì •ë³´"""
    bucket: str
    measurement: str
    fields: Dict[str, Any]
    tags: Dict[str, Any]
    timestamp: datetime
    retry_count: int = 0
    max_retries: int = 3


# -------------------------------------------------------------------
# InfluxDB í´ë¼ì´ì–¸íŠ¸ ê´€ë¦¬ì
# -------------------------------------------------------------------

class InfluxDBManager:
    """
    InfluxDB í´ë¼ì´ì–¸íŠ¸ì˜ ë°°ì¹˜ ì“°ê¸°, ë²„í¼ë§, ì¬ì‹œë„ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
    
    ì£¼ìš” ê¸°ëŠ¥:
    - ë°°ì¹˜ ì“°ê¸°ë¡œ ì„±ëŠ¥ ìµœì í™”
    - ìë™ í”ŒëŸ¬ì‹œ (ì‹œê°„ ê¸°ë°˜ ë˜ëŠ” í¬ê¸° ê¸°ë°˜)
    - ì“°ê¸° ì‹¤íŒ¨ ì‹œ ìë™ ì¬ì‹œë„
    """
    
    def __init__(
        self,
        buffer_size: int = 100,
        flush_interval: float = 5.0,
        max_retries: int = 3,
        retry_delay: float = 1.0
    ):
        """
        InfluxDB ê´€ë¦¬ì ì´ˆê¸°í™”
        
        Args:
            buffer_size: ë²„í¼ í¬ê¸° (ì´ í¬ê¸°ì— ë„ë‹¬í•˜ë©´ ìë™ í”ŒëŸ¬ì‹œ)
            flush_interval: í”ŒëŸ¬ì‹œ ê°„ê²© (ì´ˆ)
            max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
            retry_delay: ì¬ì‹œë„ ê°„ê²© (ì´ˆ)
        """
        self.client = InfluxDBClient(
            url=settings.INFLUX_URL,
            token=settings.INFLUX_TOKEN,
            org=settings.INFLUX_ORG
        )
        
        # Write API ì„¤ì • (ë°°ì¹˜ ì“°ê¸° ìµœì í™”)
        write_options = WriteOptions(
            batch_size=buffer_size,
            flush_interval=int(flush_interval * 1000),  # ë°€ë¦¬ì´ˆë¡œ ë³€í™˜
            jitter_interval=2000,  # 2ì´ˆ ì§€í„°
            retry_interval=5000,  # 5ì´ˆ ì¬ì‹œë„ ê°„ê²©
            max_retries=max_retries,
            max_retry_delay=30000,  # 30ì´ˆ ìµœëŒ€ ì¬ì‹œë„ ì§€ì—°
            exponential_base=2
        )
        
        self.write_api: WriteApi = self.client.write_api(write_options=write_options)
        self.query_api: QueryApi = self.client.query_api()
        
        # ë²„í¼ ê´€ë¦¬
        self.buffer: deque = deque()
        self.buffer_lock = threading.Lock()
        self.buffer_size = buffer_size
        self.flush_interval = flush_interval
        
        # ì¬ì‹œë„ ì„¤ì •
        self.max_retries = max_retries
        self.retry_delay = retry_delay
        
        # ìŠ¤ë ˆë“œ ì¢…ë£Œ í”Œë˜ê·¸
        self._shutdown_flag = threading.Event()
        
        # í”ŒëŸ¬ì‹œ ìŠ¤ë ˆë“œ
        self.flush_thread = threading.Thread(
            target=self._periodic_flush,
            daemon=True,
            name="InfluxDB-Flush"
        )
        self.flush_thread.start()
        
        try:
            if logger.handlers:
                logger.info(
                    f"âœ… InfluxDB manager initialized. "
                    f"URL: {settings.INFLUX_URL}, "
                    f"Buffer size: {buffer_size}, "
                    f"Flush interval: {flush_interval}s"
                )
        except (ValueError, OSError, AttributeError, RuntimeError):
            # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
            pass
    
    def write_point(
        self,
        bucket: str,
        measurement: str,
        fields: Dict[str, Any],
        tags: Dict[str, Any],
        timestamp: Optional[datetime] = None
    ) -> bool:
        """
        í¬ì¸íŠ¸ë¥¼ ë²„í¼ì— ì¶”ê°€í•©ë‹ˆë‹¤. ë²„í¼ê°€ ê°€ë“ ì°¨ë©´ ìë™ìœ¼ë¡œ í”ŒëŸ¬ì‹œë©ë‹ˆë‹¤.
        
        Args:
            bucket: InfluxDB ë²„í‚· ì´ë¦„
            measurement: ì¸¡ì •ê°’ ì´ë¦„
            fields: í•„ë“œ ë”•ì…”ë„ˆë¦¬
            tags: íƒœê·¸ ë”•ì…”ë„ˆë¦¬
            timestamp: íƒ€ì„ìŠ¤íƒ¬í”„ (Noneì´ë©´ í˜„ì¬ ì‹œê°„)
            
        Returns:
            ë²„í¼ ì¶”ê°€ ì„±ê³µ ì—¬ë¶€
        """
        try:
            buffered_point = BufferedPoint(
                bucket=bucket,
                measurement=measurement,
                fields=fields,
                tags=tags,
                timestamp=timestamp or datetime.now(),
                retry_count=0,
                max_retries=self.max_retries
            )
            
            with self.buffer_lock:
                self.buffer.append(buffered_point)
                buffer_len = len(self.buffer)
                
                try:
                    if logger.handlers:
                        logger.debug(
                            f"ğŸ“¥ Point buffered. "
                            f"Measurement: {measurement}, "
                            f"Buffer size: {buffer_len}/{self.buffer_size}"
                        )
                except (ValueError, OSError, AttributeError, RuntimeError):
                    # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
                    pass
                
                # ë²„í¼ê°€ ê°€ë“ ì°¨ë©´ ì¦‰ì‹œ í”ŒëŸ¬ì‹œ
                if buffer_len >= self.buffer_size:
                    try:
                        if logger.handlers:
                            logger.info(
                                f"ğŸ”„ Buffer full ({buffer_len} points). "
                                f"Triggering immediate flush..."
                            )
                    except (ValueError, OSError, AttributeError, RuntimeError):
                        # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
                        pass
                    threading.Thread(
                        target=self._flush_buffer,
                        daemon=True,
                        name="InfluxDB-ImmediateFlush"
                    ).start()
            
            return True
            
        except Exception as e:
            try:
                if logger.handlers:
                    logger.error(
                        f"âŒ Failed to buffer point. "
                        f"Measurement: {measurement}, Error: {e}",
                        exc_info=True
                    )
            except (ValueError, OSError, AttributeError, RuntimeError):
                # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
                pass
            return False
    
    def _periodic_flush(self):
        """
        ì£¼ê¸°ì ìœ¼ë¡œ ë²„í¼ë¥¼ í”ŒëŸ¬ì‹œí•˜ëŠ” ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ í•¨ìˆ˜.
        """
        try:
            if logger.handlers:
                logger.info("ğŸ”„ InfluxDB periodic flush thread started.")
        except (ValueError, OSError, AttributeError, RuntimeError):
            # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
            pass
        
        while not self._shutdown_flag.is_set():
            try:
                # shutdown_flagê°€ ì„¤ì •ë˜ë©´ ì¦‰ì‹œ ì¢…ë£Œ
                if self._shutdown_flag.wait(timeout=self.flush_interval):
                    break
                
                with self.buffer_lock:
                    if len(self.buffer) > 0:
                        try:
                            if logger.handlers:
                                logger.debug(
                                    f"â° Periodic flush triggered. "
                                    f"Buffer size: {len(self.buffer)}"
                                )
                        except (ValueError, OSError, AttributeError, RuntimeError):
                            # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
                            pass
                        self._flush_buffer_internal()
                        
            except Exception as e:
                # shutdown_flagê°€ ì„¤ì •ë˜ì—ˆìœ¼ë©´ ì¢…ë£Œ
                if self._shutdown_flag.is_set():
                    break
                try:
                    if logger.handlers:
                        logger.error(
                            f"âŒ Error in periodic flush thread: {e}",
                            exc_info=True
                        )
                except (ValueError, OSError, AttributeError, RuntimeError):
                    # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
                    pass
    
    def _flush_buffer(self):
        """
        ë²„í¼ë¥¼ í”ŒëŸ¬ì‹œí•©ë‹ˆë‹¤ (ìŠ¤ë ˆë“œ ì•ˆì „).
        """
        with self.buffer_lock:
            self._flush_buffer_internal()
    
    def _flush_buffer_internal(self):
        """
        ë²„í¼ë¥¼ ì‹¤ì œë¡œ í”ŒëŸ¬ì‹œí•©ë‹ˆë‹¤ (ë‚´ë¶€ ë©”ì„œë“œ, lock ë³´í˜¸ í•„ìš”).
        """
        if len(self.buffer) == 0:
            return
        
        # ë²„í¼ì—ì„œ ëª¨ë“  í¬ì¸íŠ¸ ê°€ì ¸ì˜¤ê¸°
        points_to_write: List[BufferedPoint] = []
        while len(self.buffer) > 0:
            points_to_write.append(self.buffer.popleft())
        
        if not points_to_write:
            return
        
        try:
            if logger.handlers:
                logger.info(
                    f"ğŸ“¤ Flushing {len(points_to_write)} points to InfluxDB..."
                )
        except (ValueError, OSError, AttributeError, RuntimeError):
            # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
            pass
        
        # í¬ì¸íŠ¸ë¥¼ InfluxDB Point ê°ì²´ë¡œ ë³€í™˜
        influx_points = []
        for buffered_point in points_to_write:
            try:
                point = Point(buffered_point.measurement)
                
                # í•„ë“œ ì¶”ê°€
                for key, value in buffered_point.fields.items():
                    point.field(key, value)
                
                # íƒœê·¸ ì¶”ê°€
                for key, value in buffered_point.tags.items():
                    point.tag(key, value)
                
                # íƒ€ì„ìŠ¤íƒ¬í”„ ì„¤ì •
                point.time(buffered_point.timestamp)
                
                influx_points.append(point)
                
            except Exception as e:
                try:
                    if logger.handlers:
                        logger.error(
                            f"âŒ Failed to convert point. "
                            f"Measurement: {buffered_point.measurement}, Error: {e}",
                            exc_info=True
                        )
                except (ValueError, OSError, AttributeError, RuntimeError):
                    # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
                    pass
                # ë³€í™˜ ì‹¤íŒ¨í•œ í¬ì¸íŠ¸ëŠ” ì¬ì‹œë„ íì— ì¶”ê°€
                self._retry_point(buffered_point)
        
        if not influx_points:
            try:
                if logger.handlers:
                    logger.warning("âš ï¸ No valid points to write after conversion.")
            except (ValueError, OSError, AttributeError, RuntimeError):
                # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
                pass
            return
        
        # ë°°ì¹˜ ì“°ê¸° ì‹œë„
        success = self._write_batch(points_to_write, influx_points)
        
        if not success:
            try:
                if logger.handlers:
                    logger.warning(
                        f"âš ï¸ Batch write failed. "
                        f"Re-queuing {len(points_to_write)} points for retry."
                    )
            except (ValueError, OSError, AttributeError, RuntimeError):
                # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
                pass
    
    def _write_batch(
        self,
        buffered_points: List[BufferedPoint],
        influx_points: List[Point]
    ) -> bool:
        """
        ë°°ì¹˜ë¡œ í¬ì¸íŠ¸ë¥¼ ì“°ê¸° ì‹œë„í•©ë‹ˆë‹¤.
        
        Args:
            buffered_points: ì›ë³¸ ë²„í¼ í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸
            influx_points: InfluxDB Point ê°ì²´ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì“°ê¸° ì„±ê³µ ì—¬ë¶€
        """
        if not influx_points:
            return False
        
        # ëª¨ë“  í¬ì¸íŠ¸ê°€ ê°™ì€ ë²„í‚·ì¸ì§€ í™•ì¸
        bucket = buffered_points[0].bucket
        if not all(p.bucket == bucket for p in buffered_points):
            try:
                if logger.handlers:
                    logger.warning(
                        "âš ï¸ Points have different buckets. "
                        "Writing separately by bucket."
                    )
            except (ValueError, OSError, AttributeError, RuntimeError):
                # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
                pass
            return self._write_batch_by_bucket(buffered_points, influx_points)
        
        try:
            # ë°°ì¹˜ ì“°ê¸°
            self.write_api.write(bucket=bucket, record=influx_points)
            
            try:
                if logger.handlers:
                    logger.info(
                        f"âœ… Successfully wrote {len(influx_points)} points to bucket '{bucket}'."
                    )
            except (ValueError, OSError, AttributeError, RuntimeError):
                # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
                pass
            return True
            
        except InfluxDBError as e:
            try:
                if logger.handlers:
                    logger.error(
                        f"âŒ InfluxDB error during batch write. "
                        f"Bucket: {bucket}, Points: {len(influx_points)}, Error: {e}",
                        exc_info=True
                    )
            except (ValueError, OSError, AttributeError, RuntimeError):
                # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
                pass
            # ì¬ì‹œë„ íì— ì¶”ê°€
            for buffered_point in buffered_points:
                self._retry_point(buffered_point)
            return False
            
        except Exception as e:
            try:
                if logger.handlers:
                    logger.error(
                        f"âŒ Unexpected error during batch write. "
                        f"Bucket: {bucket}, Points: {len(influx_points)}, Error: {e}",
                        exc_info=True
                    )
            except (ValueError, OSError, AttributeError, RuntimeError):
                # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
                pass
            # ì¬ì‹œë„ íì— ì¶”ê°€
            for buffered_point in buffered_points:
                self._retry_point(buffered_point)
            return False
    
    def _write_batch_by_bucket(
        self,
        buffered_points: List[BufferedPoint],
        influx_points: List[Point]
    ) -> bool:
        """
        ë²„í‚·ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ë°°ì¹˜ ì“°ê¸°ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        """
        # ë²„í‚·ë³„ë¡œ ê·¸ë£¹í™”
        by_bucket: Dict[str, List[tuple]] = {}
        for buffered_point, influx_point in zip(buffered_points, influx_points):
            bucket = buffered_point.bucket
            if bucket not in by_bucket:
                by_bucket[bucket] = []
            by_bucket[bucket].append((buffered_point, influx_point))
        
        all_success = True
        for bucket, point_pairs in by_bucket.items():
            bucket_points = [p for _, p in point_pairs]
            bucket_buffered = [b for b, _ in point_pairs]
            
            try:
                self.write_api.write(bucket=bucket, record=bucket_points)
                try:
                    if logger.handlers:
                        logger.info(
                            f"âœ… Successfully wrote {len(bucket_points)} points to bucket '{bucket}'."
                        )
                except (ValueError, OSError, AttributeError, RuntimeError):
                    # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
                    pass
            except Exception as e:
                try:
                    if logger.handlers:
                        logger.error(
                            f"âŒ Failed to write to bucket '{bucket}'. Error: {e}",
                            exc_info=True
                        )
                except (ValueError, OSError, AttributeError, RuntimeError):
                    # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
                    pass
                for buffered_point in bucket_buffered:
                    self._retry_point(buffered_point)
                all_success = False
        
        return all_success
    
    def _retry_point(self, buffered_point: BufferedPoint):
        """
        ì‹¤íŒ¨í•œ í¬ì¸íŠ¸ë¥¼ ì¬ì‹œë„ íì— ì¶”ê°€í•©ë‹ˆë‹¤.
        
        Args:
            buffered_point: ì¬ì‹œë„í•  í¬ì¸íŠ¸
        """
        if buffered_point.retry_count >= buffered_point.max_retries:
            try:
                if logger.handlers:
                    logger.error(
                        f"âŒ Point exceeded max retries. Dropping point. "
                        f"Measurement: {buffered_point.measurement}, "
                        f"Bucket: {buffered_point.bucket}, "
                        f"Retry count: {buffered_point.retry_count}"
                    )
            except (ValueError, OSError, AttributeError, RuntimeError):
                # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
                pass
            return
        
        buffered_point.retry_count += 1
        
        # ì¬ì‹œë„ ì§€ì—° í›„ ë²„í¼ì— ë‹¤ì‹œ ì¶”ê°€
        def delayed_retry():
            try:
                time.sleep(self.retry_delay * buffered_point.retry_count)  # ì§€ìˆ˜ì  ì§€ì—°
                with self.buffer_lock:
                    self.buffer.append(buffered_point)
                # ë¡œê±° í•¸ë“¤ëŸ¬ê°€ ë‹«í˜”ëŠ”ì§€ í™•ì¸
                if logger.handlers:
                    try:
                        logger.info(
                            f"ğŸ”„ Re-queued point for retry. "
                            f"Measurement: {buffered_point.measurement}, "
                            f"Retry count: {buffered_point.retry_count}/{buffered_point.max_retries}"
                        )
                    except (ValueError, OSError, AttributeError, RuntimeError):
                        # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
                        # í…ŒìŠ¤íŠ¸ ì¢…ë£Œ ì‹œ ë¡œê±° í•¸ë“¤ëŸ¬ê°€ ì´ë¯¸ ë‹«í˜”ì„ ìˆ˜ ìˆìŒ
                        pass
            except Exception:
                # ìŠ¤ë ˆë“œê°€ ì¢…ë£Œë˜ëŠ” ë™ì•ˆ ë°œìƒí•  ìˆ˜ ìˆëŠ” ëª¨ë“  ì˜ˆì™¸ ë¬´ì‹œ
                pass
        
        threading.Thread(
            target=delayed_retry,
            daemon=True,
            name=f"InfluxDB-Retry-{buffered_point.measurement}"
        ).start()
    
    def flush(self):
        """
        ìˆ˜ë™ìœ¼ë¡œ ë²„í¼ë¥¼ í”ŒëŸ¬ì‹œí•©ë‹ˆë‹¤.
        """
        try:
            if logger.handlers:
                logger.info("ğŸ”„ Manual flush requested.")
        except (ValueError, OSError, AttributeError, RuntimeError):
            # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
            pass
        self._flush_buffer()
    
    def query_sensor_status(
        self,
        bucket: str,
        inactive_threshold_minutes: int = 5
    ) -> Dict[str, Any]:
        """
        ì„¼ì„œ ìƒíƒœë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        
        ìµœê·¼ inactive_threshold_minutes ë¶„ ë‚´ì— ë°ì´í„°ê°€ ìˆëŠ” ì„¼ì„œë¥¼ í™œì„±ìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.
        
        Args:
            bucket: InfluxDB ë²„í‚· ì´ë¦„
            inactive_threshold_minutes: ë¹„í™œì„±ìœ¼ë¡œ ê°„ì£¼í•  ì‹œê°„(ë¶„)
            
        Returns:
            ì„¼ì„œ ìƒíƒœ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        try:
            from datetime import timedelta
            
            # Flux ì¿¼ë¦¬ ì‘ì„±
            # ìµœê·¼ inactive_threshold_minutes ë¶„ ë‚´ì— ë°ì´í„°ê°€ ìˆëŠ” device_id ëª©ë¡ ì¡°íšŒ
            query = f'''
            from(bucket: "{bucket}")
              |> range(start: -{inactive_threshold_minutes}m)
              |> filter(fn: (r) => r["_measurement"] == "sensor_data")
              |> filter(fn: (r) => r["_field"] == "temperature" or r["_field"] == "humidity" or r["_field"] == "vibration" or r["_field"] == "sound")
              |> group(columns: ["device_id"])
              |> distinct(column: "device_id")
              |> keep(columns: ["device_id"])
            '''
            
            try:
                if logger.handlers:
                    logger.debug(f"Querying sensor status from InfluxDB. Bucket: {bucket}")
            except (ValueError, OSError, AttributeError, RuntimeError):
                # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
                pass
            
            # ì¿¼ë¦¬ ì‹¤í–‰
            result = self.query_api.query(query=query, org=settings.INFLUX_ORG)
            
            # ê²°ê³¼ íŒŒì‹±
            active_devices = set()
            for table in result:
                for record in table.records:
                    device_id = record.values.get("device_id")
                    if device_id:
                        active_devices.add(device_id)
            
            active_count = len(active_devices)
            
            # ì „ì²´ ì„¼ì„œ ìˆ˜ëŠ” í™œì„± ì„¼ì„œ ìˆ˜ë¡œ ì¶”ì • (ì‹¤ì œë¡œëŠ” ë³„ë„ ê´€ë¦¬ í•„ìš”)
            # í–¥í›„ ì„¼ì„œ ë“±ë¡ ì‹œìŠ¤í…œì´ ìˆìœ¼ë©´ ê·¸ê³³ì—ì„œ ì „ì²´ ìˆ˜ë¥¼ ì¡°íšŒ
            total_count = active_count  # ì„ì‹œ: í™œì„± ì„¼ì„œ ìˆ˜ë¥¼ ì „ì²´ë¡œ ê°„ì£¼
            inactive_count = 0  # í˜„ì¬ëŠ” ë¹„í™œì„± ì„¼ì„œë¥¼ êµ¬ë¶„í•  ìˆ˜ ì—†ìŒ
            
            try:
                if logger.handlers:
                    logger.info(
                        f"âœ… Sensor status queried. "
                        f"Active: {active_count}, Total: {total_count}"
                    )
            except (ValueError, OSError, AttributeError, RuntimeError):
                # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
                pass
            
            return {
                "total_count": total_count,
                "active_count": active_count,
                "inactive_count": inactive_count,
                "devices": list(active_devices)
            }
            
        except Exception as e:
            try:
                if logger.handlers:
                    logger.error(
                        f"âŒ Failed to query sensor status from InfluxDB. Error: {e}",
                        exc_info=True
                    )
            except (ValueError, OSError, AttributeError, RuntimeError):
                # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
                pass
            # ì—ëŸ¬ ë°œìƒ ì‹œ ë¹ˆ ê²°ê³¼ ë°˜í™˜
            return {
                "total_count": 0,
                "active_count": 0,
                "inactive_count": 0,
                "devices": []
            }
    
    def close(self):
        """
        ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.
        """
        try:
            if logger.handlers:
                logger.info("ğŸ”„ Closing InfluxDB manager...")
        except (ValueError, OSError, AttributeError, RuntimeError):
            # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
            pass
        
        # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì¢…ë£Œ ì‹ í˜¸
        if hasattr(self, '_shutdown_flag'):
            self._shutdown_flag.set()
        
        # ìŠ¤ë ˆë“œê°€ ì¢…ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸° (ìµœëŒ€ 5ì´ˆ)
        if hasattr(self, 'flush_thread') and self.flush_thread.is_alive():
            self.flush_thread.join(timeout=5.0)
        
        # ë‚¨ì€ ë²„í¼ í”ŒëŸ¬ì‹œ
        self._flush_buffer()
        
        # Write API ì¢…ë£Œ
        try:
            self.write_api.close()
            self.client.close()
            try:
                if logger.handlers:
                    logger.info("âœ… InfluxDB manager closed successfully.")
            except (ValueError, OSError, AttributeError, RuntimeError):
                # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
                pass
        except Exception as e:
            try:
                if logger.handlers:
                    logger.error(f"âŒ Error closing InfluxDB manager: {e}", exc_info=True)
            except (ValueError, OSError, AttributeError, RuntimeError):
                # ë¡œê±°ê°€ ë‹«íŒ íŒŒì¼ì— ì“°ë ¤ê³  ì‹œë„í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
                pass


# -------------------------------------------------------------------
# ê¸€ë¡œë²Œ ì¸ìŠ¤í„´ìŠ¤ (ì§€ì—° ì´ˆê¸°í™”)
# -------------------------------------------------------------------

_influx_manager_instance = None
_influx_manager_lock = threading.Lock()

def _get_influx_manager():
    """
    InfluxDB Manager ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì§€ì—° ì´ˆê¸°í™”í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    ì„œë²„ ì‹œì‘ ì‹œ ì¦‰ì‹œ ì´ˆê¸°í™”ë˜ì§€ ì•Šê³ , ì²˜ìŒ ì‚¬ìš©ë  ë•Œë§Œ ì´ˆê¸°í™”ë©ë‹ˆë‹¤.
    """
    global _influx_manager_instance
    if _influx_manager_instance is None:
        with _influx_manager_lock:
            if _influx_manager_instance is None:
                _influx_manager_instance = InfluxDBManager(
                    buffer_size=100,
                    flush_interval=5.0,
                    max_retries=3,
                    retry_delay=1.0
                )
    return _influx_manager_instance

# í˜¸í™˜ì„±ì„ ìœ„í•œ ì†ì„±ì²˜ëŸ¼ ì ‘ê·¼ ê°€ëŠ¥í•œ ê°ì²´
class _InfluxManagerProxy:
    """InfluxDB Managerì— ëŒ€í•œ í”„ë¡ì‹œ ê°ì²´ (ì§€ì—° ì´ˆê¸°í™”)"""
    def __getattr__(self, name):
        return getattr(_get_influx_manager(), name)
    
    def __call__(self, *args, **kwargs):
        return _get_influx_manager()(*args, **kwargs)
    
    def __getstate__(self):
        # pickle ì§€ì›
        return {}
    
    def __setstate__(self, state):
        # pickle ì§€ì›
        pass

influx_manager = _InfluxManagerProxy()


# -------------------------------------------------------------------
# ê³µê°œ API (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)
# -------------------------------------------------------------------

def write_point(bucket: str, measurement: str, fields: dict, tags: dict):
    """
    ë‹¨ì¼ í¬ì¸íŠ¸ë¥¼ ì“°ê¸°í•©ë‹ˆë‹¤ (ê¸°ì¡´ API í˜¸í™˜ì„±).
    
    ì´ í•¨ìˆ˜ëŠ” ë‚´ë¶€ì ìœ¼ë¡œ ë²„í¼ì— ì¶”ê°€í•˜ë©°, ë°°ì¹˜ë¡œ ì“°ê¸°ê°€ ìˆ˜í–‰ë©ë‹ˆë‹¤.
    
    Args:
        bucket: InfluxDB ë²„í‚· ì´ë¦„
        measurement: ì¸¡ì •ê°’ ì´ë¦„
        fields: í•„ë“œ ë”•ì…”ë„ˆë¦¬
        tags: íƒœê·¸ ë”•ì…”ë„ˆë¦¬
    """
    return _get_influx_manager().write_point(
        bucket=bucket,
        measurement=measurement,
        fields=fields,
        tags=tags
    )


def flush_influxdb():
    """
    InfluxDB ë²„í¼ë¥¼ ìˆ˜ë™ìœ¼ë¡œ í”ŒëŸ¬ì‹œí•©ë‹ˆë‹¤.
    """
    _get_influx_manager().flush()


def query_sensor_status(bucket: str, inactive_threshold_minutes: int = 5) -> Dict[str, Any]:
    """
    ì„¼ì„œ ìƒíƒœë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    
    Args:
        bucket: InfluxDB ë²„í‚· ì´ë¦„
        inactive_threshold_minutes: ë¹„í™œì„±ìœ¼ë¡œ ê°„ì£¼í•  ì‹œê°„(ë¶„) - ì´ ì‹œê°„ ë™ì•ˆ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¹„í™œì„±
        
    Returns:
        ì„¼ì„œ ìƒíƒœ ì •ë³´ ë”•ì…”ë„ˆë¦¬:
        {
            "total_count": int,
            "active_count": int,
            "inactive_count": int,
            "devices": List[str]  # í™œì„± ì„¼ì„œ ëª©ë¡
        }
    """
    return _get_influx_manager().query_sensor_status(bucket, inactive_threshold_minutes)


def close_influxdb():
    """
    InfluxDB ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.
    """
    global _influx_manager_instance
    if _influx_manager_instance is not None:
        _influx_manager_instance.close()
        _influx_manager_instance = None
