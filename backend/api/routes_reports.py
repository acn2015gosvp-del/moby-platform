"""
ë³´ê³ ì„œ ìƒì„± API ì—”ë“œí¬ì¸íŠ¸

LLM ê¸°ë°˜ ì£¼ê°„/ì¼ì¼ ë³´ê³ ì„œ ìƒì„±ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

from fastapi import APIRouter, HTTPException, Depends, status, Query
from fastapi.responses import FileResponse
from typing import Dict, Any, Optional
from datetime import datetime, timedelta, timezone
from pathlib import Path
from pydantic import BaseModel, Field

from backend.api.core.responses import SuccessResponse, ErrorResponse
from backend.api.core.permissions import get_current_user, require_permissions
from backend.api.models.role import Permission
from backend.api.services.schemas.models.core.logger import get_logger
from backend.api.services.report_generator import get_report_generator, MOBYReportGenerator
from backend.api.services.alert_storage import get_latest_alerts
from backend.api.services.database import get_db
from backend.api.services.pdf_generator import markdown_to_pdf
from sqlalchemy.orm import Session

logger = get_logger(__name__)
router = APIRouter(prefix="/reports", tags=["Reports"])


class ReportRequest(BaseModel):
    """ë³´ê³ ì„œ ìƒì„± ìš”ì²­ ëª¨ë¸"""
    period_start: str = Field(..., description="ë³´ê³  ê¸°ê°„ ì‹œì‘ (YYYY-MM-DD HH:MM:SS)")
    period_end: str = Field(..., description="ë³´ê³  ê¸°ê°„ ì¢…ë£Œ (YYYY-MM-DD HH:MM:SS)")
    equipment: str = Field(..., description="ì„¤ë¹„ëª…")
    sensor_ids: Optional[list[str]] = Field(None, description="íŠ¹ì • ì„¼ì„œ ID ëª©ë¡ (ì—†ìœ¼ë©´ ì „ì²´)")
    include_mlp_anomalies: bool = Field(True, description="MLP ì´ìƒ íƒì§€ í¬í•¨ ì—¬ë¶€")
    include_if_anomalies: bool = Field(True, description="Isolation Forest ì´ìƒ íƒì§€ í¬í•¨ ì—¬ë¶€")


class ReportResponse(BaseModel):
    """ë³´ê³ ì„œ ìƒì„± ì‘ë‹µ ëª¨ë¸"""
    report_id: str
    report_content: str
    metadata: Dict[str, Any]
    generated_at: str


@router.post(
    "/generate",
    response_model=SuccessResponse[ReportResponse],
    summary="ë³´ê³ ì„œ ìƒì„±",
    description="""
    ì£¼ê°„ ë˜ëŠ” ì¼ì¼ ë³´ê³ ì„œë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤.
    
    **í•„ìš” ê¶Œí•œ**: `ALERT_READ`, `SENSOR_READ`
    
    **ë³´ê³ ì„œ ë‚´ìš©**:
    - ì„¼ì„œë³„ í†µê³„ ìš”ì•½
    - ì•ŒëŒ ë° ì´ìƒ íƒì§€ ìƒì„¸
    - ìƒê´€ ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸
    - ê¶Œì¥ ì‚¬í•­
    """,
    responses={
        200: {
            "description": "ë³´ê³ ì„œ ìƒì„± ì„±ê³µ",
            "model": SuccessResponse[ReportResponse]
        },
        400: {
            "description": "ì˜ëª»ëœ ìš”ì²­",
            "model": ErrorResponse
        },
        500: {
            "description": "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜",
            "model": ErrorResponse
        }
    }
)
async def generate_report(
    request: ReportRequest,
    format: str = Query("json", description="ì‘ë‹µ í˜•ì‹ (json ë˜ëŠ” pdf)"),
    current_user = Depends(get_current_user),
    _permissions = Depends(require_permissions(Permission.ALERT_READ, Permission.SENSOR_READ)),
    db: Session = Depends(get_db)
) -> SuccessResponse[ReportResponse] | FileResponse:
    """
    ë³´ê³ ì„œ ìƒì„±
    
    Args:
        request: ë³´ê³ ì„œ ìƒì„± ìš”ì²­ ë°ì´í„°
        current_user: í˜„ì¬ ì‚¬ìš©ì (ì˜ì¡´ì„±)
        _permissions: ê¶Œí•œ ì²´í¬ (ì˜ì¡´ì„±)
        
    Returns:
        SuccessResponse[ReportResponse]: ìƒì„±ëœ ë³´ê³ ì„œ
    """
    # ìš”ì²­ ë°ì´í„° ë¡œê¹… (ë””ë²„ê¹…ìš©)
    logger.info(f"ğŸ“¥ ë³´ê³ ì„œ ìƒì„± ìš”ì²­ ìˆ˜ì‹ ")
    logger.debug(f"   ìš”ì²­ ë³¸ë¬¸: period_start={request.period_start}, period_end={request.period_end}, equipment={request.equipment}, include_mlp={request.include_mlp_anomalies}, include_if={request.include_if_anomalies}")
    
    try:
        # ê¸°ê°„ ê²€ì¦ (ì—¬ëŸ¬ ë‚ ì§œ í˜•ì‹ ì§€ì›)
        def parse_datetime(date_str: str) -> datetime:
            """ì—¬ëŸ¬ ë‚ ì§œ í˜•ì‹ì„ ì§€ì›í•˜ëŠ” íŒŒì„œ"""
            if not date_str:
                raise ValueError(f"ë‚ ì§œ ë¬¸ìì—´ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            
            if not isinstance(date_str, str):
                raise ValueError(f"ë‚ ì§œëŠ” ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤. ë°›ì€ íƒ€ì…: {type(date_str)}, ê°’: {date_str}")
            
            # ê³µë°± ì œê±°
            date_str = date_str.strip()
            
            # í˜•ì‹ ëª©ë¡ (ìš°ì„ ìˆœìœ„ ìˆœ)
            formats = [
                "%Y-%m-%d %H:%M:%S",  # YYYY-MM-DD HH:MM:SS
                "%Y-%m-%dT%H:%M:%S",  # YYYY-MM-DDTHH:MM:SS (ISO í˜•ì‹)
                "%Y-%m-%d %H:%M",     # YYYY-MM-DD HH:MM
                "%Y-%m-%dT%H:%M",     # YYYY-MM-DDTHH:MM
                "%Y-%m-%d %H:%M:%S.%f",  # ë§ˆì´í¬ë¡œì´ˆ í¬í•¨
                "%Y-%m-%dT%H:%M:%S.%f",  # ISO í˜•ì‹ + ë§ˆì´í¬ë¡œì´ˆ
                "%Y-%m-%dT%H:%M:%S.%fZ",  # ISO í˜•ì‹ + ë§ˆì´í¬ë¡œì´ˆ + Z
                "%Y-%m-%dT%H:%M:%SZ",  # ISO í˜•ì‹ + Z
            ]
            
            for fmt in formats:
                try:
                    parsed = datetime.strptime(date_str, fmt)
                    # timezone ì •ë³´ê°€ ì—†ìœ¼ë©´ UTCë¡œ ì„¤ì •
                    if parsed.tzinfo is None:
                        parsed = parsed.replace(tzinfo=timezone.utc)
                    return parsed
                except ValueError:
                    continue
            
            # ISO í˜•ì‹ìœ¼ë¡œ ì‹œë„ (fromisoformat)
            try:
                # Zë¥¼ +00:00ìœ¼ë¡œ ë³€í™˜
                iso_str = date_str.replace('Z', '+00:00')
                parsed = datetime.fromisoformat(iso_str)
                # timezone ì •ë³´ê°€ ì—†ìœ¼ë©´ UTCë¡œ ì„¤ì •
                if parsed.tzinfo is None:
                    parsed = parsed.replace(tzinfo=timezone.utc)
                return parsed
            except (ValueError, AttributeError) as e:
                logger.debug(f"ISO í˜•ì‹ íŒŒì‹± ì‹¤íŒ¨: {date_str}, ì˜¤ë¥˜: {e}")
                pass
            
            raise ValueError(f"ë‚ ì§œ í˜•ì‹ì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: '{date_str}'. ì§€ì› í˜•ì‹: YYYY-MM-DD HH:MM:SS ë˜ëŠ” YYYY-MM-DDTHH:MM:SS")
        
        logger.info(f"ğŸ“¥ ë³´ê³ ì„œ ìƒì„± ìš”ì²­ ìˆ˜ì‹ ")
        logger.info(f"   period_start: {request.period_start} (íƒ€ì…: {type(request.period_start)})")
        logger.info(f"   period_end: {request.period_end} (íƒ€ì…: {type(request.period_end)})")
        logger.info(f"   equipment: {request.equipment} (íƒ€ì…: {type(request.equipment)})")
        logger.info(f"   include_mlp_anomalies: {request.include_mlp_anomalies}")
        logger.info(f"   include_if_anomalies: {request.include_if_anomalies}")
        logger.info(f"   sensor_ids: {request.sensor_ids}")
        
        # equipment ê°’ ê²€ì¦ ë° ì •ë¦¬
        equipment = request.equipment.strip() if request.equipment else "Unknown"
        if not equipment or equipment == "":
            logger.warning(f"equipment ê°’ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ ì‚¬ìš©: 'Unknown'")
            equipment = "Unknown"
        
        try:
            logger.info(f"ğŸ“… ë‚ ì§œ íŒŒì‹± ì‹œë„ ì¤‘...")
            logger.debug(f"   period_start='{request.period_start}' (íƒ€ì…: {type(request.period_start)})")
            logger.debug(f"   period_end='{request.period_end}' (íƒ€ì…: {type(request.period_end)})")
            start_dt = parse_datetime(request.period_start)
            end_dt = parse_datetime(request.period_end)
            logger.info(f"âœ… ë‚ ì§œ íŒŒì‹± ì„±ê³µ")
            logger.info(f"   start_dt: {start_dt} (ISO: {start_dt.isoformat()})")
            logger.info(f"   end_dt: {end_dt} (ISO: {end_dt.isoformat()})")
            logger.info(f"   íŒŒì‹±ëœ ì‹œê°„ (ISO): start_dt={start_dt.isoformat()}, end_dt={end_dt.isoformat()}")
        except ValueError as ve:
            logger.error(f"âŒ ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: period_start={request.period_start}, period_end={request.period_end}, error={ve}", exc_info=True)
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ì‹œì‘: {request.period_start}, ì¢…ë£Œ: {request.period_end}, ì˜¤ë¥˜: {str(ve)}"
            )
        except Exception as e:
            logger.error(f"âŒ ë‚ ì§œ íŒŒì‹± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}", exc_info=True)
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"ë‚ ì§œ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            )
        
        if end_dt <= start_dt:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="ì¢…ë£Œ ì‹œê°„ì´ ì‹œì‘ ì‹œê°„ë³´ë‹¤ ì´í›„ì—¬ì•¼ í•©ë‹ˆë‹¤."
            )
        
        # ë³´ê³ ì„œ ë°ì´í„° ìˆ˜ì§‘
        import time
        total_start_time = time.time()
        
        logger.info(f"ë³´ê³ ì„œ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘. ê¸°ê°„: {request.period_start} ~ {request.period_end}")
        data_collection_start = time.time()
        
        try:
            # report_serviceë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ë°ì´í„° ì¡°íšŒ
            from backend.api.services.report_service import get_report_service
            
            report_service = get_report_service()
            
            logger.info(f"ë³´ê³ ì„œ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: equipment={equipment}, ê¸°ê°„={start_dt} ~ {end_dt}")
            
            try:
                logger.info(f"ğŸ“Š ë³´ê³ ì„œ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: equipment={equipment}, ê¸°ê°„={start_dt} ~ {end_dt}")
                report_data = report_service.fetch_report_data(
                    start_time=start_dt,
                    end_time=end_dt,
                    equipment_id=equipment,
                    db=db,
                    sensor_ids=request.sensor_ids
                )
                logger.info(f"âœ… ë³´ê³ ì„œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
                logger.info(f"   ì„¼ì„œ í†µê³„: {len(report_data.get('sensor_stats', {}))}ê°œ")
                logger.info(f"   ì•ŒëŒ: {len(report_data.get('alarms', []))}ê°œ")
                logger.info(f"   MLP ì´ìƒ: {len(report_data.get('mlp_anomalies', []))}ê°œ")
                logger.info(f"   IF ì´ìƒ: {len(report_data.get('if_anomalies', []))}ê°œ")
            except Exception as data_error:
                logger.error(f"âŒ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {data_error}", exc_info=True)
                logger.error(f"   ì˜¤ë¥˜ íƒ€ì…: {type(data_error).__name__}")
                logger.error(f"   ì˜¤ë¥˜ ë©”ì‹œì§€: {str(data_error)}")
                # ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨í•´ë„ ê¸°ë³¸ êµ¬ì¡°ë¡œ ë³´ê³ ì„œ ìƒì„± ì‹œë„
                logger.warning("âš ï¸ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨, ê¸°ë³¸ê°’ìœ¼ë¡œ ë³´ê³ ì„œ ìƒì„± ì‹œë„")
                report_data = {
                    "metadata": {
                        "period_start": start_dt.isoformat(),
                        "period_end": end_dt.isoformat(),
                        "equipment": equipment,
                        "generated_at": datetime.now(timezone.utc).isoformat()
                    },
                    "sensor_stats": report_service._get_default_sensor_stats(),
                    "alarms": [],
                    "mlp_anomalies": [],
                    "if_anomalies": [],
                    "correlations": {}
                }
            
            # MLP ë° IF ì´ìƒ íƒì§€ í•„í„°ë§
            if not request.include_mlp_anomalies:
                report_data["mlp_anomalies"] = []
            if not request.include_if_anomalies:
                report_data["if_anomalies"] = []
        except ValueError as ve:
            logger.error(f"ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ (ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜): {ve}", exc_info=True)
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"ë³´ê³  ê¸°ê°„ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {str(ve)}"
            )
        except HTTPException:
            # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì „ë‹¬
            raise
        except Exception as e:
            logger.exception(f"ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            # ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨í•´ë„ ê¸°ë³¸ êµ¬ì¡°ë¡œ ë³´ê³ ì„œ ìƒì„± ì‹œë„
            logger.warning("ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨, ê¸°ë³¸ê°’ìœ¼ë¡œ ë³´ê³ ì„œ ìƒì„± ì‹œë„")
            from backend.api.services.report_service import get_report_service
            report_service = get_report_service()
            report_data = {
                "metadata": {
                    "period_start": start_dt.isoformat(),
                    "period_end": end_dt.isoformat(),
                    "equipment": equipment,
                    "generated_at": datetime.now(timezone.utc).isoformat()
                },
                "sensor_stats": report_service._get_default_sensor_stats(),
                "alarms": [],
                "mlp_anomalies": [],
                "if_anomalies": [],
                "correlations": {}
            }
        
        data_collection_time = time.time() - data_collection_start
        logger.info(f"âœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {data_collection_time:.2f}ì´ˆ)")
        
        # ë³´ê³ ì„œ ìƒì„±
        try:
            # ë³´ê³ ì„œ ìƒì„±ê¸° ì¸ìŠ¤í„´ìŠ¤ ë¦¬ì…‹ (ëª¨ë¸ ë³€ê²½ ì‹œ í•„ìš”)
            from backend.api.services.report_generator import reset_report_generator
            reset_report_generator()
            
            llm_start_time = time.time()
            logger.info("LLM ë³´ê³ ì„œ ìƒì„± ì‹œì‘...")
            
            # ë³´ê³ ì„œ ìƒì„±ê¸° ì´ˆê¸°í™” (ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”)
            try:
                generator = get_report_generator()
            except ImportError as e:
                logger.error(f"ë³´ê³ ì„œ ìƒì„±ê¸° íŒ¨í‚¤ì§€ ì˜¤ë¥˜: {e}", exc_info=True)
                raise HTTPException(
                    status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                    detail="ë³´ê³ ì„œ ìƒì„± ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. google-generativeai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                )
            except ValueError as e:
                error_msg = str(e)
                logger.error(f"ë³´ê³ ì„œ ìƒì„±ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨ (API í‚¤ ë¬¸ì œ): {e}", exc_info=True)
                
                # API í‚¤ ì •ì§€ ìƒíƒœë¥¼ ë” ëª…í™•í•˜ê²Œ ì²˜ë¦¬
                if "ì •ì§€ë˜ì—ˆìŠµë‹ˆë‹¤" in error_msg or "CONSUMER_SUSPENDED" in error_msg or "has been suspended" in error_msg.lower():
                    raise HTTPException(
                        status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                        detail=error_msg  # ì´ë¯¸ ì‚¬ìš©ì ì¹œí™”ì ì¸ ë©”ì‹œì§€ê°€ í¬í•¨ë˜ì–´ ìˆìŒ
                    )
                
                raise HTTPException(
                    status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                    detail=f"ë³´ê³ ì„œ ìƒì„± ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. GEMINI_API_KEYë¥¼ í™•ì¸í•˜ì„¸ìš”: {error_msg}"
                )
            except Exception as e:
                logger.error(f"ë³´ê³ ì„œ ìƒì„±ê¸° ì´ˆê¸°í™” ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}", exc_info=True)
                raise HTTPException(
                    status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                    detail=f"ë³´ê³ ì„œ ìƒì„±ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}"
                )
            
            # ë³´ê³ ì„œ ìƒì„± (ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”)
            try:
                logger.info(f"ğŸ“ LLM ë³´ê³ ì„œ ìƒì„± ì‹œì‘ (ë°ì´í„° ê²€ì¦)...")
                logger.info(f"   report_data í‚¤: {list(report_data.keys())}")
                logger.info(f"   sensor_stats í‚¤: {list(report_data.get('sensor_stats', {}).keys())}")
                
                report_content = generator.generate_report(report_data)
                
                if not report_content or not report_content.strip():
                    raise ValueError("ë³´ê³ ì„œ ìƒì„±ê¸°ëŠ” ì„±ê³µí–ˆì§€ë§Œ ë¹ˆ ë‚´ìš©ì´ ë°˜í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                logger.info(f"âœ… LLM ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ (ê¸¸ì´: {len(report_content)} ë¬¸ì)")
            except ValueError as e:
                error_msg = str(e)
                logger.error(f"âŒ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨ (ValueError): {error_msg}", exc_info=True)
                logger.error(f"   ì˜¤ë¥˜ ìƒì„¸: {type(e).__name__}: {error_msg}")
                
                # Gemini API í• ë‹¹ëŸ‰ ì´ˆê³¼ ì˜¤ë¥˜ì¸ ê²½ìš° ë” ëª…í™•í•œ ë©”ì‹œì§€
                if "í• ë‹¹ëŸ‰" in error_msg or "quota" in error_msg.lower() or "429" in error_msg or "rate limit" in error_msg.lower():
                    raise HTTPException(
                        status_code=status.HTTP_429_TOO_MANY_REQUESTS,
                        detail=error_msg
                    )
                
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail=f"ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {error_msg}"
                )
            except Exception as e:
                error_type = type(e).__name__
                error_msg = str(e)
                logger.error(f"âŒ ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {error_type}: {error_msg}", exc_info=True)
                logger.error(f"   ì˜¤ë¥˜ íƒ€ì…: {error_type}")
                logger.error(f"   ì˜¤ë¥˜ ë©”ì‹œì§€: {error_msg}")
                
                # ë” ìì„¸í•œ ì—ëŸ¬ ì •ë³´ ì œê³µ
                detail_msg = f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}"
                if hasattr(e, '__cause__') and e.__cause__:
                    detail_msg += f" (ì›ì¸: {str(e.__cause__)})"
                
                raise HTTPException(
                    status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                    detail=detail_msg
                )
            
            llm_time = time.time() - llm_start_time
            total_time = time.time() - total_start_time
            logger.info(f"âœ… LLM ìƒì„± ì™„ë£Œ (ì†Œìš” ì‹œê°„: {llm_time:.2f}ì´ˆ)")
            logger.info(f"ğŸ“Š ì „ì²´ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ (ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ, ë°ì´í„° ìˆ˜ì§‘: {data_collection_time:.2f}ì´ˆ, LLM ìƒì„±: {llm_time:.2f}ì´ˆ)")
            
            # ì‘ë‹µ ìƒì„±
            report_id = f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            # PDF ë‹¤ìš´ë¡œë“œ ìš”ì²­ì¸ ê²½ìš°
            if format == 'pdf':
                try:
                    # PDF ìƒì„±
                    pdf_path = Path("reports") / f"{report_id}.pdf"
                    pdf_path.parent.mkdir(exist_ok=True)
                    
                    metadata_dict = {
                        "ë³´ê³  ê¸°ê°„": f"{start_dt.strftime('%Y-%m-%d %H:%M:%S UTC')} ~ {end_dt.strftime('%Y-%m-%d %H:%M:%S UTC')}",
                        "ì„¤ë¹„ ID": equipment,
                        "ìƒì„± ì‹œê°": datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')
                    }
                    
                    success = markdown_to_pdf(
                        markdown_text=report_content,
                        output_path=pdf_path,
                        title="MOBY ì„¤ë¹„ ìƒíƒœ ë³´ê³ ì„œ",
                        metadata=metadata_dict
                    )
                    
                    if success:
                        logger.info(f"PDF ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {pdf_path}")
                        return FileResponse(
                            path=str(pdf_path),
                            filename=f"{report_id}.pdf",
                            media_type="application/pdf",
                            headers={
                                "Content-Disposition": f'attachment; filename="{report_id}.pdf"'
                            }
                        )
                    else:
                        logger.warning("PDF ìƒì„± ì‹¤íŒ¨, JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜")
                except Exception as e:
                    logger.error(f"PDF ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
                    # PDF ìƒì„± ì‹¤íŒ¨ ì‹œ JSONìœ¼ë¡œ í´ë°±
            
            # JSON ì‘ë‹µ (ê¸°ë³¸)
            response = ReportResponse(
                report_id=report_id,
                report_content=report_content,
                metadata=report_data.get("metadata", {}),
                generated_at=datetime.now().isoformat() + "Z"
            )
            
            logger.info(f"ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ. report_id={report_id}")
            
            return SuccessResponse(
                success=True,
                data=response,
                message="ë³´ê³ ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
            )
        except HTTPException:
            # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì „ë‹¬
            raise
        except Exception as e:
            # ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜
            logger.exception(f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"ë³´ê³ ì„œ ìƒì„± API ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


async def _collect_report_data(
    db: Session,
    period_start: str,
    period_end: str,
    equipment: str,
    sensor_ids: Optional[list[str]] = None,
    include_mlp_anomalies: bool = True,
    include_if_anomalies: bool = True
) -> Dict[str, Any]:
    """
    ë³´ê³ ì„œ ìƒì„±ì„ ìœ„í•œ ë°ì´í„° ìˆ˜ì§‘
    
    Args:
        period_start: ë³´ê³  ê¸°ê°„ ì‹œì‘
        period_end: ë³´ê³  ê¸°ê°„ ì¢…ë£Œ
        equipment: ì„¤ë¹„ëª…
        sensor_ids: íŠ¹ì • ì„¼ì„œ ID ëª©ë¡
        include_mlp_anomalies: MLP ì´ìƒ íƒì§€ í¬í•¨ ì—¬ë¶€
        include_if_anomalies: Isolation Forest ì´ìƒ íƒì§€ í¬í•¨ ì—¬ë¶€
        
    Returns:
        ë³´ê³ ì„œ ìƒì„±ì— í•„ìš”í•œ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
    """
    # ë©”íƒ€ë°ì´í„°
    metadata = {
        "period_start": period_start,
        "period_end": period_end,
        "equipment": equipment,
        "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    
    # ì•ŒëŒ ë°ì´í„° ìˆ˜ì§‘ (ì„±ëŠ¥ ìµœì í™”: ì œí•œëœ ìˆ˜ë§Œ ê°€ì ¸ì˜¤ê¸°)
    # ê¸°ê°„ í•„í„°ë§ì„ ìœ„í•´ ì•ŒëŒì„ ê°€ì ¸ì˜¨ í›„ í•„í„°ë§
    # limitì„ 500ìœ¼ë¡œ ì¤„ì—¬ì„œ ë°ì´í„° ìˆ˜ì§‘ ì‹œê°„ ë‹¨ì¶•
    try:
        all_alerts = get_latest_alerts(
            db=db,
            limit=500,  # 1000 â†’ 500ìœ¼ë¡œ ê°ì†Œ (ì„±ëŠ¥ ê°œì„ )
            sensor_id=None if not sensor_ids else sensor_ids[0] if len(sensor_ids) == 1 else None,
            level=None
        )
    except Exception as e:
        logger.error(f"ì•ŒëŒ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}", exc_info=True)
        # ì•ŒëŒ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬ (ë³´ê³ ì„œëŠ” ìƒì„± ê°€ëŠ¥)
        all_alerts = []
        logger.warning("ì•ŒëŒ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨ë¡œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ë³´ê³ ì„œëŠ” ê³„ì† ìƒì„±ë©ë‹ˆë‹¤.")
    
    # ê¸°ê°„ í•„í„°ë§ (parse_datetime í•¨ìˆ˜ ì¬ì‚¬ìš©)
    # timezone-aware datetimeìœ¼ë¡œ í†µì¼í•˜ì—¬ ë¹„êµ ì˜¤ë¥˜ ë°©ì§€
    def parse_datetime_for_filter(date_str: str) -> datetime:
        """ì—¬ëŸ¬ ë‚ ì§œ í˜•ì‹ì„ ì§€ì›í•˜ëŠ” íŒŒì„œ (í•„í„°ë§ìš©) - timezone-awareë¡œ ë°˜í™˜"""
        formats = [
            "%Y-%m-%d %H:%M:%S",  # YYYY-MM-DD HH:MM:SS
            "%Y-%m-%dT%H:%M:%S",  # YYYY-MM-DDTHH:MM:SS (ISO í˜•ì‹)
            "%Y-%m-%d %H:%M",     # YYYY-MM-DD HH:MM
            "%Y-%m-%dT%H:%M",     # YYYY-MM-DDTHH:MM
        ]
        
        for fmt in formats:
            try:
                # timezone-naive datetimeì„ UTC timezone-awareë¡œ ë³€í™˜
                dt = datetime.strptime(date_str, fmt)
                if dt.tzinfo is None:
                    dt = dt.replace(tzinfo=timezone.utc)
                return dt
            except ValueError:
                continue
        
        # ISO í˜•ì‹ìœ¼ë¡œ ì‹œë„
        try:
            dt = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
            # ì´ë¯¸ timezone-awareì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
            if dt.tzinfo is None:
                dt = dt.replace(tzinfo=timezone.utc)
            return dt
        except ValueError:
            pass
        
        raise ValueError(f"ë‚ ì§œ í˜•ì‹ì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {date_str}")
    
    start_dt = parse_datetime_for_filter(period_start)
    end_dt = parse_datetime_for_filter(period_end)
    
    alerts = []
    for alert in all_alerts:
        try:
            # alert.tsë¥¼ timezone-aware datetimeìœ¼ë¡œ ë³€í™˜
            alert_ts_str = alert.ts.replace('Z', '+00:00') if 'Z' in alert.ts else alert.ts
            alert_ts = datetime.fromisoformat(alert_ts_str)
            # timezone ì •ë³´ê°€ ì—†ìœ¼ë©´ UTCë¡œ ì„¤ì •
            if alert_ts.tzinfo is None:
                alert_ts = alert_ts.replace(tzinfo=timezone.utc)
            
            # ì´ì œ ëª¨ë“  datetimeì´ timezone-awareì´ë¯€ë¡œ ë¹„êµ ê°€ëŠ¥
            if start_dt <= alert_ts <= end_dt:
                alerts.append({
                    "id": alert.alert_id,
                    "ts": alert.ts,
                    "sensor_id": alert.sensor_id,
                    "level": alert.level,
                    "message": alert.message,
                    "details": alert.details if alert.details else {}
                })
        except (ValueError, AttributeError):
            continue
    
    # ì•ŒëŒ ëª©ë¡ êµ¬ì„±
    alarms = []
    mlp_anomalies = []
    if_anomalies = []
    
    for alert in alerts:
        details = alert.get("details", {})
        if not isinstance(details, dict):
            details = {}
        
        # ì›ë³¸ ë…¸íŠ¸ë¶ í˜•ì‹ì— ë§ì¶˜ alarms ë°ì´í„° êµ¬ì¡°
        # ì›ë³¸: {"timestamp": "...", "sensor": "...", "value": 52.3, "threshold": 50.0, "level": "WARNING"}
        alarm_data = {
            "timestamp": alert.get("ts", ""),
            "sensor": alert.get("sensor_id", ""),
            "level": alert.get("level", ""),
            "message": alert.get("message", "")
        }
        
        # detailsì—ì„œ valueì™€ threshold ì¶”ì¶œ (ì›ë³¸ í˜•ì‹ì— ë§ì¶¤)
        if "value" in details:
            alarm_data["value"] = details.get("value")
        if "threshold" in details:
            alarm_data["threshold"] = details.get("threshold")
        
        alarms.append(alarm_data)
        
        # MLP ì´ìƒ íƒì§€ í™•ì¸
        if include_mlp_anomalies and "vector" in details:
            mlp_anomalies.append({
                "timestamp": alert.get("ts", ""),
                "type": details.get("type", "MLP_composite"),
                "vector": details.get("vector", []),
                "vector_magnitude": details.get("norm", 0.0),
                "threshold": details.get("threshold", 0.5),
                "component_labels": details.get("meta", {}).get("component_labels", []) if isinstance(details.get("meta"), dict) else []
            })
        
        # Isolation Forest ì´ìƒ íƒì§€ í™•ì¸ (ì›ë³¸ í˜•ì‹ì— ë§ì¶¤)
        if include_if_anomalies and "anomaly_score" in details:
            if_anomaly = {
                "start_time": alert.get("ts", ""),
                "anomaly_score": details.get("anomaly_score", 0.0),
                "threshold": details.get("threshold", -0.15),
                "key_features": details.get("meta", {}) if isinstance(details.get("meta"), dict) else {}
            }
            
            # ì›ë³¸ ë…¸íŠ¸ë¶ í˜•ì‹ì— ë§ì¶° ì¶”ê°€ í•„ë“œ í¬í•¨
            if "end_time" in details:
                if_anomaly["end_time"] = details.get("end_time")
            if "duration_minutes" in details:
                if_anomaly["duration_minutes"] = details.get("duration_minutes")
            if "mlp_vector_magnitude" in details:
                if_anomaly["mlp_vector_magnitude"] = details.get("mlp_vector_magnitude")
            
            if_anomalies.append(if_anomaly)
    
    # ì„¼ì„œ í†µê³„ (ì˜ˆì‹œ ë°ì´í„° - ì‹¤ì œë¡œëŠ” InfluxDBì—ì„œ ì§‘ê³„)
    # TODO: InfluxDBì—ì„œ ì‹¤ì œ ì„¼ì„œ í†µê³„ ìˆ˜ì§‘
    # ì›ë³¸ ë…¸íŠ¸ë¶ í˜•ì‹ì— ë§ì¶° ëª¨ë“  ì„¼ì„œ ë°ì´í„° í¬í•¨
    sensor_stats = {
        "temperature": {
            "mean": 38.2,
            "min": 22.1,
            "max": 52.3,
            "std": 6.8,
            "p95": 48.5,
            "missing_rate": 0.002,
            "threshold_violations": len([a for a in alarms if a.get("sensor") == "temperature"])
        },
        "humidity": {
            "mean": 62.5,
            "min": 45.2,
            "max": 78.9,
            "std": 8.3,
            "p95": 75.1,
            "missing_rate": 0.002
        },
        "vibration": {
            "x": {"mean": 1.24, "peak": 3.87, "rms": 1.45, "p95": 2.31},
            "y": {"mean": 1.18, "peak": 3.52, "rms": 1.39, "p95": 2.18},
            "z": {"mean": 0.95, "peak": 2.89, "rms": 1.12, "p95": 1.87},
            "trend_note": "Xì¶• ì§„ë™ì´ ì£¼ í›„ë°˜ë¶€ ì•½ 15% ì¦ê°€"
        },
        # ì›ë³¸ ë…¸íŠ¸ë¶ì— ìˆë˜ ì¶”ê°€ ì„¼ì„œ ë°ì´í„°
        "accelerometer": {
            "x": {"mean": 0.12, "peak": 2.45, "rms": 0.38, "std": 0.34},
            "y": {"mean": -0.08, "peak": 2.21, "rms": 0.35, "std": 0.32},
            "z": {"mean": 9.81, "peak": 11.23, "rms": 9.85, "std": 0.28}
        },
        "gyroscope": {
            "x": {"mean": 0.03, "peak": 8.92, "rms": 1.24, "std": 1.22},
            "y": {"mean": -0.01, "peak": 7.68, "rms": 1.18, "std": 1.17},
            "z": {"mean": 0.02, "peak": 6.34, "rms": 0.95, "std": 0.94}
        },
        "sound": {
            "mean": 68.3,
            "max": 89.7,
            "p95": 81.5,
            "threshold_violations": len([a for a in alarms if a.get("sensor") == "sound"])
        },
        "pressure": {
            "mean": 1013.2,
            "min": 1008.5,
            "max": 1018.7,
            "trend_note": "ì£¼ì¤‘ ê¸°ì•• ì™„ë§Œ í•˜ê°• (ê¸°ìƒ ì˜í–¥)"
        }
    }
    
    # ìƒê´€ê³„ìˆ˜ (ì˜ˆì‹œ ë°ì´í„° - ì‹¤ì œë¡œëŠ” ê³„ì‚° í•„ìš”)
    correlations = {
        "temperature_vibration_x": {"value": 0.78, "interpretation": "ê°•í•œ ì–‘ì˜ ìƒê´€"},
        "vibration_magnitude_sound": {"value": 0.65, "interpretation": "ì¤‘ê°„ ì–‘ì˜ ìƒê´€"},
        "temperature_humidity": {"value": -0.42, "interpretation": "ì¤‘ê°„ ìŒì˜ ìƒê´€"}
    }
    
    return {
        "metadata": metadata,
        "sensor_stats": sensor_stats,
        "alarms": alarms,
        "mlp_anomalies": mlp_anomalies if include_mlp_anomalies else [],
        "if_anomalies": if_anomalies if include_if_anomalies else [],
        "correlations": correlations
    }

